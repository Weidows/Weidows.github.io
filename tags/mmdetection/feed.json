{
    "version": "https://jsonfeed.org/version/1",
    "title": "⭐️齐下无贰⭐️ • All posts by \"mmdetection\" tag",
    "description": "May all the beauty be bless.✨",
    "home_page_url": "https://weidows.github.io",
    "items": [
        {
            "id": "https://weidows.github.io/post/python/code/MM-Detection/",
            "url": "https://weidows.github.io/post/python/code/MM-Detection/",
            "title": "🐳MM-Detection-Colab",
            "date_published": "2022-06-07T09:06:50.000Z",
            "content_html": "<!--\n * @?: *********************************************************************\n * @Author: Weidows\n * @LastEditors: Weidows\n * @LastEditTime: 2022-04-20 23:11:24\n * @FilePath: \\Blog-private\\scaffolds\\post.md\n * @Description:\n * @!: *********************************************************************\n-->\n<h2 id=\"序-3\">序</h2>\n<ul>\n<li>\n<p>Colab 平台对于 <code>轻量级/边缘计算</code> 比较方便, 尤其是对这种教程性质的 notebook, 分享和运行都开箱即用</p>\n</li>\n<li>\n<p>但另一方面:</p>\n<p><code>因</code>: 免费版的 Colab 所给的硬件资源不是很稳定, 用太久的话会分不到 GPU, 虽然给的 GPU 肯定是比自己的开发机强很多, 但是跑大型项目肯定带不动 (而且 Colab 单次运行最多持续 6h, 一段时间没动作的话会断连, 断开后再过一阵 runtime 会被重置)</p>\n</li>\n<li>\n<p><code>果</code>: 可以用它来学习下怎么搭环境以及一些小测试</p>\n<p>毕竟生产服务器申请不易 / 环境也不能乱动</p>\n<p>受系统和网络限制, 在开发机搭环境并不理想</p>\n</li>\n</ul>\n<p><a><img src=\"https://fastly.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"装环境-2\">装环境</h2>\n<blockquote>\n<p>从安装到放弃到爬出坑 :( <br>\n跟着这几篇装的环境:<sup id='cite_ref-2'><a href=\"#cite_note-2\">[2]</a></sup><sup id='cite_ref-3'><a href=\"#cite_note-3\">[3]</a></sup>, 有借鉴意义但是指导不明确 <br>\n个人先跟着官方出的视频教程和 openbayes 上的 notebook 试了试水, 很深 <sup id='cite_ref-1'><a href=\"#cite_note-1\">[1]</a></sup>; 最后找到一个源库 tutorial-fork 的 colab-notebook <sup id='cite_ref-4'><a href=\"#cite_note-4\">[4]</a></sup> \\</p>\n</blockquote>\n<p>预先装上 cuda, cudnn (colab自带)</p>\n<p>依赖链: <code>cuda -&gt; pytorch -&gt; mmcv-full -&gt; mmdet</code></p>\n<p>每一步依赖前面环境的版本, 即使后面能装上也可能不适配, 任何一步有问题都 can’t-run</p>\n<p><img src=\"https://www.helloimg.com/images/2022/06/06/ZtZpOm.png\" alt=\"\"></p>\n<p><a><img src=\"https://fastly.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ====================可选, colab并不自带conda=====================</span></span><br><span class=\"line\">!conda create -n openmmlab -y</span><br><span class=\"line\">!conda activate openmmlab</span><br><span class=\"line\">!conda init</span><br></pre></td></tr></table></figure>\n<pre><code>/bin/bash: conda: command not found\n/bin/bash: conda: command not found\n/bin/bash: conda: command not found\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ================== 一键装好环境 =======================</span></span><br><span class=\"line\"><span class=\"comment\"># 如果这里有问题可以重启一下内核: 代码执行程序 -&gt; 重新启动代码执行程序</span></span><br><span class=\"line\"></span><br><span class=\"line\">!python -m pip install --upgrade pip</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 注意对应机子配置: https://pytorch.org/</span></span><br><span class=\"line\"><span class=\"comment\"># install dependencies: (use cu111 because colab has CUDA 11.1)</span></span><br><span class=\"line\">%pip install torch==<span class=\"number\">1.9</span><span class=\"number\">.0</span>+cu111 torchvision==<span class=\"number\">0.10</span><span class=\"number\">.0</span>+cu111 -f https://download.pytorch.org/whl/torch_stable.html</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># windows 平台不用装了, 一定会卡在这</span></span><br><span class=\"line\"><span class=\"comment\"># https://github.com/open-mmlab/mmcv/blob/master/README_zh-CN.md</span></span><br><span class=\"line\">%pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1<span class=\"number\">.9</span><span class=\"number\">.0</span>/index.html</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 与pip/conda同级的专门给mm-lab用的包管理器, 报错率很高</span></span><br><span class=\"line\">%pip install openmim</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 依赖 mmcv, 如果用mim装的话大概率有问题</span></span><br><span class=\"line\">%pip install mmsegmentation</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 后面要用到源码库的 config, 可选用源库安装</span></span><br><span class=\"line\">%pip install mmdet</span><br><span class=\"line\"><span class=\"comment\"># !rm -rf /content/mmdetection</span></span><br><span class=\"line\">!git clone https://github.com/<span class=\"built_in\">open</span>-mmlab/mmdetection.git</span><br><span class=\"line\">%cd mmdetection</span><br><span class=\"line\"><span class=\"comment\"># %pip install -e .</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 后续当前路径为 /content/mmdetection</span></span><br></pre></td></tr></table></figure>\n<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\nCollecting pip\n  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n\u001b[K     |████████████████████████████████| 2.1 MB 4.8 MB/s \n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 21.1.3\n    Uninstalling pip-21.1.3:\n      Successfully uninstalled pip-21.1.3\nSuccessfully installed pip-22.1.2\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\nCollecting torch==1.9.0+cu111\n  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2041348096 bytes == 0x2a2a000 @  0x7fdbaca001e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c\n\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2551685120 bytes == 0x7c4f2000 @  0x7fdbaca01615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x593fce\ntcmalloc: large alloc 2041348096 bytes == 0x2a2a000 @  0x7fdbaca001e7 0x4a3940 0x5b438c 0x5b46f7 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5fbece 0x594b72 0x548cc1 0x51566f 0x593dd7 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m858.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torchvision==0.10.0+cu111\n  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.2.0)\nRequirement already satisfied: pillow&gt;=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)\nInstalling collected packages: torch, torchvision\n  Attempting uninstall: torch\n    Found existing installation: torch 1.11.0+cu113\n    Uninstalling torch-1.11.0+cu113:\n      Successfully uninstalled torch-1.11.0+cu113\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.12.0+cu113\n    Uninstalling torchvision-0.12.0+cu113:\n      Successfully uninstalled torchvision-0.12.0+cu113\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.\ntorchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-1.9.0+cu111 torchvision-0.10.0+cu111\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nLooking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\nCollecting mmcv-full\n  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (45.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting addict\n  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\nCollecting yapf\n  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.2/190.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\nRequirement already satisfied: opencv-python&gt;=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;mmcv-full) (3.0.9)\nInstalling collected packages: yapf, addict, mmcv-full\nSuccessfully installed addict-2.4.0 mmcv-full-1.5.2 yapf-0.32.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting openmim\n  Downloading openmim-0.1.5.tar.gz (35 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: Click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\nCollecting colorama\n  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\nCollecting model-index\n  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\nRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.9)\nRequirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index-&gt;openmim) (3.3.7)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index-&gt;openmim) (3.13)\nCollecting ordered-set\n  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;openmim) (2.8.2)\nRequirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;openmim) (1.21.6)\nRequirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;openmim) (2022.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;openmim) (2022.5.18.1)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;openmim) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;openmim) (1.24.3)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;openmim) (3.0.4)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;openmim) (1.15.0)\nRequirement already satisfied: importlib-metadata&gt;=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown-&gt;model-index-&gt;openmim) (4.11.4)\nRequirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=4.4-&gt;markdown-&gt;model-index-&gt;openmim) (4.2.0)\nRequirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=4.4-&gt;markdown-&gt;model-index-&gt;openmim) (3.8.0)\nBuilding wheels for collected packages: openmim\n  Building wheel for openmim (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openmim: filename=openmim-0.1.5-py2.py3-none-any.whl size=42503 sha256=a20baa555947a826ad1fb5c6b5c7282eb538ed92cf4e3dfec2f7eb3044005554\n  Stored in directory: /root/.cache/pip/wheels/16/8b/e1/bdebbbc687aa50224a5ce46fe97a040a0c59f92b34bfc750b6\nSuccessfully built openmim\nInstalling collected packages: ordered-set, colorama, model-index, openmim\nSuccessfully installed colorama-0.4.4 model-index-0.1.11 openmim-0.1.5 ordered-set-4.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting mmsegmentation\n  Downloading mmsegmentation-0.25.0-py3-none-any.whl (804 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.0/805.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (3.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (21.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (3.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (1.21.6)\nCollecting mmcls&gt;=0.20.1\n  Downloading mmcls-0.23.1-py2.py3-none-any.whl (577 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.3/577.3 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmsegmentation) (1.4.2)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmsegmentation) (0.11.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmsegmentation) (3.0.9)\nRequirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmsegmentation) (2.8.2)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable-&gt;mmsegmentation) (0.2.5)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable-&gt;mmsegmentation) (4.11.4)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;mmsegmentation) (4.2.0)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;mmsegmentation) (1.15.0)\nRequirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;prettytable-&gt;mmsegmentation) (3.8.0)\nInstalling collected packages: mmcls, mmsegmentation\nSuccessfully installed mmcls-0.23.1 mmsegmentation-0.25.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting mmdet\n  Downloading mmdet-2.25.0-py3-none-any.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet) (3.2.2)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet) (2.0.4)\nRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.15.0)\nCollecting terminaltables\n  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.21.6)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmdet) (3.0.9)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmdet) (1.4.2)\nRequirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmdet) (2.8.2)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;mmdet) (0.11.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;mmdet) (4.2.0)\nInstalling collected packages: terminaltables, mmdet\nSuccessfully installed mmdet-2.25.0 terminaltables-3.1.10\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'mmdetection'...\nremote: Enumerating objects: 24927, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (10/10), done.\u001b[K\nremote: Total 24927 (delta 2), reused 8 (delta 1), pack-reused 24916\u001b[K\nReceiving objects: 100% (24927/24927), 37.75 MiB | 31.35 MiB/s, done.\nResolving deltas: 100% (17469/17469), done.\n/content/mmdetection\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 验证安装</span></span><br><span class=\"line\">!nvcc -V</span><br><span class=\"line\">!pip <span class=\"built_in\">list</span> | grep mm</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> mmcv <span class=\"keyword\">import</span> collect_env</span><br><span class=\"line\">collect_env()</span><br></pre></td></tr></table></figure>\n<pre><code>nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2020 NVIDIA Corporation\nBuilt on Mon_Oct_12_20:09:46_PDT_2020\nCuda compilation tools, release 11.1, V11.1.105\nBuild cuda_11.1.TC455_06.29190527_0\ncommunity                     1.0.0b1\ngoogleapis-common-protos      1.56.2\nmmcls                         0.23.1\nmmcv-full                     1.5.2\nmmdet                         2.25.0\nmmsegmentation                0.25.0\npyviz-comms                   2.2.0\nsnowballstemmer               2.2.0\ntorchsummary                  1.5.1\n\n\n\n\n\n&#123;'CUDA available': True,\n 'CUDA_HOME': '/usr/local/cuda',\n 'GCC': 'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0',\n 'GPU 0': 'Tesla T4',\n 'MMCV': '1.5.2',\n 'MMCV CUDA Compiler': '11.1',\n 'MMCV Compiler': 'GCC 7.3',\n 'NVCC': 'Cuda compilation tools, release 11.1, V11.1.105',\n 'OpenCV': '4.1.2',\n 'PyTorch': '1.9.0+cu111',\n 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n',\n 'Python': '3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]',\n 'TorchVision': '0.10.0+cu111',\n 'sys.platform': 'linux'&#125;\n</code></pre>\n<p><a><img src=\"https://fastly.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"测试-5\">测试</h2>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># mim 也可以用来search/download,不过 doc 在捉迷藏..不知道怎么用</span></span><br><span class=\"line\"><span class=\"comment\"># https://github.com/open-mmlab/mmdetection/tree/master/configs/mask_rcnn</span></span><br><span class=\"line\"><span class=\"comment\"># 跟教程一样的命令...失效了?</span></span><br><span class=\"line\"><span class=\"comment\"># !mim search mmdet --model &#x27;mask r-cnn&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># !mim download mmdet --config mask_rcnn_r50_fpn_2x_coco --dest ./_model</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 下载并分别测试下面两个 pre-trained model-checkpoints</span></span><br><span class=\"line\">!mkdir checkpoints</span><br><span class=\"line\">!wget -c https://download.openmmlab.com/mmdetection/v2<span class=\"number\">.0</span>/mask_rcnn/mask_rcnn_r50_fpn_2x_coco/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-<span class=\"number\">0.392</span>__segm_mAP-<span class=\"number\">0.354_20200505_003907</span>-3e542a40.pth \\</span><br><span class=\"line\">      -O checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-<span class=\"number\">0.392</span>__segm_mAP-<span class=\"number\">0.354_20200505_003907</span>-3e542a40.pth</span><br><span class=\"line\">!wget -c https://download.openmmlab.com/mmdetection/v2<span class=\"number\">.0</span>/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \\</span><br><span class=\"line\">      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>--2022-06-07 15:03:24--  https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_2x_coco/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth\nResolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\nConnecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 177866862 (170M) [application/octet-stream]\nSaving to: ‘checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth’\n\ncheckpoints/mask_rc 100%[===================&gt;] 169.63M  8.23MB/s    in 22s     \n\n2022-06-07 15:03:47 (7.65 MB/s) - ‘checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth’ saved [177866862/177866862]\n\n--2022-06-07 15:03:48--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth\nResolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\nConnecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 167291982 (160M) [application/octet-stream]\nSaving to: ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’\n\ncheckpoints/faster_ 100%[===================&gt;] 159.54M  9.11MB/s    in 18s     \n\n2022-06-07 15:04:06 (9.04 MB/s) - ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’ saved [167291982/167291982]\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> mmdet.apis <span class=\"keyword\">import</span> init_detector, inference_detector, show_result_pyplot</span><br><span class=\"line\"></span><br><span class=\"line\">config = <span class=\"string\">&#x27;configs/mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py&#x27;</span></span><br><span class=\"line\">checkpoint = <span class=\"string\">&#x27;checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 在 CPU 上需要设置 device=&#x27;cpu&#x27; ; GPU 上设置 device=&#x27;cuda:0&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># 使用 mmdetection 源库自带的 demo/demo.jpg</span></span><br><span class=\"line\">model = init_detector(config, checkpoint, device=<span class=\"string\">&#x27;cuda:0&#x27;</span>) </span><br><span class=\"line\">result = inference_detector(model, <span class=\"string\">&#x27;demo/demo.jpg&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">show_result_pyplot(model, <span class=\"string\">&#x27;demo/demo.jpg&#x27;</span>, result)</span><br></pre></td></tr></table></figure>\n<pre><code>load checkpoint from local path: checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth\n\n\n/content/mmdetection/mmdet/datasets/utils.py:70: UserWarning: &quot;ImageToTensor&quot; pipeline is replaced by &quot;DefaultFormatBundle&quot; for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n  'data pipeline in your config file.', UserWarning)\n/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n</code></pre>\n<p><img src=\"MM-Detection_files/MM-Detection_7_2.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> mmcv</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmcv.runner <span class=\"keyword\">import</span> load_checkpoint</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.apis <span class=\"keyword\">import</span> inference_detector, show_result_pyplot</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.models <span class=\"keyword\">import</span> build_detector</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Choose to use a config and initialize the detector</span></span><br><span class=\"line\">config = <span class=\"string\">&#x27;configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># Setup a checkpoint file to load</span></span><br><span class=\"line\">checkpoint = <span class=\"string\">&#x27;checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the device to be used for evaluation</span></span><br><span class=\"line\">device=<span class=\"string\">&#x27;cuda:0&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load the config</span></span><br><span class=\"line\">config = mmcv.Config.fromfile(config)</span><br><span class=\"line\"><span class=\"comment\"># Set pretrained to be None since we do not need pretrained model here</span></span><br><span class=\"line\">config.model.pretrained = <span class=\"literal\">None</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Initialize the detector</span></span><br><span class=\"line\">model = build_detector(config.model)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Load checkpoint</span></span><br><span class=\"line\">checkpoint = load_checkpoint(model, checkpoint, map_location=device)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set the classes of models for inference</span></span><br><span class=\"line\">model.CLASSES = checkpoint[<span class=\"string\">&#x27;meta&#x27;</span>][<span class=\"string\">&#x27;CLASSES&#x27;</span>]</span><br><span class=\"line\"><span class=\"comment\"># We need to set the model&#x27;s cfg for inference</span></span><br><span class=\"line\">model.cfg = config</span><br><span class=\"line\"><span class=\"comment\"># Convert the model to GPU</span></span><br><span class=\"line\">model.to(device)</span><br><span class=\"line\"><span class=\"comment\"># Convert the model into evaluation mode</span></span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use the detector to do inference</span></span><br><span class=\"line\">img = <span class=\"string\">&#x27;demo/demo.jpg&#x27;</span></span><br><span class=\"line\">result = inference_detector(model, img)</span><br><span class=\"line\"><span class=\"comment\"># Let&#x27;s plot the result</span></span><br><span class=\"line\">show_result_pyplot(model, img, result, score_thr=<span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>load checkpoint from local path: checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth\n\n\n/content/mmdetection/mmdet/datasets/utils.py:70: UserWarning: &quot;ImageToTensor&quot; pipeline is replaced by &quot;DefaultFormatBundle&quot; for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n  'data pipeline in your config file.', UserWarning)\n/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n</code></pre>\n<p><img src=\"MM-Detection_files/MM-Detection_8_2.png\" alt=\"png\"></p>\n<p><a><img src=\"https://fastly.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"Custom-training\">Custom-training</h2>\n<ol>\n<li>\n<p>选择+下载预训练模型和数据集</p>\n<p>参数解释: <code>mask_rcnn_r50_fpn_2x_coco</code></p>\n<p>mask_rcnn 中不同的 backbone (主干网络)</p>\n<p>r50: 50层ResNet</p>\n<p>fpn: 特征金字塔</p>\n<p>2x: learning rate schedule</p>\n</li>\n<li>\n<p>定义数据集类 + config</p>\n</li>\n<li>\n<p>调用 API 训练 + 评估</p>\n</li>\n<li>\n<p>用训练好的模型推理测试</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># pre-trained model 在上面下载好了, 这里只下载数据集</span></span><br><span class=\"line\">!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.<span class=\"built_in\">zip</span></span><br><span class=\"line\">!unzip kitti_tiny.<span class=\"built_in\">zip</span> &gt; /dev/null</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Let&#x27;s take a look at the dataset image</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> mmcv</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = mmcv.imread(<span class=\"string\">&#x27;kitti_tiny/training/image_2/000073.jpeg&#x27;</span>)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">plt.imshow(mmcv.bgr2rgb(img))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>--2022-06-07 15:40:35--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\nResolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\nConnecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 6918271 (6.6M) [application/zip]\nSaving to: ‘kitti_tiny.zip’\n\nkitti_tiny.zip      100%[===================&gt;]   6.60M  8.72MB/s    in 0.8s    \n\n2022-06-07 15:40:37 (8.72 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]\n</code></pre>\n<p><img src=\"MM-Detection_files/MM-Detection_10_1.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 自定义数据集格式 &#x27;KittiTinyDataset&#x27; 并注册到 mmdet</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> copy</span><br><span class=\"line\"><span class=\"keyword\">import</span> os.path <span class=\"keyword\">as</span> osp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> mmcv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.datasets.builder <span class=\"keyword\">import</span> DATASETS</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.datasets.custom <span class=\"keyword\">import</span> CustomDataset</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@DATASETS.register_module()</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">KittiTinyDataset</span>(<span class=\"title class_ inherited__\">CustomDataset</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    CLASSES = (<span class=\"string\">&#x27;Car&#x27;</span>, <span class=\"string\">&#x27;Pedestrian&#x27;</span>, <span class=\"string\">&#x27;Cyclist&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">load_annotations</span>(<span class=\"params\">self, ann_file</span>):</span><br><span class=\"line\">        cat2label = &#123;k: i <span class=\"keyword\">for</span> i, k <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(self.CLASSES)&#125;</span><br><span class=\"line\">        <span class=\"comment\"># load image list from file</span></span><br><span class=\"line\">        image_list = mmcv.list_from_file(self.ann_file)</span><br><span class=\"line\">    </span><br><span class=\"line\">        data_infos = []</span><br><span class=\"line\">        <span class=\"comment\"># convert annotations to middle format</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> image_id <span class=\"keyword\">in</span> image_list:</span><br><span class=\"line\">            filename = <span class=\"string\">f&#x27;<span class=\"subst\">&#123;self.img_prefix&#125;</span>/<span class=\"subst\">&#123;image_id&#125;</span>.jpeg&#x27;</span></span><br><span class=\"line\">            image = mmcv.imread(filename)</span><br><span class=\"line\">            height, width = image.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">            data_info = <span class=\"built_in\">dict</span>(filename=<span class=\"string\">f&#x27;<span class=\"subst\">&#123;image_id&#125;</span>.jpeg&#x27;</span>, width=width, height=height)</span><br><span class=\"line\">    </span><br><span class=\"line\">            <span class=\"comment\"># load annotations</span></span><br><span class=\"line\">            label_prefix = self.img_prefix.replace(<span class=\"string\">&#x27;image_2&#x27;</span>, <span class=\"string\">&#x27;label_2&#x27;</span>)</span><br><span class=\"line\">            lines = mmcv.list_from_file(osp.join(label_prefix, <span class=\"string\">f&#x27;<span class=\"subst\">&#123;image_id&#125;</span>.txt&#x27;</span>))</span><br><span class=\"line\">    </span><br><span class=\"line\">            content = [line.strip().split(<span class=\"string\">&#x27; &#x27;</span>) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> lines]</span><br><span class=\"line\">            bbox_names = [x[<span class=\"number\">0</span>] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> content]</span><br><span class=\"line\">            bboxes = [[<span class=\"built_in\">float</span>(info) <span class=\"keyword\">for</span> info <span class=\"keyword\">in</span> x[<span class=\"number\">4</span>:<span class=\"number\">8</span>]] <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> content]</span><br><span class=\"line\">    </span><br><span class=\"line\">            gt_bboxes = []</span><br><span class=\"line\">            gt_labels = []</span><br><span class=\"line\">            gt_bboxes_ignore = []</span><br><span class=\"line\">            gt_labels_ignore = []</span><br><span class=\"line\">    </span><br><span class=\"line\">            <span class=\"comment\"># filter &#x27;DontCare&#x27;</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> bbox_name, bbox <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(bbox_names, bboxes):</span><br><span class=\"line\">                <span class=\"keyword\">if</span> bbox_name <span class=\"keyword\">in</span> cat2label:</span><br><span class=\"line\">                    gt_labels.append(cat2label[bbox_name])</span><br><span class=\"line\">                    gt_bboxes.append(bbox)</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    gt_labels_ignore.append(-<span class=\"number\">1</span>)</span><br><span class=\"line\">                    gt_bboxes_ignore.append(bbox)</span><br><span class=\"line\"></span><br><span class=\"line\">            data_anno = <span class=\"built_in\">dict</span>(</span><br><span class=\"line\">                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-<span class=\"number\">1</span>, <span class=\"number\">4</span>),</span><br><span class=\"line\">                labels=np.array(gt_labels, dtype=np.long),</span><br><span class=\"line\">                bboxes_ignore=np.array(gt_bboxes_ignore,</span><br><span class=\"line\">                                       dtype=np.float32).reshape(-<span class=\"number\">1</span>, <span class=\"number\">4</span>),</span><br><span class=\"line\">                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))</span><br><span class=\"line\"></span><br><span class=\"line\">            data_info.update(ann=data_anno)</span><br><span class=\"line\">            data_infos.append(data_info)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> data_infos</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># mmdet 配置</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mmcv <span class=\"keyword\">import</span> Config</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.apis <span class=\"keyword\">import</span> set_random_seed</span><br><span class=\"line\"></span><br><span class=\"line\">cfg = Config.fromfile(<span class=\"string\">&#x27;configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># If we need to finetune a model based on a pre-trained detector, we need to use load_from to set the path of checkpoints.</span></span><br><span class=\"line\">cfg.load_from = <span class=\"string\">&#x27;checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Modify dataset type and path</span></span><br><span class=\"line\">cfg.dataset_type = <span class=\"string\">&#x27;KittiTinyDataset&#x27;</span></span><br><span class=\"line\">cfg.data_root = <span class=\"string\">&#x27;kitti_tiny/&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">cfg.data.test.<span class=\"built_in\">type</span> = <span class=\"string\">&#x27;KittiTinyDataset&#x27;</span></span><br><span class=\"line\">cfg.data.test.data_root = <span class=\"string\">&#x27;kitti_tiny/&#x27;</span></span><br><span class=\"line\">cfg.data.test.ann_file = <span class=\"string\">&#x27;train.txt&#x27;</span></span><br><span class=\"line\">cfg.data.test.img_prefix = <span class=\"string\">&#x27;training/image_2&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">cfg.data.train.<span class=\"built_in\">type</span> = <span class=\"string\">&#x27;KittiTinyDataset&#x27;</span></span><br><span class=\"line\">cfg.data.train.data_root = <span class=\"string\">&#x27;kitti_tiny/&#x27;</span></span><br><span class=\"line\">cfg.data.train.ann_file = <span class=\"string\">&#x27;train.txt&#x27;</span></span><br><span class=\"line\">cfg.data.train.img_prefix = <span class=\"string\">&#x27;training/image_2&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">cfg.data.val.<span class=\"built_in\">type</span> = <span class=\"string\">&#x27;KittiTinyDataset&#x27;</span></span><br><span class=\"line\">cfg.data.val.data_root = <span class=\"string\">&#x27;kitti_tiny/&#x27;</span></span><br><span class=\"line\">cfg.data.val.ann_file = <span class=\"string\">&#x27;val.txt&#x27;</span></span><br><span class=\"line\">cfg.data.val.img_prefix = <span class=\"string\">&#x27;training/image_2&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># modify num classes of the model in box head</span></span><br><span class=\"line\">cfg.model.roi_head.bbox_head.num_classes = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set up working dir to save files and logs.</span></span><br><span class=\"line\">cfg.work_dir = <span class=\"string\">&#x27;./tutorial_exps&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># The original learning rate (LR) is set for 8-GPU training.</span></span><br><span class=\"line\"><span class=\"comment\"># We divide it by 8 since we only use one GPU.</span></span><br><span class=\"line\">cfg.optimizer.lr = <span class=\"number\">0.02</span> / <span class=\"number\">8</span></span><br><span class=\"line\">cfg.lr_config.warmup = <span class=\"literal\">None</span></span><br><span class=\"line\">cfg.log_config.interval = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Change the evaluation metric since we use customized dataset.</span></span><br><span class=\"line\">cfg.evaluation.metric = <span class=\"string\">&#x27;mAP&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># We can set the evaluation interval to reduce the evaluation times</span></span><br><span class=\"line\">cfg.evaluation.interval = <span class=\"number\">12</span></span><br><span class=\"line\"><span class=\"comment\"># We can set the checkpoint saving interval to reduce the storage cost</span></span><br><span class=\"line\">cfg.checkpoint_config.interval = <span class=\"number\">12</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Set seed thus the results are more reproducible</span></span><br><span class=\"line\">cfg.seed = <span class=\"number\">0</span></span><br><span class=\"line\">set_random_seed(<span class=\"number\">0</span>, deterministic=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">cfg.device=<span class=\"string\">&#x27;cuda&#x27;</span></span><br><span class=\"line\">cfg.gpu_ids = <span class=\"built_in\">range</span>(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># We can also use tensorboard to log the training process</span></span><br><span class=\"line\">cfg.log_config.hooks = [</span><br><span class=\"line\">    <span class=\"built_in\">dict</span>(<span class=\"built_in\">type</span>=<span class=\"string\">&#x27;TextLoggerHook&#x27;</span>),</span><br><span class=\"line\">    <span class=\"built_in\">dict</span>(<span class=\"built_in\">type</span>=<span class=\"string\">&#x27;TensorboardLoggerHook&#x27;</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># We can initialize the logger for training and have a look at the final config used for training</span></span><br><span class=\"line\"><span class=\"comment\"># print(f&#x27;Config:\\n&#123;cfg.pretty_text&#125;&#x27;)</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Train a new detector</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.datasets <span class=\"keyword\">import</span> build_dataset</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.models <span class=\"keyword\">import</span> build_detector</span><br><span class=\"line\"><span class=\"keyword\">from</span> mmdet.apis <span class=\"keyword\">import</span> train_detector</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Build dataset</span></span><br><span class=\"line\">datasets = [build_dataset(cfg.data.train)]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Build the detector</span></span><br><span class=\"line\">model = build_detector(cfg.model)</span><br><span class=\"line\"><span class=\"comment\">#  build_detector( cfg.model, train_cfg=cfg.get(&#x27;train_cfg&#x27;), test_cfg=cfg.get(&#x27;test_cfg&#x27;))</span></span><br><span class=\"line\"><span class=\"comment\"># Add an attribute for visualization convenience</span></span><br><span class=\"line\">model.CLASSES = datasets[<span class=\"number\">0</span>].CLASSES</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create work_dir</span></span><br><span class=\"line\">mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 报错:AttributeError: &#x27;ConfigDict&#x27; object has no attribute &#x27;device&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># https://github.com/open-mmlab/mmdetection/issues/7901</span></span><br><span class=\"line\"><span class=\"comment\"># 在上面 cfg 添加了 cfg.device=&#x27;cuda&#x27;</span></span><br><span class=\"line\">train_detector(model, datasets, cfg, distributed=<span class=\"literal\">False</span>, validate=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<pre><code>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/content/mmdetection/mmdet/datasets/custom.py:180: UserWarning: CustomDataset does not support filtering empty gt images.\n  'CustomDataset does not support filtering empty gt images.')\n2022-06-07 16:41:00,736 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n2022-06-07 16:41:00,899 - mmdet - INFO - load checkpoint from local path: checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth\n2022-06-07 16:41:01,026 - mmdet - WARNING - The model and loaded state dict do not match exactly\n\nsize mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\nsize mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).\nsize mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\nsize mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).\n2022-06-07 16:41:01,035 - mmdet - INFO - Start running, host: root@7a73f7b358c4, work_dir: /content/mmdetection/tutorial_exps\n2022-06-07 16:41:01,037 - mmdet - INFO - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(NORMAL      ) NumClassCheckHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) StepLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n -------------------- \nafter_train_iter:\n(ABOVE_NORMAL) OptimizerHook                      \n(NORMAL      ) CheckpointHook                     \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nafter_train_epoch:\n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nbefore_val_epoch:\n(NORMAL      ) NumClassCheckHook                  \n(LOW         ) IterTimerHook                      \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nbefore_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_epoch:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \nafter_run:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n -------------------- \n2022-06-07 16:41:01,038 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n2022-06-07 16:41:01,040 - mmdet - INFO - Checkpoints will be saved to /content/mmdetection/tutorial_exps by HardDiskBackend.\n2022-06-07 16:41:17,697 - mmdet - INFO - Epoch [1][10/25]\tlr: 2.500e-03, eta: 0:04:25, time: 0.914, data_time: 0.236, memory: 2790, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0173, loss_cls: 0.5377, acc: 81.6211, loss_bbox: 0.3947, loss: 0.9764\n2022-06-07 16:41:21,039 - mmdet - INFO - Epoch [1][20/25]\tlr: 2.500e-03, eta: 0:02:54, time: 0.334, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0119, loss_cls: 0.1753, acc: 93.4570, loss_bbox: 0.3254, loss: 0.5275\n2022-06-07 16:41:28,575 - mmdet - INFO - Epoch [2][10/25]\tlr: 2.500e-03, eta: 0:02:16, time: 0.558, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0138, loss_cls: 0.1519, acc: 94.7656, loss_bbox: 0.2673, loss: 0.4497\n2022-06-07 16:41:31,944 - mmdet - INFO - Epoch [2][20/25]\tlr: 2.500e-03, eta: 0:02:01, time: 0.337, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0128, loss_rpn_bbox: 0.0127, loss_cls: 0.1325, acc: 94.9316, loss_bbox: 0.2084, loss: 0.3664\n2022-06-07 16:41:39,445 - mmdet - INFO - Epoch [3][10/25]\tlr: 2.500e-03, eta: 0:01:48, time: 0.569, data_time: 0.236, memory: 2790, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0102, loss_cls: 0.0972, acc: 96.2500, loss_bbox: 0.1600, loss: 0.2733\n2022-06-07 16:41:42,958 - mmdet - INFO - Epoch [3][20/25]\tlr: 2.500e-03, eta: 0:01:40, time: 0.349, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0133, loss_cls: 0.1474, acc: 94.4336, loss_bbox: 0.2652, loss: 0.4346\n2022-06-07 16:41:50,449 - mmdet - INFO - Epoch [4][10/25]\tlr: 2.500e-03, eta: 0:01:31, time: 0.562, data_time: 0.231, memory: 2790, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0134, loss_cls: 0.1168, acc: 95.5566, loss_bbox: 0.2201, loss: 0.3567\n2022-06-07 16:41:53,973 - mmdet - INFO - Epoch [4][20/25]\tlr: 2.500e-03, eta: 0:01:25, time: 0.353, data_time: 0.027, memory: 2790, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0117, loss_cls: 0.1179, acc: 95.5566, loss_bbox: 0.2133, loss: 0.3464\n2022-06-07 16:42:01,892 - mmdet - INFO - Epoch [5][10/25]\tlr: 2.500e-03, eta: 0:01:18, time: 0.595, data_time: 0.237, memory: 2790, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0092, loss_cls: 0.1003, acc: 96.2695, loss_bbox: 0.2087, loss: 0.3223\n2022-06-07 16:42:05,430 - mmdet - INFO - Epoch [5][20/25]\tlr: 2.500e-03, eta: 0:01:13, time: 0.352, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0107, loss_cls: 0.0903, acc: 96.7090, loss_bbox: 0.1845, loss: 0.2892\n2022-06-07 16:42:12,992 - mmdet - INFO - Epoch [6][10/25]\tlr: 2.500e-03, eta: 0:01:07, time: 0.567, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0082, loss_cls: 0.0786, acc: 97.1777, loss_bbox: 0.1799, loss: 0.2685\n2022-06-07 16:42:16,595 - mmdet - INFO - Epoch [6][20/25]\tlr: 2.500e-03, eta: 0:01:02, time: 0.363, data_time: 0.027, memory: 2790, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0100, loss_cls: 0.0891, acc: 96.5332, loss_bbox: 0.1856, loss: 0.2876\n2022-06-07 16:42:24,486 - mmdet - INFO - Epoch [7][10/25]\tlr: 2.500e-03, eta: 0:00:56, time: 0.591, data_time: 0.238, memory: 2790, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0096, loss_cls: 0.0904, acc: 96.6113, loss_bbox: 0.1740, loss: 0.2783\n2022-06-07 16:42:28,147 - mmdet - INFO - Epoch [7][20/25]\tlr: 2.500e-03, eta: 0:00:52, time: 0.364, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0116, loss_cls: 0.0926, acc: 96.1816, loss_bbox: 0.1774, loss: 0.2835\n2022-06-07 16:42:35,802 - mmdet - INFO - Epoch [8][10/25]\tlr: 2.500e-03, eta: 0:00:45, time: 0.572, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0091, loss_cls: 0.0777, acc: 96.8262, loss_bbox: 0.1420, loss: 0.2314\n2022-06-07 16:42:39,346 - mmdet - INFO - Epoch [8][20/25]\tlr: 2.500e-03, eta: 0:00:41, time: 0.354, data_time: 0.025, memory: 2790, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0082, loss_cls: 0.0777, acc: 97.2168, loss_bbox: 0.1590, loss: 0.2485\n2022-06-07 16:42:46,922 - mmdet - INFO - Epoch [9][10/25]\tlr: 2.500e-04, eta: 0:00:35, time: 0.565, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0082, loss_cls: 0.0658, acc: 97.4902, loss_bbox: 0.1351, loss: 0.2116\n2022-06-07 16:42:50,443 - mmdet - INFO - Epoch [9][20/25]\tlr: 2.500e-04, eta: 0:00:31, time: 0.352, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0066, loss_cls: 0.0571, acc: 97.8418, loss_bbox: 0.1133, loss: 0.1783\n2022-06-07 16:42:58,001 - mmdet - INFO - Epoch [10][10/25]\tlr: 2.500e-04, eta: 0:00:25, time: 0.567, data_time: 0.233, memory: 2790, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0081, loss_cls: 0.0678, acc: 97.3926, loss_bbox: 0.1332, loss: 0.2125\n2022-06-07 16:43:01,493 - mmdet - INFO - Epoch [10][20/25]\tlr: 2.500e-04, eta: 0:00:21, time: 0.350, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0059, loss_cls: 0.0594, acc: 97.6758, loss_bbox: 0.1294, loss: 0.1955\n2022-06-07 16:43:09,042 - mmdet - INFO - Epoch [11][10/25]\tlr: 2.500e-04, eta: 0:00:15, time: 0.567, data_time: 0.234, memory: 2790, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0069, loss_cls: 0.0638, acc: 97.6270, loss_bbox: 0.1217, loss: 0.1932\n2022-06-07 16:43:12,554 - mmdet - INFO - Epoch [11][20/25]\tlr: 2.500e-04, eta: 0:00:11, time: 0.351, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0073, loss_cls: 0.0571, acc: 97.8711, loss_bbox: 0.1212, loss: 0.1869\n2022-06-07 16:43:20,107 - mmdet - INFO - Epoch [12][10/25]\tlr: 2.500e-05, eta: 0:00:05, time: 0.567, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0061, loss_cls: 0.0563, acc: 97.9199, loss_bbox: 0.1246, loss: 0.1887\n2022-06-07 16:43:23,598 - mmdet - INFO - Epoch [12][20/25]\tlr: 2.500e-05, eta: 0:00:01, time: 0.349, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0048, loss_cls: 0.0511, acc: 97.9297, loss_bbox: 0.0946, loss: 0.1520\n2022-06-07 16:43:25,323 - mmdet - INFO - Saving checkpoint at 12 epochs\n\n\n[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 25/25, 9.8 task/s, elapsed: 3s, ETA:     0s\n---------------iou_thr: 0.5---------------\n\n\n2022-06-07 16:43:30,260 - mmdet - INFO - \n+------------+-----+------+--------+-------+\n| class      | gts | dets | recall | ap    |\n+------------+-----+------+--------+-------+\n| Car        | 62  | 133  | 0.984  | 0.888 |\n| Pedestrian | 13  | 40   | 0.846  | 0.768 |\n| Cyclist    | 7   | 50   | 0.571  | 0.114 |\n+------------+-----+------+--------+-------+\n| mAP        |     |      |        | 0.590 |\n+------------+-----+------+--------+-------+\n2022-06-07 16:43:30,268 - mmdet - INFO - Epoch(val) [12][25]\tAP50: 0.5900, mAP: 0.5899\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># load tensorboard in colab</span></span><br><span class=\"line\">%load_ext tensorboard</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># see curves in tensorboard</span></span><br><span class=\"line\">%tensorboard --logdir ./tutorial_exps</span><br></pre></td></tr></table></figure>\n<pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = mmcv.imread(<span class=\"string\">&#x27;kitti_tiny/training/image_2/000068.jpeg&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model.cfg = cfg</span><br><span class=\"line\">result = inference_detector(model, img)</span><br><span class=\"line\">show_result_pyplot(model, img, result)</span><br></pre></td></tr></table></figure>\n<p><img src=\"MM-Detection_files/MM-Detection_15_0.png\" alt=\"png\"></p>\n<p><a><img src=\"https://fastly.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"借物表-37\">借物表</h2>\n<p><a name='cite_note-1' href='#cite_ref-1'>[1]</a>: <a href=\"https://openbayes.com/console/wrh/containers/t93t3LTXlgU\">https://openbayes.com/console/wrh/containers/t93t3LTXlgU</a></p>\n<p><a name='cite_note-2' href='#cite_ref-2'>[2]</a>: <a href=\"https://zhuanlan.zhihu.com/p/163645165\">MMDetection 2.3 安装教程</a></p>\n<p><a name='cite_note-3' href='#cite_ref-3'>[3]</a>: <a href=\"https://mmdetection.readthedocs.io/zh_CN/latest/get_started.html#mmdetection\">https://mmdetection.readthedocs.io/zh_CN/latest/get_started.html#mmdetection</a></p>\n<p><a name='cite_note-4' href='#cite_ref-4'>[4]</a>: <a href=\"https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=8M5KUnX7Np3h\">https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=8M5KUnX7Np3h</a></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">",
            "tags": [
                "深度学习",
                "colab",
                "mmdetection"
            ]
        }
    ]
}