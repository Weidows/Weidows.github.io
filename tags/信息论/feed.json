{
    "version": "https://jsonfeed.org/version/1",
    "title": "⭐️齐下无贰⭐️ • All posts by \"信息论\" tag",
    "description": "May all the beauty be bless.✨",
    "home_page_url": "https://weidows.github.io",
    "items": [
        {
            "id": "https://weidows.github.io/post/public-post/notebook/ML/",
            "url": "https://weidows.github.io/post/public-post/notebook/ML/",
            "title": "👀Code-4-Machine-Learning",
            "date_published": "2022-04-11T07:07:22.000Z",
            "content_html": "<!--\n * @?: *********************************************************************\n * @Author: Weidows\n * @LastEditors: Weidows\n * @LastEditTime: 2022-02-23 02:28:46\n * @FilePath: \\Blog-private\\scaffolds\\post.md\n * @Description:\n * @!: *********************************************************************\n-->\n<h2 id=\"序\">序</h2>\n<p>此文为其他文章的代码部分:</p>\n<blockquote>\n<p><a href=\"../../../AI/AI\">🐊All-about-AI</a></p>\n</blockquote>\n<p>也提供了 notebook 形式: <a href=\"https://github.com/Weidows-projects/public-post/blob/main/notebook/ML/ML.ipynb\">代码地址</a></p>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"数据预处理方法\">数据预处理方法</h2>\n<h3 id=\"标准化-均值移除\">标准化-均值移除</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据预处理之：均值移除示例</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 样本数据</span></span><br><span class=\"line\">raw_samples = np.array([</span><br><span class=\"line\">    [<span class=\"number\">3.0</span>, -<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>],\\</span><br><span class=\"line\">    [<span class=\"number\">0.0</span>, <span class=\"number\">4.0</span>, <span class=\"number\">3.0</span>], \\</span><br><span class=\"line\">    [<span class=\"number\">1.0</span>, -<span class=\"number\">4.0</span>, <span class=\"number\">2.0</span>]]\\</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 求每列的平均值 axis=0为列, =1为行 不填就计算所有值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(raw_samples.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"comment\"># 求每列标准差</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(raw_samples.std(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">std_samples = raw_samples.copy()  <span class=\"comment\"># 复制样本数据</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> std_samples.T:  <span class=\"comment\"># .T为转置,遍历每列</span></span><br><span class=\"line\">    col_mean = col.mean()  <span class=\"comment\"># 计算平均数</span></span><br><span class=\"line\">    col_std = col.std()  <span class=\"comment\"># 求标准差</span></span><br><span class=\"line\">    col -= col_mean  <span class=\"comment\"># 减平均值</span></span><br><span class=\"line\">    col /= col_std  <span class=\"comment\"># 除标准差</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 均值无限趋近0,但可能不是0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(std_samples.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(std_samples.std(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># scale 标准移除,与上面功能相同</span></span><br><span class=\"line\">std_samples = sp.scale(raw_samples)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(std_samples.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(std_samples.std(axis=<span class=\"number\">0</span>))</span><br></pre></td></tr></table></figure>\n<pre><code>[ 1.33333333 -0.33333333  2.33333333]\n[1.24721913 3.29983165 0.47140452]\n[ 5.55111512e-17  0.00000000e+00 -2.96059473e-16]\n[1. 1. 1.]\n[ 5.55111512e-17  0.00000000e+00 -2.96059473e-16]\n[1. 1. 1.]\n</code></pre>\n<h3 id=\"范围缩放-2\">范围缩放</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数据预处理之：范围缩放</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 样本数据</span></span><br><span class=\"line\">raw_samples = np.array([</span><br><span class=\"line\">    [<span class=\"number\">1.0</span>, <span class=\"number\">2.0</span>, <span class=\"number\">3.0</span>],\\</span><br><span class=\"line\">    [<span class=\"number\">4.0</span>, <span class=\"number\">5.0</span>, <span class=\"number\">6.0</span>],\\</span><br><span class=\"line\">    [<span class=\"number\">7.0</span>, <span class=\"number\">8.0</span>, <span class=\"number\">9.0</span>]]).astype(<span class=\"string\">&quot;float64&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">mms_samples = raw_samples.copy()  <span class=\"comment\"># 复制样本数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> mms_samples.T:</span><br><span class=\"line\">    col_min = col.<span class=\"built_in\">min</span>()</span><br><span class=\"line\">    col_max = col.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">    col -= col_min</span><br><span class=\"line\">    col /= (col_max - col_min)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(mms_samples)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 根据给定范围创建一个范围缩放器对象</span></span><br><span class=\"line\"><span class=\"comment\"># 使用范围缩放器实现特征值范围缩放</span></span><br><span class=\"line\">mms_samples = sp.MinMaxScaler(feature_range=(<span class=\"number\">0</span>, <span class=\"number\">1</span>))\\</span><br><span class=\"line\">  .fit_transform(raw_samples)  <span class=\"comment\"># 缩放</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(mms_samples)</span><br></pre></td></tr></table></figure>\n<pre><code>[[0.  0.  0. ]\n [0.5 0.5 0.5]\n [1.  1.  1. ]]\n[[0.  0.  0. ]\n [0.5 0.5 0.5]\n [1.  1.  1. ]]\n</code></pre>\n<h3 id=\"归一化-2\">归一化</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 样本数据</span></span><br><span class=\"line\">raw_samples = np.array([</span><br><span class=\"line\">    [<span class=\"number\">10.0</span>, <span class=\"number\">20.0</span>, <span class=\"number\">5.0</span>],\\</span><br><span class=\"line\">    [<span class=\"number\">8.0</span>, <span class=\"number\">10.0</span>, <span class=\"number\">1.0</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">nor_samples = raw_samples.copy()</span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> nor_samples:</span><br><span class=\"line\">    row /= <span class=\"built_in\">abs</span>(row).<span class=\"built_in\">sum</span>()  <span class=\"comment\"># 先对行求绝对值，再求和，再除以绝对值之和</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(nor_samples)  <span class=\"comment\"># 打印结果</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># norm=l1  /=绝对值之和</span></span><br><span class=\"line\"><span class=\"comment\"># norm=l2  /=平方之和</span></span><br><span class=\"line\">nor_samples = sp.normalize(raw_samples.copy(), norm=<span class=\"string\">&#x27;l1&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(nor_samples)  <span class=\"comment\"># 打印结果</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[[0.28571429 0.57142857 0.14285714]\n [0.42105263 0.52631579 0.05263158]]\n[[0.28571429 0.57142857 0.14285714]\n [0.42105263 0.52631579 0.05263158]]\n</code></pre>\n<h3 id=\"二值化-2\">二值化</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 二值化</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\">raw_samples = np.array([[<span class=\"number\">65.5</span>, <span class=\"number\">89.0</span>, <span class=\"number\">73.0</span>],\\</span><br><span class=\"line\">                        [<span class=\"number\">55.0</span>, <span class=\"number\">99.0</span>, <span class=\"number\">98.5</span>],\\</span><br><span class=\"line\">                        [<span class=\"number\">45.0</span>, <span class=\"number\">22.5</span>, <span class=\"number\">60.0</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">bin_samples = raw_samples.copy()  <span class=\"comment\"># 复制数组</span></span><br><span class=\"line\"><span class=\"comment\"># 生成掩码数组</span></span><br><span class=\"line\">mask1 = bin_samples &lt; <span class=\"number\">60</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(mask1)</span><br><span class=\"line\">mask2 = bin_samples &gt;= <span class=\"number\">60</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过掩码进行二值化处理 (只转换True的位置)</span></span><br><span class=\"line\">bin_samples[mask1] = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(bin_samples)</span><br><span class=\"line\">bin_samples[mask2] = <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(bin_samples)  <span class=\"comment\"># 打印结果</span></span><br><span class=\"line\"></span><br><span class=\"line\">bin_transformer = sp.Binarizer(threshold=<span class=\"number\">60</span> - <span class=\"number\">1</span>)  <span class=\"comment\"># 创建二值化对象(注意边界值)</span></span><br><span class=\"line\">bin_samples = bin_transformer.transform(raw_samples.copy())  <span class=\"comment\"># 二值化预处理</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(bin_samples)</span><br></pre></td></tr></table></figure>\n<pre><code>[[False False False]\n [ True False False]\n [ True  True False]]\n[[65.5 89.  73. ]\n [ 0.  99.  98.5]\n [ 0.   0.  60. ]]\n[[1. 1. 1.]\n [0. 1. 1.]\n [0. 0. 1.]]\n[[1. 1. 1.]\n [0. 1. 1.]\n [0. 0. 1.]]\n</code></pre>\n<h3 id=\"独热编码示例\">独热编码示例</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\">raw_samples = np.array([[<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">2</span>],\\</span><br><span class=\"line\">                        [<span class=\"number\">7</span>, <span class=\"number\">5</span>, <span class=\"number\">4</span>],\\</span><br><span class=\"line\">                        [<span class=\"number\">1</span>, <span class=\"number\">8</span>, <span class=\"number\">6</span>],\\</span><br><span class=\"line\">                        [<span class=\"number\">7</span>, <span class=\"number\">3</span>, <span class=\"number\">9</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">one_hot_encoder = sp.OneHotEncoder(</span><br><span class=\"line\">    sparse=<span class=\"literal\">False</span>,  <span class=\"comment\"># 是否采用稀疏格式</span></span><br><span class=\"line\">    dtype=<span class=\"string\">&quot;int32&quot;</span>,</span><br><span class=\"line\">    categories=<span class=\"string\">&quot;auto&quot;</span>)  <span class=\"comment\"># 自动编码</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 执行独热编码</span></span><br><span class=\"line\">oh_samples = one_hot_encoder.fit_transform(raw_samples.copy())</span><br><span class=\"line\"><span class=\"built_in\">print</span>(oh_samples)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(one_hot_encoder.inverse_transform(oh_samples))  <span class=\"comment\"># 解码</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[[1 0 1 0 0 1 0 0 0]\n [0 1 0 1 0 0 1 0 0]\n [1 0 0 0 1 0 0 1 0]\n [0 1 1 0 0 0 0 0 1]]\n[[1 3 2]\n [7 5 4]\n [1 8 6]\n [7 3 9]]\n</code></pre>\n<h3 id=\"标签编码-2\">标签编码</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\">raw_samples = np.array([<span class=\"string\">&#x27;audi&#x27;</span>, <span class=\"string\">&#x27;ford&#x27;</span>, <span class=\"string\">&#x27;audi&#x27;</span>, <span class=\"string\">&#x27;bmw&#x27;</span>, <span class=\"string\">&#x27;ford&#x27;</span>, <span class=\"string\">&#x27;bmw&#x27;</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">lb_encoder = sp.LabelEncoder()  <span class=\"comment\"># 定义标签编码对象</span></span><br><span class=\"line\">lb_samples = lb_encoder.fit_transform(raw_samples.copy())  <span class=\"comment\"># 执行标签编码</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(lb_samples)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(lb_encoder.inverse_transform(lb_samples))  <span class=\"comment\"># 逆向转换</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>[0 2 0 1 2 1]\n['audi' 'ford' 'audi' 'bmw' 'ford' 'bmw']\n</code></pre>\n<h2 id=\"基本问题-2\">基本问题</h2>\n<h3 id=\"回归问题-2\">回归问题</h3>\n<h4 id=\"线性回归-2\">线性回归</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> axes3d</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.preprocessing <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练数据集</span></span><br><span class=\"line\">train_x = np.array([<span class=\"number\">0.5</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.8</span>, <span class=\"number\">1.1</span>, <span class=\"number\">1.4</span>])  <span class=\"comment\"># 输入集</span></span><br><span class=\"line\">train_y = np.array([<span class=\"number\">5.0</span>, <span class=\"number\">5.5</span>, <span class=\"number\">6.0</span>, <span class=\"number\">6.8</span>, <span class=\"number\">7.0</span>])  <span class=\"comment\"># 输出集</span></span><br><span class=\"line\"></span><br><span class=\"line\">n_epochs = <span class=\"number\">30</span>  <span class=\"comment\"># 迭代次数</span></span><br><span class=\"line\">l_rate = <span class=\"number\">0.01</span>  <span class=\"comment\"># 学习率</span></span><br><span class=\"line\">epochs = []  <span class=\"comment\"># 记录迭代次数</span></span><br><span class=\"line\">losses = []  <span class=\"comment\"># 记录损失值</span></span><br><span class=\"line\"></span><br><span class=\"line\">w0, w1 = [<span class=\"number\">1</span>], [<span class=\"number\">1</span>]  <span class=\"comment\"># 模型初始值</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, n_epochs + <span class=\"number\">1</span>):</span><br><span class=\"line\">    epochs.append(i)  <span class=\"comment\"># 记录第几次迭代</span></span><br><span class=\"line\"></span><br><span class=\"line\">    y = w0[-<span class=\"number\">1</span>] + w1[-<span class=\"number\">1</span>] * train_x  <span class=\"comment\"># 取出最新的w0,w1计算线性方程输出</span></span><br><span class=\"line\">    <span class=\"comment\"># 损失函数(均方差)</span></span><br><span class=\"line\">    loss = (((train_y - y)**<span class=\"number\">2</span>).<span class=\"built_in\">sum</span>()) / <span class=\"number\">2</span></span><br><span class=\"line\">    losses.append(loss)  <span class=\"comment\"># 记录每次迭代的损失值</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;%d: w0=%f, w1=%f, loss=%f&quot;</span> % (i, w0[-<span class=\"number\">1</span>], w1[-<span class=\"number\">1</span>], loss))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 计算w0,w1的偏导数</span></span><br><span class=\"line\">    d0 = -(train_y - y).<span class=\"built_in\">sum</span>()</span><br><span class=\"line\">    d1 = -(train_x * (train_y - y)).<span class=\"built_in\">sum</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 更新w0,w1</span></span><br><span class=\"line\">    w0.append(w0[-<span class=\"number\">1</span>] - (d0 * l_rate))</span><br><span class=\"line\">    w1.append(w1[-<span class=\"number\">1</span>] - (d1 * l_rate))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###################### 训练过程可视化 ######################</span></span><br><span class=\"line\"><span class=\"comment\">## 损失函数收敛过程</span></span><br><span class=\"line\">w0 = np.array(w0[:-<span class=\"number\">1</span>])</span><br><span class=\"line\">w1 = np.array(w1[:-<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">mp.figure(<span class=\"string\">&quot;Losses&quot;</span>, facecolor=<span class=\"string\">&quot;lightgray&quot;</span>)  <span class=\"comment\"># 创建一个窗体</span></span><br><span class=\"line\">mp.title(<span class=\"string\">&quot;epoch&quot;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&quot;loss&quot;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.grid(linestyle=<span class=\"string\">&quot;:&quot;</span>)  <span class=\"comment\"># 网格线：虚线</span></span><br><span class=\"line\">mp.plot(epochs, losses, c=<span class=\"string\">&quot;blue&quot;</span>, label=<span class=\"string\">&quot;loss&quot;</span>)</span><br><span class=\"line\">mp.legend()  <span class=\"comment\"># 图例</span></span><br><span class=\"line\">mp.tight_layout()  <span class=\"comment\"># 紧凑格式</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## 显示模型直线</span></span><br><span class=\"line\">pred_y = w0[-<span class=\"number\">1</span>] + w1[-<span class=\"number\">1</span>] * train_x  <span class=\"comment\"># 根据x预测y</span></span><br><span class=\"line\">mp.figure(<span class=\"string\">&quot;Linear Regression&quot;</span>, facecolor=<span class=\"string\">&quot;lightgray&quot;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&quot;Linear Regression&quot;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.xlabel(<span class=\"string\">&quot;x&quot;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&quot;y&quot;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.grid(linestyle=<span class=\"string\">&quot;:&quot;</span>)</span><br><span class=\"line\">mp.scatter(train_x, train_y, c=<span class=\"string\">&quot;blue&quot;</span>, label=<span class=\"string\">&quot;Traing&quot;</span>)  <span class=\"comment\"># 绘制样本散点图</span></span><br><span class=\"line\">mp.plot(train_x, pred_y, c=<span class=\"string\">&quot;red&quot;</span>, label=<span class=\"string\">&quot;Regression&quot;</span>)</span><br><span class=\"line\">mp.legend()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 显示梯度下降过程(复制粘贴即可，不需要编写)</span></span><br><span class=\"line\"><span class=\"comment\"># 计算损失函数曲面上的点 loss = f(w0, w1)</span></span><br><span class=\"line\">arr1 = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">10</span>, <span class=\"number\">500</span>)  <span class=\"comment\"># 0~9间产生500个元素的均匀列表</span></span><br><span class=\"line\">arr2 = np.linspace(<span class=\"number\">0</span>, <span class=\"number\">3.5</span>, <span class=\"number\">500</span>)  <span class=\"comment\"># 0~3.5间产生500个元素的均匀列表</span></span><br><span class=\"line\"></span><br><span class=\"line\">grid_w0, grid_w1 = np.meshgrid(arr1, arr2)  <span class=\"comment\"># 产生二维矩阵</span></span><br><span class=\"line\"></span><br><span class=\"line\">flat_w0, flat_w1 = grid_w0.ravel(), grid_w1.ravel()  <span class=\"comment\"># 二维矩阵扁平化</span></span><br><span class=\"line\">loss_metrix = train_y.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)  <span class=\"comment\"># 生成误差矩阵（-1,1）表示自动计算维度</span></span><br><span class=\"line\">outer = np.outer(train_x, flat_w1)  <span class=\"comment\"># 求外积（train_x和flat_w1元素两两相乘的新矩阵）</span></span><br><span class=\"line\"><span class=\"comment\"># 计算损失：((w0 + w1*x - y)**2)/2</span></span><br><span class=\"line\">flat_loss = (((flat_w0 + outer - loss_metrix) ** <span class=\"number\">2</span>).<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)) / <span class=\"number\">2</span></span><br><span class=\"line\">grid_loss = flat_loss.reshape(grid_w0.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.figure(<span class=\"string\">&#x27;Loss Function&#x27;</span>)</span><br><span class=\"line\">ax = mp.axes(projection=<span class=\"string\">&#x27;3d&#x27;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&#x27;Loss Function&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;w0&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;w1&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">&#x27;loss&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">ax.plot_surface(grid_w0, grid_w1, grid_loss, rstride=<span class=\"number\">10</span>, cstride=<span class=\"number\">10</span>, cmap=<span class=\"string\">&#x27;jet&#x27;</span>)</span><br><span class=\"line\">ax.plot(w0, w1, losses, <span class=\"string\">&#x27;o-&#x27;</span>, c=<span class=\"string\">&#x27;orangered&#x27;</span>, label=<span class=\"string\">&#x27;BGD&#x27;</span>, zorder=<span class=\"number\">5</span>)</span><br><span class=\"line\">mp.legend(loc=<span class=\"string\">&#x27;lower left&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.show()</span><br></pre></td></tr></table></figure>\n<pre><code>1: w0=1.000000, w1=1.000000, loss=44.175000\n2: w0=1.209000, w1=1.190600, loss=36.538828\n3: w0=1.399164, w1=1.363579, loss=30.231687\n4: w0=1.572208, w1=1.520546, loss=25.022227\n5: w0=1.729693, w1=1.662961, loss=20.719373\n6: w0=1.873039, w1=1.792151, loss=17.165309\n7: w0=2.003532, w1=1.909325, loss=14.229691\n8: w0=2.122345, w1=2.015577, loss=11.804865\n9: w0=2.230542, w1=2.111905, loss=9.801916\n10: w0=2.329091, w1=2.199215, loss=8.147408\n11: w0=2.418871, w1=2.278330, loss=6.780688\n12: w0=2.500681, w1=2.349997, loss=5.651660\n13: w0=2.575247, w1=2.414898, loss=4.718950\n14: w0=2.643230, w1=2.473648, loss=3.948384\n15: w0=2.705228, w1=2.526811, loss=3.311740\n16: w0=2.761786, w1=2.574896, loss=2.785706\n17: w0=2.813402, w1=2.618367, loss=2.351029\n18: w0=2.860524, w1=2.657645, loss=1.991807\n19: w0=2.903561, w1=2.693114, loss=1.694907\n20: w0=2.942886, w1=2.725122, loss=1.449482\n21: w0=2.978836, w1=2.753985, loss=1.246572\n22: w0=3.011719, w1=2.779990, loss=1.078777\n23: w0=3.041814, w1=2.803399, loss=0.939987\n24: w0=3.069373, w1=2.824449, loss=0.825153\n25: w0=3.094629, w1=2.843355, loss=0.730107\n26: w0=3.117790, w1=2.860315, loss=0.651405\n27: w0=3.139046, w1=2.875507, loss=0.586204\n28: w0=3.158572, w1=2.889091, loss=0.532154\n29: w0=3.176523, w1=2.901216, loss=0.487315\n30: w0=3.193044, w1=2.912016, loss=0.450086\n</code></pre>\n<p><img src=\"ML_files/ML_13_1.png\" alt=\"png\"></p>\n<p><img src=\"ML_files/ML_13_2.png\" alt=\"png\"></p>\n<p><img src=\"ML_files/ML_13_3.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 利用LinearRegression实现线性回归</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.linear_model <span class=\"keyword\">as</span> lm  <span class=\"comment\"># 线性模型# 线性模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.metrics <span class=\"keyword\">as</span> sm  <span class=\"comment\"># 模型性能评价模块</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"></span><br><span class=\"line\">train_x = np.array([[<span class=\"number\">0.5</span>], [<span class=\"number\">0.6</span>], [<span class=\"number\">0.8</span>], [<span class=\"number\">1.1</span>], [<span class=\"number\">1.4</span>]])  <span class=\"comment\"># 输入集</span></span><br><span class=\"line\">train_y = np.array([<span class=\"number\">5.0</span>, <span class=\"number\">5.5</span>, <span class=\"number\">6.0</span>, <span class=\"number\">6.8</span>, <span class=\"number\">7.0</span>])  <span class=\"comment\"># 输出集</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建线性回归器</span></span><br><span class=\"line\">line_model = lm.LinearRegression()</span><br><span class=\"line\"><span class=\"comment\"># 用已知输入、输出数据集训练回归器</span></span><br><span class=\"line\">line_model.fit(train_x, train_y)</span><br><span class=\"line\"><span class=\"comment\"># 根据训练模型预测输出</span></span><br><span class=\"line\">pred_y = line_model.predict(train_x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;coef_:&quot;</span>, line_model.coef_)  <span class=\"comment\"># 系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;intercept_:&quot;</span>, line_model.intercept_)  <span class=\"comment\"># 截距</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化回归曲线</span></span><br><span class=\"line\">mp.figure(<span class=\"string\">&#x27;Linear Regression&#x27;</span>, facecolor=<span class=\"string\">&#x27;lightgray&#x27;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&#x27;Linear Regression&#x27;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.xlabel(<span class=\"string\">&#x27;x&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&#x27;y&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.tick_params(labelsize=<span class=\"number\">10</span>)</span><br><span class=\"line\">mp.grid(linestyle=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制样本点</span></span><br><span class=\"line\">mp.scatter(train_x, train_y, c=<span class=\"string\">&#x27;blue&#x27;</span>, alpha=<span class=\"number\">0.8</span>, s=<span class=\"number\">60</span>, label=<span class=\"string\">&#x27;Sample&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制拟合直线</span></span><br><span class=\"line\">mp.plot(</span><br><span class=\"line\">    train_x,  <span class=\"comment\"># x坐标数据</span></span><br><span class=\"line\">    pred_y,  <span class=\"comment\"># y坐标数据</span></span><br><span class=\"line\">    c=<span class=\"string\">&#x27;orangered&#x27;</span>,</span><br><span class=\"line\">    label=<span class=\"string\">&#x27;Regression Line&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.legend()  <span class=\"comment\"># 左上角的图例</span></span><br><span class=\"line\">mp.show()</span><br></pre></td></tr></table></figure>\n<pre><code>coef_: [2.2189781]\nintercept_: 4.107299270072994\n</code></pre>\n<p><img src=\"ML_files/ML_14_1.png\" alt=\"png\"></p>\n<h3 id=\"决策树-随机森林-2\">决策树-随机森林</h3>\n<h4 id=\"决策树分类\">决策树分类</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> LabelEncoder</span><br><span class=\"line\"><span class=\"keyword\">import</span> pydotplus</span><br><span class=\"line\"></span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;simHei&#x27;</span>]</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">iris_feature_E = <span class=\"string\">&#x27;sepal length&#x27;</span>, <span class=\"string\">&#x27;sepal width&#x27;</span>, <span class=\"string\">&#x27;petal length&#x27;</span>, <span class=\"string\">&#x27;petal width&#x27;</span></span><br><span class=\"line\">iris_feature = <span class=\"string\">&#x27;花萼长度&#x27;</span>, <span class=\"string\">&#x27;花萼宽度&#x27;</span>, <span class=\"string\">&#x27;花瓣长度&#x27;</span>, <span class=\"string\">&#x27;花瓣宽度&#x27;</span></span><br><span class=\"line\">iris_class = <span class=\"string\">&#x27;Iris-setosa&#x27;</span>, <span class=\"string\">&#x27;Iris-versicolor&#x27;</span>, <span class=\"string\">&#x27;Iris-virginica&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">path = <span class=\"string\">&#x27;iris_classification/iris.data&#x27;</span>  <span class=\"comment\"># 数据文件路径</span></span><br><span class=\"line\">data = pd.read_csv(path, header=<span class=\"literal\">None</span>)</span><br><span class=\"line\">x = data[<span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">4</span>))]</span><br><span class=\"line\"><span class=\"comment\"># y = pd.Categorical(data[4]).codes</span></span><br><span class=\"line\">y = LabelEncoder().fit_transform(data[<span class=\"number\">4</span>])</span><br><span class=\"line\"><span class=\"comment\"># 为了可视化，仅使用前两列特征</span></span><br><span class=\"line\">x = x[[<span class=\"number\">0</span>, <span class=\"number\">1</span>]]</span><br><span class=\"line\"><span class=\"comment\"># x = x.iloc[:, :2]</span></span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(x,</span><br><span class=\"line\">                                                    y,</span><br><span class=\"line\">                                                    test_size=<span class=\"number\">0.3</span>,</span><br><span class=\"line\">                                                    random_state=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 决策树参数估计</span></span><br><span class=\"line\"><span class=\"comment\"># min_samples_split = 10：如果该结点包含的样本数目大于10，则(有可能)对其分支</span></span><br><span class=\"line\"><span class=\"comment\"># min_samples_leaf = 10：若将某结点分支后，得到的每个子结点样本数目都大于10，则完成分支；否则，不进行分支</span></span><br><span class=\"line\">model = DecisionTreeClassifier(criterion=<span class=\"string\">&#x27;entropy&#x27;</span>)</span><br><span class=\"line\">model.fit(x_train, y_train)</span><br><span class=\"line\">y_train_pred = model.predict(x_train)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;训练集正确率：&#x27;</span>, accuracy_score(y_train, y_train_pred))</span><br><span class=\"line\">y_test_hat = model.predict(x_test)  <span class=\"comment\"># 测试数据</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;测试集正确率：&#x27;</span>, accuracy_score(y_test, y_test_hat))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存</span></span><br><span class=\"line\"><span class=\"comment\"># dot -Tpng my.dot -o my.png</span></span><br><span class=\"line\"><span class=\"comment\"># 1、输出</span></span><br><span class=\"line\"><span class=\"comment\"># with open(&#x27;iris.dot&#x27;, &#x27;w&#x27;) as f:</span></span><br><span class=\"line\"><span class=\"comment\">#     tree.export_graphviz(model, out_file=f, feature_names=iris_feature_E[0:2], class_names=iris_class,</span></span><br><span class=\"line\"><span class=\"comment\">#                          filled=True, rounded=True, special_characters=True)</span></span><br><span class=\"line\">tree.export_graphviz(model,</span><br><span class=\"line\">                     out_file=<span class=\"string\">&#x27;iris_classification/iris.dot&#x27;</span>,</span><br><span class=\"line\">                     feature_names=iris_feature_E[<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                     class_names=iris_class,</span><br><span class=\"line\">                     filled=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                     rounded=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                     special_characters=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\"># 2、给定文件名</span></span><br><span class=\"line\"><span class=\"comment\"># tree.export_graphviz(model, out_file=&#x27;iris.dot&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># tree.export_graphviz(model, out_file=&#x27;iris.dot&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># 3、输出为pdf格式</span></span><br><span class=\"line\">dot_data = tree.export_graphviz(model,</span><br><span class=\"line\">                                out_file=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                                feature_names=iris_feature_E[<span class=\"number\">0</span>:<span class=\"number\">2</span>],</span><br><span class=\"line\">                                class_names=iris_class,</span><br><span class=\"line\">                                filled=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                                rounded=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                                special_characters=<span class=\"literal\">True</span>)</span><br><span class=\"line\">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class=\"line\">graph.write_pdf(<span class=\"string\">&#x27;iris_classification/iris.pdf&#x27;</span>)</span><br><span class=\"line\">f = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;iris_classification/iris.png&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>)</span><br><span class=\"line\">f.write(graph.create_png())</span><br><span class=\"line\">f.close()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">N, M = <span class=\"number\">50</span>, <span class=\"number\">50</span>  <span class=\"comment\"># 横纵各采样多少个值</span></span><br><span class=\"line\">x1_min, x2_min = x.<span class=\"built_in\">min</span>()</span><br><span class=\"line\">x1_max, x2_max = x.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">t1 = np.linspace(x1_min, x1_max, N)</span><br><span class=\"line\">t2 = np.linspace(x2_min, x2_max, M)</span><br><span class=\"line\">x1, x2 = np.meshgrid(t1, t2)  <span class=\"comment\"># 生成网格采样点</span></span><br><span class=\"line\">x_show = np.stack((x1.flat, x2.flat), axis=<span class=\"number\">1</span>)  <span class=\"comment\"># 测试点</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_show.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;x_show = \\n&#x27;</span>, x_show)</span><br><span class=\"line\"></span><br><span class=\"line\">cm_light = mpl.colors.ListedColormap([<span class=\"string\">&#x27;#A0FFA0&#x27;</span>, <span class=\"string\">&#x27;#FFA0A0&#x27;</span>, <span class=\"string\">&#x27;#A0A0FF&#x27;</span>])</span><br><span class=\"line\">cm_dark = mpl.colors.ListedColormap([<span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>])</span><br><span class=\"line\">y_show_hat = model.predict(x_show)  <span class=\"comment\"># 预测值</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_show_hat.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_show_hat)</span><br><span class=\"line\">y_show_hat = y_show_hat.reshape(x1.shape)  <span class=\"comment\"># 使之与输入的形状相同</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_show_hat)</span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.pcolormesh(x1, x2, y_show_hat, cmap=cm_light, shading=<span class=\"string\">&#x27;auto&#x27;</span>)  <span class=\"comment\"># 预测值的显示</span></span><br><span class=\"line\">plt.scatter(x_test[<span class=\"number\">0</span>],</span><br><span class=\"line\">            x_test[<span class=\"number\">1</span>],</span><br><span class=\"line\">            c=y_test.ravel(),</span><br><span class=\"line\">            edgecolors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">            s=<span class=\"number\">100</span>,</span><br><span class=\"line\">            zorder=<span class=\"number\">10</span>,</span><br><span class=\"line\">            cmap=cm_dark,</span><br><span class=\"line\">            marker=<span class=\"string\">&#x27;*&#x27;</span>)  <span class=\"comment\"># 测试数据</span></span><br><span class=\"line\">plt.scatter(x[<span class=\"number\">0</span>], x[<span class=\"number\">1</span>], c=y.ravel(), edgecolors=<span class=\"string\">&#x27;k&#x27;</span>, s=<span class=\"number\">20</span>,</span><br><span class=\"line\">            cmap=cm_dark)  <span class=\"comment\"># 全部数据</span></span><br><span class=\"line\">plt.xlabel(iris_feature[<span class=\"number\">0</span>], fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.ylabel(iris_feature[<span class=\"number\">1</span>], fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.xlim(x1_min, x1_max)</span><br><span class=\"line\">plt.ylim(x2_min, x2_max)</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>, color=<span class=\"string\">&#x27;#606060&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;鸢尾花数据的决策树分类&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练集上的预测结果</span></span><br><span class=\"line\">y_test = y_test.reshape(-<span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_test_hat)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_test)</span><br><span class=\"line\">result = (y_test_hat == y_test)  <span class=\"comment\"># True则预测正确，False则预测错误</span></span><br><span class=\"line\">acc = np.mean(result)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;准确度: %.2f%%&#x27;</span> % (<span class=\"number\">100</span> * acc))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 过拟合：错误率</span></span><br><span class=\"line\">depth = np.arange(<span class=\"number\">1</span>, <span class=\"number\">15</span>)</span><br><span class=\"line\">err_train_list = []</span><br><span class=\"line\">err_test_list = []</span><br><span class=\"line\">clf = DecisionTreeClassifier(criterion=<span class=\"string\">&#x27;entropy&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> d <span class=\"keyword\">in</span> depth:</span><br><span class=\"line\">    clf.set_params(max_depth=d)</span><br><span class=\"line\">    clf.fit(x_train, y_train)</span><br><span class=\"line\">    y_train_pred = clf.predict(x_train)</span><br><span class=\"line\">    err_train = <span class=\"number\">1</span> - accuracy_score(y_train, y_train_pred)</span><br><span class=\"line\">    err_train_list.append(err_train)</span><br><span class=\"line\">    y_test_pred = clf.predict(x_test)</span><br><span class=\"line\">    err_test = <span class=\"number\">1</span> - accuracy_score(y_test, y_test_pred)</span><br><span class=\"line\">    err_test_list.append(err_test)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(d, <span class=\"string\">&#x27; 测试集错误率: %.2f%%&#x27;</span> % (<span class=\"number\">100</span> * err_test))</span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.plot(depth,</span><br><span class=\"line\">         err_test_list,</span><br><span class=\"line\">         <span class=\"string\">&#x27;ro-&#x27;</span>,</span><br><span class=\"line\">         markeredgecolor=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">         lw=<span class=\"number\">2</span>,</span><br><span class=\"line\">         label=<span class=\"string\">&#x27;测试集错误率&#x27;</span>)</span><br><span class=\"line\">plt.plot(depth,</span><br><span class=\"line\">         err_train_list,</span><br><span class=\"line\">         <span class=\"string\">&#x27;go-&#x27;</span>,</span><br><span class=\"line\">         markeredgecolor=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">         lw=<span class=\"number\">2</span>,</span><br><span class=\"line\">         label=<span class=\"string\">&#x27;训练集错误率&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;决策树深度&#x27;</span>, fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;错误率&#x27;</span>, fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;lower left&#x27;</span>, fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;决策树深度与过拟合&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>, color=<span class=\"string\">&#x27;#606060&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>训练集正确率： 0.9523809523809523\n测试集正确率： 0.6222222222222222\n(2500, 2)\nx_show = \n [[4.3        2.        ]\n [4.37346939 2.        ]\n [4.44693878 2.        ]\n ...\n [7.75306122 4.4       ]\n [7.82653061 4.4       ]\n [7.9        4.4       ]]\n(2500,)\n[0 0 0 ... 2 2 2]\n[[0 0 0 ... 1 1 1]\n [0 0 0 ... 1 1 1]\n [0 0 0 ... 1 1 1]\n ...\n [0 0 0 ... 2 2 2]\n [0 0 0 ... 2 2 2]\n [0 0 0 ... 2 2 2]]\n</code></pre>\n<p><img src=\"ML_files/ML_16_1.png\" alt=\"png\"></p>\n<pre><code>[0 1 2 0 2 2 1 0 0 2 2 0 1 2 1 0 2 1 0 0 1 0 2 0 2 1 0 0 1 1 2 2 2 2 1 0 1\n 0 2 1 2 0 1 1 1]\n[0 1 1 0 2 1 2 0 0 2 1 0 2 1 1 0 1 1 0 0 1 1 1 0 2 1 0 0 1 2 1 2 1 2 2 0 1\n 0 1 2 2 0 2 2 1]\n准确度: 62.22%\n1  测试集错误率: 44.44%\n2  测试集错误率: 40.00%\n3  测试集错误率: 20.00%\n4  测试集错误率: 24.44%\n5  测试集错误率: 24.44%\n6  测试集错误率: 28.89%\n7  测试集错误率: 37.78%\n8  测试集错误率: 40.00%\n9  测试集错误率: 37.78%\n10  测试集错误率: 40.00%\n11  测试集错误率: 37.78%\n12  测试集错误率: 37.78%\n13  测试集错误率: 40.00%\n14  测试集错误率: 37.78%\n</code></pre>\n<p><img src=\"ML_files/ML_16_3.png\" alt=\"png\"></p>\n<h4 id=\"随机森林-3\">随机森林</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">iris_feature = <span class=\"string\">u&#x27;花萼长度&#x27;</span>, <span class=\"string\">u&#x27;花萼宽度&#x27;</span>, <span class=\"string\">u&#x27;花瓣长度&#x27;</span>, <span class=\"string\">u&#x27;花瓣宽度&#x27;</span></span><br><span class=\"line\">path = <span class=\"string\">&#x27;iris_classification/iris.data&#x27;</span>  <span class=\"comment\"># 数据文件路径</span></span><br><span class=\"line\">data = pd.read_csv(path, header=<span class=\"literal\">None</span>)</span><br><span class=\"line\">x_prime = data[<span class=\"built_in\">list</span>(<span class=\"built_in\">range</span>(<span class=\"number\">4</span>))]</span><br><span class=\"line\">y = pd.Categorical(data[<span class=\"number\">4</span>]).codes</span><br><span class=\"line\">x_prime_train, x_prime_test, y_train, y_test = train_test_split(</span><br><span class=\"line\">    x_prime, y, train_size=<span class=\"number\">0.7</span>, random_state=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">feature_pairs = [[<span class=\"number\">0</span>, <span class=\"number\">1</span>], [<span class=\"number\">0</span>, <span class=\"number\">2</span>], [<span class=\"number\">0</span>, <span class=\"number\">3</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">3</span>], [<span class=\"number\">2</span>, <span class=\"number\">3</span>]]</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">6</span>), facecolor=<span class=\"string\">&#x27;#FFFFFF&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, pair <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(feature_pairs):</span><br><span class=\"line\">    <span class=\"comment\"># 准备数据</span></span><br><span class=\"line\">    x_train = x_prime_train[pair]</span><br><span class=\"line\">    x_test = x_prime_test[pair]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 决策树学习</span></span><br><span class=\"line\">    model = DecisionTreeClassifier(criterion=<span class=\"string\">&#x27;entropy&#x27;</span>, min_samples_leaf=<span class=\"number\">3</span>)</span><br><span class=\"line\">    model.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\">    N, M = <span class=\"number\">500</span>, <span class=\"number\">500</span>  <span class=\"comment\"># 横纵各采样多少个值</span></span><br><span class=\"line\">    x1_min, x2_min = x_train.<span class=\"built_in\">min</span>()</span><br><span class=\"line\">    x1_max, x2_max = x_train.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">    t1 = np.linspace(x1_min, x1_max, N)</span><br><span class=\"line\">    t2 = np.linspace(x2_min, x2_max, M)</span><br><span class=\"line\">    x1, x2 = np.meshgrid(t1, t2)  <span class=\"comment\"># 生成网格采样点</span></span><br><span class=\"line\">    x_show = np.stack((x1.flat, x2.flat), axis=<span class=\"number\">1</span>)  <span class=\"comment\"># 测试点</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 训练集上的预测结果</span></span><br><span class=\"line\">    y_train_pred = model.predict(x_train)</span><br><span class=\"line\">    acc_train = accuracy_score(y_train, y_train_pred)</span><br><span class=\"line\">    y_test_pred = model.predict(x_test)</span><br><span class=\"line\">    acc_test = accuracy_score(y_test, y_test_pred)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;特征：&#x27;</span>, iris_feature[pair[<span class=\"number\">0</span>]], <span class=\"string\">&#x27; + &#x27;</span>, iris_feature[pair[<span class=\"number\">1</span>]])</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\t训练集准确率: %.4f%%&#x27;</span> % (<span class=\"number\">100</span> * acc_train))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\t测试集准确率: %.4f%%\\n&#x27;</span> % (<span class=\"number\">100</span> * acc_test))</span><br><span class=\"line\"></span><br><span class=\"line\">    cm_light = mpl.colors.ListedColormap([<span class=\"string\">&#x27;#A0FFA0&#x27;</span>, <span class=\"string\">&#x27;#FFA0A0&#x27;</span>, <span class=\"string\">&#x27;#A0A0FF&#x27;</span>])</span><br><span class=\"line\">    cm_dark = mpl.colors.ListedColormap([<span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>])</span><br><span class=\"line\">    y_hat = model.predict(x_show)</span><br><span class=\"line\">    y_hat = y_hat.reshape(x1.shape)</span><br><span class=\"line\">    plt.subplot(<span class=\"number\">2</span>, <span class=\"number\">3</span>, i + <span class=\"number\">1</span>)</span><br><span class=\"line\">    plt.contour(x1,</span><br><span class=\"line\">                x2,</span><br><span class=\"line\">                y_hat,</span><br><span class=\"line\">                colors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">                levels=[<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">                antialiased=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                linewidths=<span class=\"number\">1</span>)</span><br><span class=\"line\">    plt.pcolormesh(x1, x2, y_hat, cmap=cm_light, shading=<span class=\"string\">&#x27;auto&#x27;</span>)  <span class=\"comment\"># 预测值</span></span><br><span class=\"line\">    plt.scatter(x_train[pair[<span class=\"number\">0</span>]],</span><br><span class=\"line\">                x_train[pair[<span class=\"number\">1</span>]],</span><br><span class=\"line\">                c=y_train,</span><br><span class=\"line\">                s=<span class=\"number\">20</span>,</span><br><span class=\"line\">                edgecolors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">                cmap=cm_dark,</span><br><span class=\"line\">                label=<span class=\"string\">u&#x27;训练集&#x27;</span>)</span><br><span class=\"line\">    plt.scatter(x_test[pair[<span class=\"number\">0</span>]],</span><br><span class=\"line\">                x_test[pair[<span class=\"number\">1</span>]],</span><br><span class=\"line\">                c=y_test,</span><br><span class=\"line\">                s=<span class=\"number\">80</span>,</span><br><span class=\"line\">                marker=<span class=\"string\">&#x27;*&#x27;</span>,</span><br><span class=\"line\">                edgecolors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">                cmap=cm_dark,</span><br><span class=\"line\">                label=<span class=\"string\">u&#x27;测试集&#x27;</span>)</span><br><span class=\"line\">    plt.xlabel(iris_feature[pair[<span class=\"number\">0</span>]], fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">    plt.ylabel(iris_feature[pair[<span class=\"number\">1</span>]], fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">    <span class=\"comment\"># plt.legend(loc=&#x27;upper right&#x27;, fancybox=True, framealpha=0.3)</span></span><br><span class=\"line\">    plt.xlim(x1_min, x1_max)</span><br><span class=\"line\">    plt.ylim(x2_min, x2_max)</span><br><span class=\"line\">    plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>, color=<span class=\"string\">&#x27;#606060&#x27;</span>)</span><br><span class=\"line\">plt.suptitle(<span class=\"string\">u&#x27;决策树对鸢尾花数据两特征组合的分类结果&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.tight_layout(<span class=\"number\">1</span>, rect=(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.94</span>))  <span class=\"comment\"># (left, bottom, right, top)</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>特征： 花萼长度  +  花萼宽度\n\t训练集准确率: 85.7143%\n\t测试集准确率: 71.1111%\n\n特征： 花萼长度  +  花瓣长度\n\t训练集准确率: 96.1905%\n\t测试集准确率: 91.1111%\n\n特征： 花萼长度  +  花瓣宽度\n\t训练集准确率: 96.1905%\n\t测试集准确率: 86.6667%\n\n特征： 花萼宽度  +  花瓣长度\n\t训练集准确率: 97.1429%\n\t测试集准确率: 95.5556%\n\n特征： 花萼宽度  +  花瓣宽度\n\t训练集准确率: 96.1905%\n\t测试集准确率: 84.4444%\n\n特征： 花瓣长度  +  花瓣宽度\n\t训练集准确率: 98.0952%\n\t测试集准确率: 97.7778%\n\n\n\nC:\\Users\\utsuk\\AppData\\Local\\Temp\\ipykernel_25000\\2108356862.py:83: MatplotlibDeprecationWarning: Passing the pad parameter of tight_layout() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n  plt.tight_layout(1, rect=(0, 0, 1, 0.94))  # (left, bottom, right, top)\n</code></pre>\n<p><img src=\"ML_files/ML_18_2.png\" alt=\"png\"></p>\n<h4 id=\"决策树-随机森林回归\">决策树-随机森林回归</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestRegressor</span><br><span class=\"line\"></span><br><span class=\"line\">N = <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># [-3,3)</span></span><br><span class=\"line\">x = np.random.rand(N) * <span class=\"number\">6</span> - <span class=\"number\">3</span></span><br><span class=\"line\">x.sort()</span><br><span class=\"line\">y = np.sin(x) + np.random.randn(N) * <span class=\"number\">0.05</span></span><br><span class=\"line\">x = x.reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># model = DecisionTreeRegressor(criterion=&#x27;mse&#x27;, max_depth=10)</span></span><br><span class=\"line\">model = RandomForestRegressor(n_estimators=<span class=\"number\">20</span>, criterion=<span class=\"string\">&#x27;mse&#x27;</span>, max_depth=<span class=\"number\">10</span>)</span><br><span class=\"line\">model.fit(x, y)</span><br><span class=\"line\">x_test = np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">50</span>).reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">y_hat = model.predict(x_test)</span><br><span class=\"line\"></span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.plot(x, y, <span class=\"string\">&#x27;r*&#x27;</span>, markersize=<span class=\"number\">10</span>, markeredgecolor=<span class=\"string\">&#x27;k&#x27;</span>, label=<span class=\"string\">&#x27;实际值&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_test, y_hat, <span class=\"string\">&#x27;g-&#x27;</span>, linewidth=<span class=\"number\">2</span>, label=<span class=\"string\">&#x27;预测值&#x27;</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;upper left&#x27;</span>, fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;X&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Y&#x27;</span>)</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>, color=<span class=\"string\">&#x27;#606060&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;决策树-随机森林回归&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.tight_layout(<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 比较决策树的深度影响</span></span><br><span class=\"line\">depth = [<span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">6</span>, <span class=\"number\">8</span>, <span class=\"number\">10</span>]</span><br><span class=\"line\">clr = <span class=\"string\">&#x27;rgbmy&#x27;</span></span><br><span class=\"line\"><span class=\"comment\"># model = DecisionTreeRegressor(criterion=&#x27;mse&#x27;)</span></span><br><span class=\"line\">model = RandomForestRegressor(n_estimators=<span class=\"number\">20</span>, criterion=<span class=\"string\">&#x27;mse&#x27;</span>)</span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.plot(x, y, <span class=\"string\">&#x27;ro&#x27;</span>, ms=<span class=\"number\">5</span>, mec=<span class=\"string\">&#x27;k&#x27;</span>, label=<span class=\"string\">&#x27;实际值&#x27;</span>)</span><br><span class=\"line\">x_test = np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">50</span>).reshape(-<span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> d, c <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>(depth, clr):</span><br><span class=\"line\">    model.set_params(max_depth=d)</span><br><span class=\"line\">    model.fit(x, y)</span><br><span class=\"line\">    y_hat = model.predict(x_test)</span><br><span class=\"line\">    plt.plot(x_test,</span><br><span class=\"line\">             y_hat,</span><br><span class=\"line\">             <span class=\"string\">&#x27;-&#x27;</span>,</span><br><span class=\"line\">             color=c,</span><br><span class=\"line\">             linewidth=<span class=\"number\">2</span>,</span><br><span class=\"line\">             markeredgecolor=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">             label=<span class=\"string\">&#x27;Depth=%d&#x27;</span> % d)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;upper left&#x27;</span>, fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;X&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Y&#x27;</span>)</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>, color=<span class=\"string\">&#x27;#606060&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;决策树-随机森林回归&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">plt.tight_layout(<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>[[-2.95013857]\n [-2.91406777]\n [-2.90709403]\n [-2.90375999]\n [-2.87745415]\n [-2.86685497]\n [-2.84070033]\n [-2.81375697]\n [-2.77943784]\n [-2.77745775]\n [-2.66347611]\n [-2.65986762]\n [-2.64217075]\n [-2.63778267]\n [-2.63639243]\n [-2.60165162]\n [-2.48896096]\n [-2.43041085]\n [-2.39941506]\n [-2.38779079]\n [-2.37856289]\n [-2.32809632]\n [-2.29426051]\n [-2.25524085]\n [-2.23914776]\n [-2.16578847]\n [-2.0055294 ]\n [-1.9885004 ]\n [-1.73199798]\n [-1.61893958]\n [-1.58908223]\n [-1.54966302]\n [-1.49074428]\n [-1.46530843]\n [-1.40362808]\n [-1.3935955 ]\n [-1.3928819 ]\n [-1.37684247]\n [-1.3377295 ]\n [-1.33035029]\n [-1.24577529]\n [-1.15561278]\n [-1.12976361]\n [-0.92771942]\n [-0.91536325]\n [-0.83851709]\n [-0.54828961]\n [-0.54587447]\n [-0.54456521]\n [-0.51610774]\n [-0.38078143]\n [-0.27298529]\n [-0.20898971]\n [-0.20866835]\n [ 0.01703485]\n [ 0.03203468]\n [ 0.06107388]\n [ 0.07358949]\n [ 0.07361575]\n [ 0.10676155]\n [ 0.15818226]\n [ 0.20123638]\n [ 0.3410772 ]\n [ 0.45680655]\n [ 0.52384169]\n [ 0.65741898]\n [ 0.68306354]\n [ 0.82845395]\n [ 0.83952908]\n [ 0.99278446]\n [ 1.04865533]\n [ 1.16809926]\n [ 1.21294563]\n [ 1.44659934]\n [ 1.47606149]\n [ 1.48031876]\n [ 1.54476213]\n [ 1.54542061]\n [ 1.60452852]\n [ 1.85706958]\n [ 1.9814776 ]\n [ 2.07801869]\n [ 2.08420295]\n [ 2.08974078]\n [ 2.09458999]\n [ 2.21547939]\n [ 2.2354401 ]\n [ 2.2824592 ]\n [ 2.39313024]\n [ 2.4822308 ]\n [ 2.5275393 ]\n [ 2.56392915]\n [ 2.63696096]\n [ 2.65318554]\n [ 2.66286196]\n [ 2.67531127]\n [ 2.69337798]\n [ 2.78329004]\n [ 2.83409465]\n [ 2.94897411]]\n[-0.16517944 -0.2651016  -0.26383212 -0.2408083  -0.21137157 -0.30729908\n -0.24489794 -0.42738593 -0.39536257 -0.34762803 -0.55252409 -0.40629331\n -0.47658554 -0.47459876 -0.50897455 -0.58933727 -0.57144697 -0.61564276\n -0.76543047 -0.64009055 -0.79612233 -0.77625958 -0.82824783 -0.74228023\n -0.6882561  -0.85479709 -0.9210133  -0.88824326 -0.94228155 -1.04205908\n -1.01456756 -1.0150173  -1.01319155 -0.93942161 -1.0101109  -1.00949492\n -1.00669835 -1.02762794 -0.90526463 -1.04873446 -0.98356087 -0.96345712\n -0.90790305 -0.78617335 -0.8215092  -0.7756252  -0.62805774 -0.61416394\n -0.55438357 -0.54877048 -0.24409899 -0.24654351 -0.22139215 -0.31816396\n -0.00948097  0.03731195  0.07871564  0.06089414  0.091661    0.10130855\n  0.05916354  0.284293    0.32301758  0.47390064  0.43774825  0.59439442\n  0.62285701  0.78479681  0.7888438   0.91498224  0.91654605  0.84583033\n  0.90598404  0.99494553  1.05048367  0.97256267  1.04768316  1.09246729\n  0.92367061  0.97097779  0.98148804  0.86766162  0.87249721  0.81545132\n  0.80772307  0.75639662  0.73792794  0.75909448  0.71239606  0.63892773\n  0.6373865   0.53978973  0.47836416  0.47544309  0.4156747   0.46233128\n  0.43384357  0.32001956  0.2980857   0.16211947]\n\n\nC:\\Users\\utsuk\\AppData\\Local\\Temp\\ipykernel_25000\\2984870596.py:33: MatplotlibDeprecationWarning: Passing the pad parameter of tight_layout() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n  plt.tight_layout(2)\n</code></pre>\n<p><img src=\"ML_files/ML_20_2.png\" alt=\"png\"></p>\n<pre><code>C:\\Users\\utsuk\\AppData\\Local\\Temp\\ipykernel_25000\\2984870596.py:60: MatplotlibDeprecationWarning: Passing the pad parameter of tight_layout() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n  plt.tight_layout(2)\n</code></pre>\n<p><img src=\"ML_files/ML_20_4.png\" alt=\"png\"></p>\n<h3 id=\"分类问题-2\">分类问题</h3>\n<h4 id=\"逻辑回归-2\">逻辑回归</h4>\n<h5 id=\"二分类\">二分类</h5>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.linear_model <span class=\"keyword\">as</span> lm</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.array([[<span class=\"number\">3</span>, <span class=\"number\">1</span>], [<span class=\"number\">2</span>, <span class=\"number\">5</span>], [<span class=\"number\">1</span>, <span class=\"number\">8</span>], [<span class=\"number\">6</span>, <span class=\"number\">4</span>],\\</span><br><span class=\"line\">              [<span class=\"number\">5</span>, <span class=\"number\">2</span>], [<span class=\"number\">3</span>, <span class=\"number\">5</span>], [<span class=\"number\">4</span>, <span class=\"number\">7</span>], [<span class=\"number\">4</span>, -<span class=\"number\">1</span>]])</span><br><span class=\"line\">y = np.array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建逻辑分类器对象</span></span><br><span class=\"line\"><span class=\"comment\"># C参数：正则强度，越大拟合效果越小，通过调整该参数防止过拟合</span></span><br><span class=\"line\"><span class=\"comment\"># solver参数：逻辑函数中指数的函数关系（liblinear表示线性关系）</span></span><br><span class=\"line\">model = lm.LogisticRegression()</span><br><span class=\"line\">model.fit(x, y)  <span class=\"comment\"># 训练</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测</span></span><br><span class=\"line\">test_x = np.array([[<span class=\"number\">3</span>, <span class=\"number\">9</span>], [<span class=\"number\">6</span>, <span class=\"number\">1</span>]])</span><br><span class=\"line\">test_y = model.predict(test_x)  <span class=\"comment\"># 预测</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(test_y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 计算显示坐标的边界</span></span><br><span class=\"line\"><span class=\"comment\"># x[:, 0].min()   x 中所有数组的第一位</span></span><br><span class=\"line\">left = x[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span></span><br><span class=\"line\">right = x[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">buttom = x[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span></span><br><span class=\"line\">top = x[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 产生网格化矩阵</span></span><br><span class=\"line\">grid_x, grid_y = np.meshgrid(np.arange(left, right, <span class=\"number\">0.01</span>),</span><br><span class=\"line\">                             np.arange(buttom, top, <span class=\"number\">0.01</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;grid_x.shape:&quot;</span>, grid_x.shape)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;grid_y.shape:&quot;</span>, grid_y.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将x,y坐标合并成两列</span></span><br><span class=\"line\">mesh_x = np.column_stack((grid_x.ravel(), grid_y.ravel()))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;mesh_x.shape:&quot;</span>, mesh_x.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 根据每个点的xy坐标进行预测，并还原成二维形状</span></span><br><span class=\"line\">mesh_z = model.predict(mesh_x)</span><br><span class=\"line\">mesh_z = mesh_z.reshape(grid_x.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.figure(<span class=\"string\">&#x27;Logistic Regression&#x27;</span>, facecolor=<span class=\"string\">&#x27;lightgray&#x27;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&#x27;Logistic Regression&#x27;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.xlabel(<span class=\"string\">&#x27;x&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&#x27;y&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.tick_params(labelsize=<span class=\"number\">10</span>)</span><br><span class=\"line\">mp.pcolormesh(grid_x, grid_y, mesh_z, cmap=<span class=\"string\">&#x27;gray&#x27;</span>, shading=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">mp.scatter(</span><br><span class=\"line\">    x[:, <span class=\"number\">0</span>],  <span class=\"comment\"># 样本x坐标</span></span><br><span class=\"line\">    x[:, <span class=\"number\">1</span>],  <span class=\"comment\"># 样本y坐标</span></span><br><span class=\"line\">    c=y,</span><br><span class=\"line\">    cmap=<span class=\"string\">&#x27;brg&#x27;</span>,</span><br><span class=\"line\">    s=<span class=\"number\">80</span>)</span><br><span class=\"line\">mp.scatter(test_x[:, <span class=\"number\">0</span>], test_x[:, <span class=\"number\">1</span>], c=<span class=\"string\">&quot;red&quot;</span>, marker=<span class=\"string\">&#x27;s&#x27;</span>, s=<span class=\"number\">80</span>)</span><br><span class=\"line\">mp.show()</span><br></pre></td></tr></table></figure>\n<pre><code>[1 0]\ngrid_x.shape: (1100, 700)\ngrid_y.shape: (1100, 700)\nmesh_x.shape: (770000, 2)\n</code></pre>\n<p><img src=\"ML_files/ML_22_1.png\" alt=\"png\"></p>\n<h5 id=\"多分类\">多分类</h5>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.linear_model <span class=\"keyword\">as</span> lm</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 输入</span></span><br><span class=\"line\">x = np.array([[<span class=\"number\">4</span>, <span class=\"number\">7</span>], [<span class=\"number\">3.5</span>, <span class=\"number\">8</span>], [<span class=\"number\">3.1</span>, <span class=\"number\">6.2</span>], [<span class=\"number\">0.5</span>, <span class=\"number\">1</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1.2</span>, <span class=\"number\">1.9</span>],</span><br><span class=\"line\">              [<span class=\"number\">6</span>, <span class=\"number\">2</span>], [<span class=\"number\">5.7</span>, <span class=\"number\">1.5</span>], [<span class=\"number\">5.4</span>, <span class=\"number\">2.2</span>]])</span><br><span class=\"line\"><span class=\"comment\"># 输出（多个类别）</span></span><br><span class=\"line\">y = np.array([<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建逻辑分类器对象</span></span><br><span class=\"line\">model = lm.LogisticRegression(C=<span class=\"number\">200</span>)  <span class=\"comment\"># 调整该值为1看效果</span></span><br><span class=\"line\">model.fit(x, y)  <span class=\"comment\"># 训练</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 坐标轴范围</span></span><br><span class=\"line\">left = x[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span></span><br><span class=\"line\">right = x[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">h = <span class=\"number\">0.005</span></span><br><span class=\"line\"></span><br><span class=\"line\">buttom = x[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span></span><br><span class=\"line\">top = x[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">v = <span class=\"number\">0.005</span></span><br><span class=\"line\"></span><br><span class=\"line\">grid_x, grid_y = np.meshgrid(np.arange(left, right, h),</span><br><span class=\"line\">                             np.arange(buttom, top, v))</span><br><span class=\"line\"></span><br><span class=\"line\">mesh_x = np.column_stack((grid_x.ravel(), grid_y.ravel()))</span><br><span class=\"line\">mesh_z = model.predict(mesh_x)</span><br><span class=\"line\">mesh_z = mesh_z.reshape(grid_x.shape)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化</span></span><br><span class=\"line\">mp.figure(<span class=\"string\">&#x27;Logistic Classification&#x27;</span>, facecolor=<span class=\"string\">&#x27;lightgray&#x27;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&#x27;Logistic Classification&#x27;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.xlabel(<span class=\"string\">&#x27;x&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&#x27;y&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.tick_params(labelsize=<span class=\"number\">10</span>)</span><br><span class=\"line\">mp.pcolormesh(grid_x, grid_y, mesh_z, cmap=<span class=\"string\">&#x27;gray&#x27;</span>, shading=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">mp.scatter(x[:, <span class=\"number\">0</span>], x[:, <span class=\"number\">1</span>], c=y, cmap=<span class=\"string\">&#x27;brg&#x27;</span>, s=<span class=\"number\">80</span>)</span><br><span class=\"line\">mp.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"ML_files/ML_24_0.png\" alt=\"png\"></p>\n<h4 id=\"支持向量机-SVM-2\">支持向量机-SVM</h4>\n<h5 id=\"核函数-2\">核函数</h5>\n<ol>\n<li>\n<p>线性</p>\n</li>\n<li>\n<p>径向基-高斯</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> GridSearchCV</span><br><span class=\"line\"><span class=\"keyword\">from</span> time <span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\">iris_feature = <span class=\"string\">&#x27;花萼长度&#x27;</span>, <span class=\"string\">&#x27;花萼宽度&#x27;</span>, <span class=\"string\">&#x27;花瓣长度&#x27;</span>, <span class=\"string\">&#x27;花瓣宽度&#x27;</span></span><br><span class=\"line\">path = <span class=\"string\">&#x27;iris_classification/iris.data&#x27;</span>  <span class=\"comment\"># 数据文件路径</span></span><br><span class=\"line\">data = pd.read_csv(path, header=<span class=\"literal\">None</span>)</span><br><span class=\"line\">x, y = data[[<span class=\"number\">0</span>, <span class=\"number\">1</span>]], pd.Categorical(data[<span class=\"number\">4</span>]).codes</span><br><span class=\"line\">x_train, x_test, y_train, y_test = train_test_split(x,</span><br><span class=\"line\">                                                    y,</span><br><span class=\"line\">                                                    random_state=<span class=\"number\">1</span>,</span><br><span class=\"line\">                                                    test_size=<span class=\"number\">0.4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分类器</span></span><br><span class=\"line\"><span class=\"comment\"># svm_clf = svm.SVC(C=10, gamma=1, kernel=&#x27;rbf&#x27;, decision_function_shape=&#x27;ovo&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># svm_clf = svm.SVC(C=3, kernel=&#x27;poly&#x27;, degree=3)</span></span><br><span class=\"line\">svm_clf = svm.SVC(C=<span class=\"number\">3</span>, kernel=<span class=\"string\">&#x27;linear&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;GridSearchCV begin...&#x27;</span>)</span><br><span class=\"line\">t = time()</span><br><span class=\"line\">clf = svm_clf</span><br><span class=\"line\"><span class=\"comment\"># clf = GridSearchCV(svm_clf, param_grid=&#123;&#x27;gamma&#x27;:np.logspace(-2, 2, 10), &#x27;C&#x27;:np.logspace(-2, 2, 10)&#125;, cv=3)</span></span><br><span class=\"line\">clf.fit(x_train, y_train.ravel())</span><br><span class=\"line\">t_end = time()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;耗时：%d秒&#x27;</span> % (t_end - t))</span><br><span class=\"line\"><span class=\"comment\"># print(&#x27;最优参数：&#x27;, clf.best_params_)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 准确率</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf.score(x_train, y_train))  <span class=\"comment\"># 精度</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;训练集准确率：&#x27;</span>, accuracy_score(y_train, clf.predict(x_train)))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf.score(x_test, y_test))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;测试集准确率：&#x27;</span>, accuracy_score(y_test, clf.predict(x_test)))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># decision_function</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_train[:<span class=\"number\">5</span>])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;decision_function:\\n&#x27;</span>, clf.decision_function(x_train))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;\\npredict:\\n&#x27;</span>, clf.predict(x_train))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">x1_min, x2_min = x.<span class=\"built_in\">min</span>()</span><br><span class=\"line\">x1_max, x2_max = x.<span class=\"built_in\">max</span>()</span><br><span class=\"line\">x1, x2 = np.mgrid[x1_min:x1_max:<span class=\"number\">300j</span>, x2_min:x2_max:<span class=\"number\">300j</span>]  <span class=\"comment\"># 生成网格采样点</span></span><br><span class=\"line\">grid_test = np.stack((x1.flat, x2.flat), axis=<span class=\"number\">1</span>)  <span class=\"comment\"># 测试点</span></span><br><span class=\"line\">grid_hat = clf.predict(grid_test)  <span class=\"comment\"># 预测分类值</span></span><br><span class=\"line\">grid_hat = grid_hat.reshape(x1.shape)  <span class=\"comment\"># 使之与输入的形状相同</span></span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">cm_light = mpl.colors.ListedColormap([<span class=\"string\">&#x27;#A0FFA0&#x27;</span>, <span class=\"string\">&#x27;#FFA0A0&#x27;</span>, <span class=\"string\">&#x27;#A0A0FF&#x27;</span>])</span><br><span class=\"line\">cm_dark = mpl.colors.ListedColormap([<span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>])</span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light, shading=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">plt.scatter(x[<span class=\"number\">0</span>], x[<span class=\"number\">1</span>], c=y, edgecolors=<span class=\"string\">&#x27;k&#x27;</span>, s=<span class=\"number\">50</span>, cmap=cm_dark)  <span class=\"comment\"># 样本</span></span><br><span class=\"line\">plt.scatter(x_test[<span class=\"number\">0</span>], x_test[<span class=\"number\">1</span>], s=<span class=\"number\">120</span>, facecolors=<span class=\"string\">&#x27;none&#x27;</span>,</span><br><span class=\"line\">            zorder=<span class=\"number\">10</span>)  <span class=\"comment\"># 圈中测试集样本</span></span><br><span class=\"line\">plt.xlabel(iris_feature[<span class=\"number\">0</span>], fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.ylabel(iris_feature[<span class=\"number\">1</span>], fontsize=<span class=\"number\">13</span>)</span><br><span class=\"line\">plt.xlim(x1_min, x1_max)</span><br><span class=\"line\">plt.ylim(x2_min, x2_max)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;鸢尾花SVM二特征分类&#x27;</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout(pad=<span class=\"number\">1.5</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<pre><code>GridSearchCV begin...\n耗时：0秒\n0.7888888888888889\n训练集准确率： 0.7888888888888889\n0.7833333333333333\n测试集准确率： 0.7833333333333333\n       0    1\n11   4.8  3.4\n113  5.7  2.5\n123  6.3  2.7\n12   4.8  3.0\n2    4.7  3.2\ndecision_function:\n [[ 2.27077043  0.77466667 -0.23050192]\n [-0.26084184  2.25751125  1.0560141 ]\n [-0.28293421  2.25843306  1.22796515]\n [ 2.24308998  0.92588576 -0.2355186 ]\n [ 2.26643883  0.80879936 -0.24170145]\n [-0.28069428  1.23581332  2.24817619]\n [ 2.28018898  0.76457517 -0.24714914]\n [-0.25832462  1.21350955  2.20811726]\n [-0.27289547  1.20094518  2.249947  ]\n [-0.28479994  1.2318958   2.26058535]\n [-0.23449614  2.22389578  1.08207816]\n [-0.27824598  1.19362022  2.2618816 ]\n [-0.24940836  1.20624284  2.19142888]\n [ 2.2732283  -0.2577432   0.82271427]\n [-0.2872948   2.27977562  1.1680301 ]\n [-0.28016055  1.24346593  2.23969255]\n [-0.28069428  1.23581332  2.24817619]\n [-0.17539161  2.25364746  0.77515212]\n [-0.25325305  1.14281388  2.23566431]\n [-0.2421088   2.25159667  0.90072452]\n [ 2.24374936 -0.23761503  0.93581753]\n [ 2.24150985  0.87804111 -0.2241573 ]\n [ 2.28041834 -0.27382086  0.86293615]\n [-0.27824598  1.19362022  2.2618816 ]\n [ 2.27361996  0.84008337 -0.26180365]\n [-0.26919985  2.24943754  1.18347413]\n [-0.28629221  2.26101768  1.23745359]\n [-0.23808639  1.19803786  2.16960812]\n [ 2.24670891 -0.21840299  0.83780678]\n [ 2.23817757  0.82105098 -0.19112107]\n [-0.2549617   2.24213564  1.1247623 ]\n [ 2.24150985  0.87804111 -0.2241573 ]\n [-0.30409023  1.27536123  2.28319903]\n [-0.27073104  1.23503534  2.2197061 ]\n [-0.30441277  1.26883084  2.28803158]\n [-0.28752494  1.24411663  2.25991942]\n [-0.29292012  2.28000741  1.22212062]\n [-0.23176304  1.04104242  2.22722296]\n [-0.28694643  1.15125962  2.28088265]\n [-0.19956441  2.19653578  1.01742803]\n [ 2.26878977 -0.27918692  1.16597018]\n [-0.2549617   2.24213564  1.1247623 ]\n [ 2.18519501  1.23494087 -0.26146238]\n [-0.2512831   2.2597216   0.89408741]\n [-0.29066599  1.240849    2.26933123]\n [ 2.25729439 -0.2129225   0.79411601]\n [-0.29441953  1.26382422  2.26345809]\n [ 2.26377705 -0.22976306  0.79617407]\n [ 2.27077043  0.77466667 -0.23050192]\n [-0.2445374   1.07681969  2.23683943]\n [-0.21840757  2.21786592  1.00447438]\n [-0.28524498  1.22203776  2.26581127]\n [ 2.24947915  0.81045802 -0.20787766]\n [ 2.2684482  -0.24915018  0.81973595]\n [-0.20907334  1.12013512  2.17603067]\n [ 2.26728139  0.82893904 -0.24984081]\n [-0.2549617   2.24213564  1.1247623 ]\n [ 2.25207771  0.85867453 -0.23431088]\n [-0.28069428  1.23581332  2.24817619]\n [ 1.05055292  2.22662497 -0.23240122]\n [ 2.2722284   0.7997718  -0.24896247]\n [-0.26723747  1.19201787  2.24286157]\n [ 2.27827649  0.82682975 -0.26630655]\n [-0.17333043  2.16553945  1.02939988]\n [ 2.26890439  0.89311197 -0.26243597]\n [-0.2512831   2.2597216   0.89408741]\n [-0.23341849  2.27309387  0.7709214 ]\n [ 2.25617562 -0.22437834  0.81410784]\n [ 2.22986475  0.96247553 -0.22562355]\n [ 0.93771503  2.24006469 -0.23365567]\n [ 2.28631446 -0.25590025  0.75474384]\n [-0.23808639  1.19803786  2.16960812]\n [-0.2646401   1.23019768  2.20613126]\n [ 2.25729439 -0.2129225   0.79411601]\n [-0.28479994  1.2318958   2.26058535]\n [-0.22087216  2.20491832  1.08971052]\n [-0.29260626  2.28238001  1.20719635]\n [-0.29101034  1.23272406  2.27341138]\n [-0.2549617   2.24213564  1.1247623 ]\n [ 2.19974418 -0.17699012  0.91119813]\n [ 2.21209755  1.01040036 -0.21350121]\n [-0.27849238  2.26059076  1.19977637]\n [-0.26997469  2.24280567  1.20408124]\n [-0.29874557  1.25977449  2.27874043]\n [-0.25377271  2.24886239  1.06528288]\n [-0.27961589  2.2500049   1.22933155]\n [-0.27219081  1.21466357  2.24182934]\n [-0.2884762   2.2710352   1.22512174]\n [-0.28479994  1.2318958   2.26058535]\n [ 2.24150985  0.87804111 -0.2241573 ]]\n\npredict:\n [0 1 1 0 0 2 0 2 2 2 1 2 2 0 1 2 2 1 2 1 0 0 0 2 0 1 1 2 0 0 1 0 2 2 2 2 1\n 2 2 1 0 1 0 1 2 0 2 0 0 2 1 2 0 0 2 0 1 0 2 1 0 2 0 1 0 1 1 0 0 1 0 2 2 0\n 2 1 1 2 1 0 0 1 1 2 1 1 2 1 2 0]\n</code></pre>\n<p><img src=\"ML_files/ML_26_1.png\" alt=\"png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy <span class=\"keyword\">import</span> stats</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> accuracy_score</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">extend</span>(<span class=\"params\">a, b, r=<span class=\"number\">0.01</span></span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> a * (<span class=\"number\">1</span> + r) - b * r, -a * r + b * (<span class=\"number\">1</span> + r)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">N = <span class=\"number\">200</span></span><br><span class=\"line\">x = np.empty((<span class=\"number\">4</span> * N, <span class=\"number\">2</span>))</span><br><span class=\"line\">means = [(-<span class=\"number\">1</span>, <span class=\"number\">1</span>), (<span class=\"number\">1</span>, <span class=\"number\">1</span>), (<span class=\"number\">1</span>, -<span class=\"number\">1</span>), (-<span class=\"number\">1</span>, -<span class=\"number\">1</span>)]</span><br><span class=\"line\">sigmas = [</span><br><span class=\"line\">    np.eye(<span class=\"number\">2</span>), <span class=\"number\">2</span> * np.eye(<span class=\"number\">2</span>),</span><br><span class=\"line\">    np.diag((<span class=\"number\">1</span>, <span class=\"number\">2</span>)),</span><br><span class=\"line\">    np.array(((<span class=\"number\">3</span>, <span class=\"number\">2</span>), (<span class=\"number\">2</span>, <span class=\"number\">3</span>)))</span><br><span class=\"line\">]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">4</span>):</span><br><span class=\"line\">    mn = stats.multivariate_normal(means[i], sigmas[i] * <span class=\"number\">0.07</span>)</span><br><span class=\"line\">    x[i * N:(i + <span class=\"number\">1</span>) * N, :] = mn.rvs(N)</span><br><span class=\"line\">a = np.array((<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)).reshape((-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">y = np.tile(a, N).flatten()</span><br><span class=\"line\">clf = svm.SVC(C=<span class=\"number\">1</span>, kernel=<span class=\"string\">&#x27;rbf&#x27;</span>, gamma=<span class=\"number\">1</span>, decision_function_shape=<span class=\"string\">&#x27;ovo&#x27;</span>)</span><br><span class=\"line\"><span class=\"comment\"># clf = svm.SVC(C=1, kernel=&#x27;linear&#x27;, decision_function_shape=&#x27;ovr&#x27;)</span></span><br><span class=\"line\">clf.fit(x, y)</span><br><span class=\"line\">y_hat = clf.predict(x)</span><br><span class=\"line\">acc = accuracy_score(y, y_hat)</span><br><span class=\"line\">np.set_printoptions(suppress=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;预测正确的样本个数：%d，正确率：%.2f%%&#x27;</span> % (<span class=\"built_in\">round</span>(acc * <span class=\"number\">4</span> * N), <span class=\"number\">100</span> * acc))</span><br><span class=\"line\"><span class=\"comment\"># decision_function</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(clf.decision_function(x))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_hat)</span><br><span class=\"line\"></span><br><span class=\"line\">x1_min, x2_min = np.<span class=\"built_in\">min</span>(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">x1_max, x2_max = np.<span class=\"built_in\">max</span>(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">x1_min, x1_max = extend(x1_min, x1_max)</span><br><span class=\"line\">x2_min, x2_max = extend(x2_min, x2_max)</span><br><span class=\"line\">x1, x2 = np.mgrid[x1_min:x1_max:<span class=\"number\">500j</span>, x2_min:x2_max:<span class=\"number\">500j</span>]</span><br><span class=\"line\">x_test = np.stack((x1.flat, x2.flat), axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">y_test = clf.predict(x_test)</span><br><span class=\"line\">y_test = y_test.reshape(x1.shape)</span><br><span class=\"line\">cm_light = mpl.colors.ListedColormap(</span><br><span class=\"line\">    [<span class=\"string\">&#x27;#FF8080&#x27;</span>, <span class=\"string\">&#x27;#80FF80&#x27;</span>, <span class=\"string\">&#x27;#8080FF&#x27;</span>, <span class=\"string\">&#x27;#F0F080&#x27;</span>])</span><br><span class=\"line\">cm_dark = mpl.colors.ListedColormap([<span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>, <span class=\"string\">&#x27;y&#x27;</span>])</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\">plt.figure(facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">plt.pcolormesh(x1, x2, y_test, cmap=cm_light, shading=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">plt.contour(x1, x2, y_test, levels=(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>), colors=<span class=\"string\">&#x27;k&#x27;</span>, linestyles=<span class=\"string\">&#x27;--&#x27;</span>)</span><br><span class=\"line\">plt.scatter(x[:, <span class=\"number\">0</span>],</span><br><span class=\"line\">            x[:, <span class=\"number\">1</span>],</span><br><span class=\"line\">            s=<span class=\"number\">20</span>,</span><br><span class=\"line\">            c=y,</span><br><span class=\"line\">            cmap=cm_dark,</span><br><span class=\"line\">            edgecolors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">            alpha=<span class=\"number\">0.7</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;$X_1$&#x27;</span>, fontsize=<span class=\"number\">11</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;$X_2$&#x27;</span>, fontsize=<span class=\"number\">11</span>)</span><br><span class=\"line\">plt.xlim((x1_min, x1_max))</span><br><span class=\"line\">plt.ylim((x2_min, x2_max))</span><br><span class=\"line\">plt.grid(b=<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.tight_layout(pad=<span class=\"number\">2.5</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;SVM多分类方法：One/One or One/Other&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>预测正确的样本个数：793，正确率：99.12%\n[[ 1.30403817  1.18371967  1.61069453  0.53379555  0.10282667 -0.6639782 ]\n [ 1.20484592  1.00041165  1.13023042  0.32840742  0.16888308 -0.33559223]\n [ 1.28448754  1.15305262  1.24310512  0.59725054 -0.31474389 -0.97622623]\n ...\n [-0.23584035 -0.08224918 -1.09483656  0.1554822  -1.12200744 -1.12840424]\n [ 0.2447751   0.34444513 -1.55255237  0.17064062 -1.24348982 -1.41973039]\n [-0.03070327 -0.15566364 -1.9254549  -0.09600454 -1.23897289 -1.44257329]]\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n</code></pre>\n<p><img src=\"ML_files/ML_27_1.png\" alt=\"png\"></p>\n<h4 id=\"朴素贝叶斯-2\">朴素贝叶斯</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NBClassify</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, fillNa=<span class=\"number\">1</span></span>):</span></span><br><span class=\"line\">        self.fillNa = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span>(<span class=\"params\">self, trainSet</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># 计算每种类别的概率</span></span><br><span class=\"line\">        <span class=\"comment\"># 保存所有tag的所有种类，及它们出现的频次</span></span><br><span class=\"line\">        dictTag = &#123;&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> subTuple <span class=\"keyword\">in</span> trainSet:</span><br><span class=\"line\">            dictTag[<span class=\"built_in\">str</span>(</span><br><span class=\"line\">                subTuple[<span class=\"number\">1</span>])] = <span class=\"number\">1</span> <span class=\"keyword\">if</span> <span class=\"built_in\">str</span>(subTuple[<span class=\"number\">1</span>]) <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> dictTag.keys(</span><br><span class=\"line\">                ) <span class=\"keyword\">else</span> dictTag[<span class=\"built_in\">str</span>(subTuple[<span class=\"number\">1</span>])] + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 保存每个tag本身的概率</span></span><br><span class=\"line\">        tagProbablity = &#123;&#125;</span><br><span class=\"line\">        totalFreq = <span class=\"built_in\">sum</span>([value <span class=\"keyword\">for</span> value <span class=\"keyword\">in</span> dictTag.values()])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key, value <span class=\"keyword\">in</span> dictTag.items():</span><br><span class=\"line\">            tagProbablity[key] = value / totalFreq</span><br><span class=\"line\">        <span class=\"comment\"># print(tagProbablity)</span></span><br><span class=\"line\">        self.tagProbablity = tagProbablity</span><br><span class=\"line\">        <span class=\"comment\">##############################################################################</span></span><br><span class=\"line\">        <span class=\"comment\"># 计算特征的条件概率</span></span><br><span class=\"line\">        <span class=\"comment\"># 保存特征属性基本信息&#123;特征1:&#123;值1:出现5次, 值2:出现1次&#125;, 特征2:&#123;值1:出现1次, 值2:出现5次&#125;&#125;</span></span><br><span class=\"line\">        dictFeaturesBase = &#123;&#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> subTuple <span class=\"keyword\">in</span> trainSet:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> key, value <span class=\"keyword\">in</span> subTuple[<span class=\"number\">0</span>].items():</span><br><span class=\"line\">                <span class=\"keyword\">if</span> key <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> dictFeaturesBase.keys():</span><br><span class=\"line\">                    dictFeaturesBase[key] = &#123;value: <span class=\"number\">1</span>&#125;</span><br><span class=\"line\">                <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> value <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> dictFeaturesBase[key].keys():</span><br><span class=\"line\">                        dictFeaturesBase[key][value] = <span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                        dictFeaturesBase[key][value] += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># dictFeaturesBase = &#123;</span></span><br><span class=\"line\">        <span class=\"comment\"># &#x27;职业&#x27;: &#123;&#x27;农夫&#x27;: 1, &#x27;教师&#x27;: 2, &#x27;建筑工人&#x27;: 2, &#x27;护士&#x27;: 1&#125;,</span></span><br><span class=\"line\">        <span class=\"comment\"># &#x27;症状&#x27;: &#123;&#x27;打喷嚏&#x27;: 3, &#x27;头痛&#x27;: 3&#125;</span></span><br><span class=\"line\">        <span class=\"comment\"># &#125;</span></span><br><span class=\"line\">        dictFeatures = &#123;&#125;.fromkeys([key <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> dictTag])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> dictFeatures.keys():</span><br><span class=\"line\">            dictFeatures[key] = &#123;&#125;.fromkeys([key <span class=\"keyword\">for</span> key <span class=\"keyword\">in</span> dictFeaturesBase])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> key, value <span class=\"keyword\">in</span> dictFeatures.items():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> subkey <span class=\"keyword\">in</span> value.keys():</span><br><span class=\"line\">                value[subkey] = &#123;&#125;.fromkeys(</span><br><span class=\"line\">                    [x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> dictFeaturesBase[subkey].keys()])</span><br><span class=\"line\">        <span class=\"comment\"># dictFeatures = &#123;</span></span><br><span class=\"line\">        <span class=\"comment\">#  &#x27;感冒 &#x27;: &#123;&#x27;症状&#x27;: &#123;&#x27;打喷嚏&#x27;: None, &#x27;头痛&#x27;: None&#125;, &#x27;职业&#x27;: &#123;&#x27;护士&#x27;: None, &#x27;农夫&#x27;: None, &#x27;建筑工人&#x27;: None, &#x27;教师&#x27;: None&#125;&#125;,</span></span><br><span class=\"line\">        <span class=\"comment\">#  &#x27;脑震荡&#x27;: &#123;&#x27;症状&#x27;: &#123;&#x27;打喷嚏&#x27;: None, &#x27;头痛&#x27;: None&#125;, &#x27;职业&#x27;: &#123;&#x27;护士&#x27;: None, &#x27;农夫&#x27;: None, &#x27;建筑工人&#x27;: None, &#x27;教师&#x27;: None&#125;&#125;,</span></span><br><span class=\"line\">        <span class=\"comment\">#  &#x27;过敏 &#x27;: &#123;&#x27;症状&#x27;: &#123;&#x27;打喷嚏&#x27;: None, &#x27;头痛&#x27;: None&#125;, &#x27;职业&#x27;: &#123;&#x27;护士&#x27;: None, &#x27;农夫&#x27;: None, &#x27;建筑工人&#x27;: None, &#x27;教师&#x27;: None&#125;&#125;</span></span><br><span class=\"line\">        <span class=\"comment\">#  &#125;</span></span><br><span class=\"line\">        <span class=\"comment\"># initialise dictFeatures</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> subTuple <span class=\"keyword\">in</span> trainSet:</span><br><span class=\"line\">            <span class=\"keyword\">for</span> key, value <span class=\"keyword\">in</span> subTuple[<span class=\"number\">0</span>].items():</span><br><span class=\"line\">                dictFeatures[subTuple[<span class=\"number\">1</span>]][key][value] = <span class=\"number\">1</span> <span class=\"keyword\">if</span> dictFeatures[</span><br><span class=\"line\">                    subTuple[<span class=\"number\">1</span>]][key][value] == <span class=\"literal\">None</span> <span class=\"keyword\">else</span> dictFeatures[</span><br><span class=\"line\">                        subTuple[<span class=\"number\">1</span>]][key][value] + <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># print(dictFeatures)</span></span><br><span class=\"line\">        <span class=\"comment\"># 将驯良样本中没有的项目，由None改为一个非常小的数值，表示其概率极小而并非是零</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> tag, featuresDict <span class=\"keyword\">in</span> dictFeatures.items():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> featureName, fetureValueDict <span class=\"keyword\">in</span> featuresDict.items():</span><br><span class=\"line\">                <span class=\"keyword\">for</span> featureKey, featureValues <span class=\"keyword\">in</span> fetureValueDict.items():</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> featureValues == <span class=\"literal\">None</span>:</span><br><span class=\"line\">                        fetureValueDict[featureKey] = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 由特征频率计算特征的条件概率P(feature|tag)</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> tag, featuresDict <span class=\"keyword\">in</span> dictFeatures.items():</span><br><span class=\"line\">            <span class=\"keyword\">for</span> featureName, fetureValueDict <span class=\"keyword\">in</span> featuresDict.items():</span><br><span class=\"line\">                totalCount = <span class=\"built_in\">sum</span>(</span><br><span class=\"line\">                    [x <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> fetureValueDict.values() <span class=\"keyword\">if</span> x != <span class=\"literal\">None</span>])</span><br><span class=\"line\">                <span class=\"keyword\">for</span> featureKey, featureValues <span class=\"keyword\">in</span> fetureValueDict.items():</span><br><span class=\"line\">                    fetureValueDict[</span><br><span class=\"line\">                        featureKey] = featureValues / totalCount <span class=\"keyword\">if</span> featureValues != <span class=\"literal\">None</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        self.featuresProbablity = dictFeatures</span><br><span class=\"line\">        <span class=\"comment\">##############################################################################</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">classify</span>(<span class=\"params\">self, featureDict</span>):</span></span><br><span class=\"line\">        resultDict = &#123;&#125;</span><br><span class=\"line\">        <span class=\"comment\"># 计算每个tag的条件概率</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> key, value <span class=\"keyword\">in</span> self.tagProbablity.items():</span><br><span class=\"line\">            iNumList = []</span><br><span class=\"line\">            <span class=\"keyword\">for</span> f, v <span class=\"keyword\">in</span> featureDict.items():</span><br><span class=\"line\">                <span class=\"keyword\">if</span> self.featuresProbablity[key][f][v]:</span><br><span class=\"line\">                    iNumList.append(self.featuresProbablity[key][f][v])</span><br><span class=\"line\">            conditionPr = <span class=\"number\">1</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> iNum <span class=\"keyword\">in</span> iNumList:</span><br><span class=\"line\">                conditionPr *= iNum</span><br><span class=\"line\">            resultDict[key] = value * conditionPr</span><br><span class=\"line\">        <span class=\"comment\"># 对比每个tag的条件概率的大小</span></span><br><span class=\"line\">        resultList = <span class=\"built_in\">sorted</span>(resultDict.items(),</span><br><span class=\"line\">                            key=<span class=\"keyword\">lambda</span> x: x[<span class=\"number\">1</span>],</span><br><span class=\"line\">                            reverse=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> resultList[<span class=\"number\">0</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    trainSet = [</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;打喷嚏&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;护士&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;感冒 &quot;</span>),</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;打喷嚏&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;农夫&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;过敏 &quot;</span>),</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;头痛&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;建筑工人&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;脑震荡&quot;</span>),</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;头痛&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;建筑工人&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;感冒 &quot;</span>),</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;打喷嚏&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;教师&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;感冒 &quot;</span>),</span><br><span class=\"line\">        (&#123;</span><br><span class=\"line\">            <span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;头痛&quot;</span>,</span><br><span class=\"line\">            <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;教师&quot;</span></span><br><span class=\"line\">        &#125;, <span class=\"string\">&quot;脑震荡&quot;</span>),</span><br><span class=\"line\">    ]</span><br><span class=\"line\">    monitor = NBClassify()</span><br><span class=\"line\">    <span class=\"comment\"># trainSet is something like that [(featureDict, tag), ]</span></span><br><span class=\"line\">    monitor.train(trainSet)</span><br><span class=\"line\">    <span class=\"comment\"># 打喷嚏的建筑工人</span></span><br><span class=\"line\">    <span class=\"comment\"># 请问他患上感冒的概率有多大？</span></span><br><span class=\"line\">    result = monitor.classify(&#123;<span class=\"string\">&quot;症状&quot;</span>: <span class=\"string\">&quot;打喷嚏&quot;</span>, <span class=\"string\">&quot;职业&quot;</span>: <span class=\"string\">&quot;建筑工人&quot;</span>&#125;)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>感冒 \n</code></pre>\n<h3 id=\"聚类问题\">聚类问题</h3>\n<h4 id=\"K-Means-与衡量指标\">K-Means-与衡量指标</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.colors</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.datasets <span class=\"keyword\">as</span> ds</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> homogeneity_score, completeness_score, v_measure_score, adjusted_mutual_info_score,\\</span><br><span class=\"line\">    adjusted_rand_score, silhouette_score</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> KMeans</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">expand</span>(<span class=\"params\">a, b</span>):</span></span><br><span class=\"line\">    d = (b - a) * <span class=\"number\">0.1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> a - d, b + d</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">N = <span class=\"number\">400</span></span><br><span class=\"line\">centers = <span class=\"number\">4</span></span><br><span class=\"line\">data, y = ds.make_blobs(N, n_features=<span class=\"number\">2</span>, centers=centers, random_state=<span class=\"number\">2</span>)</span><br><span class=\"line\">data2, y2 = ds.make_blobs(N,</span><br><span class=\"line\">                          n_features=<span class=\"number\">2</span>,</span><br><span class=\"line\">                          centers=centers,</span><br><span class=\"line\">                          cluster_std=(<span class=\"number\">1</span>, <span class=\"number\">2.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">2</span>),</span><br><span class=\"line\">                          random_state=<span class=\"number\">2</span>)</span><br><span class=\"line\">data3 = np.vstack(</span><br><span class=\"line\">    (data[y == <span class=\"number\">0</span>][:], data[y == <span class=\"number\">1</span>][:<span class=\"number\">50</span>], data[y == <span class=\"number\">2</span>][:<span class=\"number\">20</span>], data[y == <span class=\"number\">3</span>][:<span class=\"number\">5</span>]))</span><br><span class=\"line\">y3 = np.array([<span class=\"number\">0</span>] * <span class=\"number\">100</span> + [<span class=\"number\">1</span>] * <span class=\"number\">50</span> + [<span class=\"number\">2</span>] * <span class=\"number\">20</span> + [<span class=\"number\">3</span>] * <span class=\"number\">5</span>)</span><br><span class=\"line\">m = np.array(((<span class=\"number\">1</span>, <span class=\"number\">1</span>), (<span class=\"number\">1</span>, <span class=\"number\">3</span>)))</span><br><span class=\"line\">data_r = data.dot(m)</span><br><span class=\"line\"></span><br><span class=\"line\">matplotlib.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">matplotlib.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\">cm = matplotlib.colors.ListedColormap(<span class=\"built_in\">list</span>(<span class=\"string\">&#x27;rgbm&#x27;</span>))</span><br><span class=\"line\">data_list = data, data, data_r, data_r, data2, data2, data3, data3</span><br><span class=\"line\">y_list = y, y, y, y, y2, y2, y3, y3</span><br><span class=\"line\">titles = <span class=\"string\">&#x27;原始数据&#x27;</span>, <span class=\"string\">&#x27;KMeans++聚类&#x27;</span>, <span class=\"string\">&#x27;旋转后数据&#x27;</span>, <span class=\"string\">&#x27;旋转后KMeans++聚类&#x27;</span>,\\</span><br><span class=\"line\">          <span class=\"string\">&#x27;方差不相等数据&#x27;</span>, <span class=\"string\">&#x27;方差不相等KMeans++聚类&#x27;</span>, <span class=\"string\">&#x27;数量不相等数据&#x27;</span>, <span class=\"string\">&#x27;数量不相等KMeans++聚类&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">model = KMeans(n_clusters=<span class=\"number\">4</span>, init=<span class=\"string\">&#x27;k-means++&#x27;</span>, n_init=<span class=\"number\">5</span>)</span><br><span class=\"line\">fig = plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">9</span>), facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i, (x, y, title) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(<span class=\"built_in\">zip</span>(data_list, y_list, titles), start=<span class=\"number\">1</span>):</span><br><span class=\"line\">    <span class=\"comment\"># plt.subplot(4, 2, i)</span></span><br><span class=\"line\">    ax = fig.add_subplot(<span class=\"number\">4</span>, <span class=\"number\">2</span>, i)</span><br><span class=\"line\">    plt.title(title)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> i % <span class=\"number\">2</span> == <span class=\"number\">1</span>:</span><br><span class=\"line\">        y_pred = y</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        y_pred = model.fit_predict(x)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(i)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Homogeneity:&#x27;</span>, homogeneity_score(y, y_pred))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;completeness:&#x27;</span>, completeness_score(y, y_pred))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;V measure:&#x27;</span>, v_measure_score(y, y_pred))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;AMI:&#x27;</span>, adjusted_mutual_info_score(y, y_pred))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;ARI:&#x27;</span>, adjusted_rand_score(y, y_pred))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;Silhouette:&#x27;</span>, silhouette_score(x, y_pred), <span class=\"string\">&#x27;\\n&#x27;</span>)</span><br><span class=\"line\">    ax.scatter(x[:, <span class=\"number\">0</span>], x[:, <span class=\"number\">1</span>], s=<span class=\"number\">10</span>, c=y_pred, cmap=cm, edgecolors=<span class=\"string\">&#x27;none&#x27;</span>)</span><br><span class=\"line\">    ax.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\">plt.tight_layout(<span class=\"number\">2</span>, rect=(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.95</span>))</span><br><span class=\"line\">plt.suptitle(<span class=\"string\">&#x27;数据分布对KMeans聚类的影响&#x27;</span>, fontsize=<span class=\"number\">18</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>1\nHomogeneity: 1.0\ncompleteness: 1.0\nV measure: 1.0\nAMI: 1.0\nARI: 1.0\nSilhouette: 0.616436816839852 \n\n2\nHomogeneity: 0.9898828240244267\ncompleteness: 0.9899006758819153\nV measure: 0.9898917498726852\nAMI: 0.9898081557479033\nARI: 0.9933165272203728\nSilhouette: 0.6189656317733315 \n\n3\nHomogeneity: 1.0\ncompleteness: 1.0\nV measure: 1.0\nAMI: 1.0\nARI: 1.0\nSilhouette: 0.5275987244664399 \n\n4\nHomogeneity: 0.7296158940840607\ncompleteness: 0.7315285272632114\nV measure: 0.7305709588584066\nAMI: 0.7283397010755561\nARI: 0.6783811042853299\nSilhouette: 0.5366236044449266 \n\n5\nHomogeneity: 1.0\ncompleteness: 1.0\nV measure: 1.0\nAMI: 1.0\nARI: 1.0\nSilhouette: 0.4790725752982868 \n\n6\nHomogeneity: 0.7449364376693913\ncompleteness: 0.7755445167472191\nV measure: 0.7599323988656883\nAMI: 0.757903292819801\nARI: 0.7113213508090338\nSilhouette: 0.5737260449304202 \n\n7\nHomogeneity: 1.0\ncompleteness: 1.0\nV measure: 1.0\nAMI: 1.0\nARI: 1.0\nSilhouette: 0.5975066093204152 \n\n8\nHomogeneity: 0.9776347312784609\ncompleteness: 0.9728632742060752\nV measure: 0.975243166591057\nAMI: 0.9745709993295113\nARI: 0.9906840043816505\nSilhouette: 0.6013877858619149 \n\n\n\nC:\\Users\\utsuk\\AppData\\Local\\Temp\\ipykernel_28356\\867049078.py:57: MatplotlibDeprecationWarning: Passing the pad parameter of tight_layout() positionally is deprecated since Matplotlib 3.3; the parameter will become keyword-only two minor releases later.\n  plt.tight_layout(2, rect=(0, 0, 1, 0.95))\n</code></pre>\n<p><img src=\"ML_files/ML_31_2.png\" alt=\"png\"></p>\n<h4 id=\"层次聚类\">层次聚类</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib <span class=\"keyword\">as</span> mpl</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> AgglomerativeClustering</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> kneighbors_graph</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.datasets <span class=\"keyword\">as</span> ds</span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">expand</span>(<span class=\"params\">a, b, r</span>):</span></span><br><span class=\"line\">    d = (b - a) * r</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a - d, b + d</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&#x27;__main__&#x27;</span>:</span><br><span class=\"line\">    warnings.filterwarnings(action=<span class=\"string\">&#x27;ignore&#x27;</span>, category=UserWarning)</span><br><span class=\"line\">    np.set_printoptions(suppress=<span class=\"literal\">True</span>)</span><br><span class=\"line\">    np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">    n_clusters = <span class=\"number\">4</span></span><br><span class=\"line\">    N = <span class=\"number\">400</span></span><br><span class=\"line\">    data1, y1 = ds.make_blobs(n_samples=N,</span><br><span class=\"line\">                              n_features=<span class=\"number\">2</span>,</span><br><span class=\"line\">                              centers=((-<span class=\"number\">1</span>, <span class=\"number\">1</span>), (<span class=\"number\">1</span>, <span class=\"number\">1</span>), (<span class=\"number\">1</span>, -<span class=\"number\">1</span>), (-<span class=\"number\">1</span>, -<span class=\"number\">1</span>)),</span><br><span class=\"line\">                              cluster_std=(<span class=\"number\">0.1</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>, <span class=\"number\">0.4</span>),</span><br><span class=\"line\">                              random_state=<span class=\"number\">0</span>)</span><br><span class=\"line\">    data1 = np.array(data1)</span><br><span class=\"line\">    n_noise = <span class=\"built_in\">int</span>(<span class=\"number\">0.1</span> * N)</span><br><span class=\"line\">    r = np.random.rand(n_noise, <span class=\"number\">2</span>)</span><br><span class=\"line\">    data_min1, data_min2 = np.<span class=\"built_in\">min</span>(data1, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    data_max1, data_max2 = np.<span class=\"built_in\">max</span>(data1, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    r[:, <span class=\"number\">0</span>] = r[:, <span class=\"number\">0</span>] * (data_max1 - data_min1) + data_min1</span><br><span class=\"line\">    r[:, <span class=\"number\">1</span>] = r[:, <span class=\"number\">1</span>] * (data_max2 - data_min2) + data_min2</span><br><span class=\"line\">    data1_noise = np.concatenate((data1, r), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    y1_noise = np.concatenate((y1, [<span class=\"number\">4</span>] * n_noise))</span><br><span class=\"line\"></span><br><span class=\"line\">    data2, y2 = ds.make_moons(n_samples=N, noise=<span class=\"number\">.05</span>)</span><br><span class=\"line\">    data2 = np.array(data2)</span><br><span class=\"line\">    n_noise = <span class=\"built_in\">int</span>(<span class=\"number\">0.1</span> * N)</span><br><span class=\"line\">    r = np.random.rand(n_noise, <span class=\"number\">2</span>)</span><br><span class=\"line\">    data_min1, data_min2 = np.<span class=\"built_in\">min</span>(data2, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    data_max1, data_max2 = np.<span class=\"built_in\">max</span>(data2, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    r[:, <span class=\"number\">0</span>] = r[:, <span class=\"number\">0</span>] * (data_max1 - data_min1) + data_min1</span><br><span class=\"line\">    r[:, <span class=\"number\">1</span>] = r[:, <span class=\"number\">1</span>] * (data_max2 - data_min2) + data_min2</span><br><span class=\"line\">    data2_noise = np.concatenate((data2, r), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    y2_noise = np.concatenate((y2, [<span class=\"number\">3</span>] * n_noise))</span><br><span class=\"line\"></span><br><span class=\"line\">    mpl.rcParams[<span class=\"string\">&#x27;font.sans-serif&#x27;</span>] = [<span class=\"string\">&#x27;SimHei&#x27;</span>]</span><br><span class=\"line\">    mpl.rcParams[<span class=\"string\">&#x27;axes.unicode_minus&#x27;</span>] = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">    cm = mpl.colors.ListedColormap([<span class=\"string\">&#x27;r&#x27;</span>, <span class=\"string\">&#x27;g&#x27;</span>, <span class=\"string\">&#x27;b&#x27;</span>, <span class=\"string\">&#x27;m&#x27;</span>, <span class=\"string\">&#x27;c&#x27;</span>])</span><br><span class=\"line\">    plt.figure(figsize=(<span class=\"number\">10</span>, <span class=\"number\">8</span>), facecolor=<span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\">    plt.cla()</span><br><span class=\"line\">    linkages = (<span class=\"string\">&quot;ward&quot;</span>, <span class=\"string\">&quot;complete&quot;</span>, <span class=\"string\">&quot;average&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> index, (n_clusters, data, y) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(</span><br><span class=\"line\">        ((<span class=\"number\">4</span>, data1, y1), (<span class=\"number\">4</span>, data1_noise, y1_noise), (<span class=\"number\">2</span>, data2, y2),</span><br><span class=\"line\">         (<span class=\"number\">2</span>, data2_noise, y2_noise))):</span><br><span class=\"line\">        plt.subplot(<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">4</span> * index + <span class=\"number\">1</span>)</span><br><span class=\"line\">        plt.scatter(data[:, <span class=\"number\">0</span>], data[:, <span class=\"number\">1</span>], c=y, s=<span class=\"number\">12</span>, edgecolors=<span class=\"string\">&#x27;k&#x27;</span>, cmap=cm)</span><br><span class=\"line\">        plt.title(<span class=\"string\">&#x27;Prime&#x27;</span>, fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">        plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\">        data_min1, data_min2 = np.<span class=\"built_in\">min</span>(data, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        data_max1, data_max2 = np.<span class=\"built_in\">max</span>(data, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        plt.xlim(expand(data_min1, data_max1, <span class=\"number\">0.05</span>))</span><br><span class=\"line\">        plt.ylim(expand(data_min2, data_max2, <span class=\"number\">0.05</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        connectivity = kneighbors_graph(data,</span><br><span class=\"line\">                                        n_neighbors=<span class=\"number\">7</span>,</span><br><span class=\"line\">                                        mode=<span class=\"string\">&#x27;distance&#x27;</span>,</span><br><span class=\"line\">                                        metric=<span class=\"string\">&#x27;minkowski&#x27;</span>,</span><br><span class=\"line\">                                        p=<span class=\"number\">2</span>,</span><br><span class=\"line\">                                        include_self=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        connectivity = <span class=\"number\">0.5</span> * (connectivity + connectivity.T)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i, linkage <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(linkages):</span><br><span class=\"line\">            ac = AgglomerativeClustering(n_clusters=n_clusters,</span><br><span class=\"line\">                                         affinity=<span class=\"string\">&#x27;euclidean&#x27;</span>,</span><br><span class=\"line\">                                         connectivity=connectivity,</span><br><span class=\"line\">                                         linkage=linkage)</span><br><span class=\"line\">            ac.fit(data)</span><br><span class=\"line\">            y = ac.labels_</span><br><span class=\"line\">            plt.subplot(<span class=\"number\">4</span>, <span class=\"number\">4</span>, i + <span class=\"number\">2</span> + <span class=\"number\">4</span> * index)</span><br><span class=\"line\">            plt.scatter(data[:, <span class=\"number\">0</span>],</span><br><span class=\"line\">                        data[:, <span class=\"number\">1</span>],</span><br><span class=\"line\">                        c=y,</span><br><span class=\"line\">                        s=<span class=\"number\">12</span>,</span><br><span class=\"line\">                        edgecolors=<span class=\"string\">&#x27;k&#x27;</span>,</span><br><span class=\"line\">                        cmap=cm)</span><br><span class=\"line\">            plt.title(linkage, fontsize=<span class=\"number\">12</span>)</span><br><span class=\"line\">            plt.grid(b=<span class=\"literal\">True</span>, ls=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\">            plt.xlim(expand(data_min1, data_max1, <span class=\"number\">0.05</span>))</span><br><span class=\"line\">            plt.ylim(expand(data_min2, data_max2, <span class=\"number\">0.05</span>))</span><br><span class=\"line\">    plt.suptitle(<span class=\"string\">&#x27;层次聚类的不同合并策略&#x27;</span>, fontsize=<span class=\"number\">15</span>)</span><br><span class=\"line\">    plt.tight_layout(<span class=\"number\">0.5</span>, rect=(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0.95</span>))</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><img src=\"ML_files/ML_33_0.png\" alt=\"png\"></p>\n<h3 id=\"降维问题-2\">降维问题</h3>\n<h4 id=\"缺失值比率-2\">缺失值比率</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># import required libraries</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># read the data</span></span><br><span class=\"line\">train = pd.read_csv(<span class=\"string\">&quot;./降维问题/train_v9rqX0R.csv&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># checking the percentage of missing values in each variable</span></span><br><span class=\"line\"><span class=\"comment\"># 数据完整率 = (空数 / 所有数) * 100</span></span><br><span class=\"line\">a = train.isnull().<span class=\"built_in\">sum</span>() / <span class=\"built_in\">len</span>(train) * <span class=\"number\">100</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># saving column names in a variable</span></span><br><span class=\"line\">variable = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, <span class=\"number\">12</span>):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> a[i] &lt;= <span class=\"number\">20</span>:  <span class=\"comment\">#setting the threshold as 20%</span></span><br><span class=\"line\">        variable.append(train.columns[i])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 缺失率大于阈值的列</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(variable)</span><br></pre></td></tr></table></figure>\n<pre><code>['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Location_Type', 'Outlet_Type', 'Item_Outlet_Sales']\n</code></pre>\n<h4 id=\"低方差过滤-2\">低方差过滤</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># import required libraries</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># read the data</span></span><br><span class=\"line\">train = pd.read_csv(<span class=\"string\">&quot;./降维问题/train_v9rqX0R.csv&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 填充空项</span></span><br><span class=\"line\">train[<span class=\"string\">&#x27;Item_Weight&#x27;</span>].fillna(train[<span class=\"string\">&#x27;Item_Weight&#x27;</span>].median(), inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\">train[<span class=\"string\">&#x27;Outlet_Size&#x27;</span>].fillna(train[<span class=\"string\">&#x27;Outlet_Size&#x27;</span>].mode()[<span class=\"number\">0</span>], inplace=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 填充后的缺失率</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(train.isnull().<span class=\"built_in\">sum</span>() / <span class=\"built_in\">len</span>(train) * <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">numeric = train[[</span><br><span class=\"line\">    <span class=\"string\">&#x27;Item_Weight&#x27;</span>, <span class=\"string\">&#x27;Item_Visibility&#x27;</span>, <span class=\"string\">&#x27;Item_MRP&#x27;</span>, <span class=\"string\">&#x27;Outlet_Establishment_Year&#x27;</span></span><br><span class=\"line\">]]</span><br><span class=\"line\">var = numeric.var()</span><br><span class=\"line\">numeric = numeric.columns</span><br><span class=\"line\">variable = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(var)):</span><br><span class=\"line\">    <span class=\"keyword\">if</span> var[i] &gt;= <span class=\"number\">10</span>:  <span class=\"comment\">#setting the threshold as 10%</span></span><br><span class=\"line\">        variable.append(numeric[i])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(variable)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<pre><code>Item_Identifier              0.0\nItem_Weight                  0.0\nItem_Fat_Content             0.0\nItem_Visibility              0.0\nItem_Type                    0.0\nItem_MRP                     0.0\nOutlet_Identifier            0.0\nOutlet_Establishment_Year    0.0\nOutlet_Size                  0.0\nOutlet_Location_Type         0.0\nOutlet_Type                  0.0\nItem_Outlet_Sales            0.0\ndtype: float64\n['Item_Weight', 'Item_MRP', 'Outlet_Establishment_Year']\n</code></pre>\n<h2 id=\"代码相关\">代码相关</h2>\n<h3 id=\"存储-读取模型\">存储-读取模型</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.linear_model <span class=\"keyword\">as</span> lm  <span class=\"comment\"># 线性模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> sklearn.metrics <span class=\"keyword\">as</span> sm  <span class=\"comment\"># 模型性能评价模块</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> mp</span><br><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.array([[<span class=\"number\">0.5</span>], [<span class=\"number\">0.6</span>], [<span class=\"number\">0.8</span>], [<span class=\"number\">1.1</span>], [<span class=\"number\">1.4</span>]])  <span class=\"comment\"># 输入集</span></span><br><span class=\"line\">y = np.array([<span class=\"number\">5.0</span>, <span class=\"number\">5.5</span>, <span class=\"number\">6.0</span>, <span class=\"number\">6.8</span>, <span class=\"number\">7.0</span>])  <span class=\"comment\"># 输出集</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建线性回归器</span></span><br><span class=\"line\">model = lm.LinearRegression()</span><br><span class=\"line\"><span class=\"comment\"># 用已知输入、输出数据集训练回归器</span></span><br><span class=\"line\">model.fit(x, y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;训练完成.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存训练后的模型</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;linear_model.pkl&#x27;</span>, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(model, f)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;保存模型完成.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">######################### 加载模型 #########################</span></span><br><span class=\"line\"><span class=\"comment\"># 上面通过训练数据x,y 训练好了 x -&gt; y 的线性回归模型</span></span><br><span class=\"line\"><span class=\"comment\"># 下面加载模型, 再给出测试数据 x, 查看模型预测结果直线与原始数据 (x,y) 的拟合度</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;linear_model.pkl&#x27;</span>, <span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    model = pickle.load(f)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;加载模型完成.&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 根据加载的模型预测输出</span></span><br><span class=\"line\">pred_y = model.predict(x)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化回归曲线</span></span><br><span class=\"line\">mp.figure(<span class=\"string\">&#x27;Linear Regression&#x27;</span>, facecolor=<span class=\"string\">&#x27;lightgray&#x27;</span>)</span><br><span class=\"line\">mp.title(<span class=\"string\">&#x27;Linear Regression&#x27;</span>, fontsize=<span class=\"number\">20</span>)</span><br><span class=\"line\">mp.xlabel(<span class=\"string\">&#x27;x&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.ylabel(<span class=\"string\">&#x27;y&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">mp.tick_params(labelsize=<span class=\"number\">10</span>)</span><br><span class=\"line\">mp.grid(linestyle=<span class=\"string\">&#x27;:&#x27;</span>)</span><br><span class=\"line\">mp.scatter(x, y, c=<span class=\"string\">&#x27;blue&#x27;</span>, alpha=<span class=\"number\">0.8</span>, s=<span class=\"number\">60</span>, label=<span class=\"string\">&#x27;Sample Points&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.plot(x, pred_y, c=<span class=\"string\">&#x27;orangered&#x27;</span>, label=<span class=\"string\">&#x27;Regression&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">mp.legend()</span><br><span class=\"line\">mp.show()</span><br></pre></td></tr></table></figure>\n<pre><code>训练完成.\n保存模型完成.\n加载模型完成.\n</code></pre>\n<p><img src=\"ML_files/ML_39_1.png\" alt=\"png\"></p>\n<h2 id=\"信息论\">信息论</h2>\n<h3 id=\"两点分布信息熵\">两点分布信息熵</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 因为 ln0 无定义, 用此值模拟趋近 0</span></span><br><span class=\"line\">eps = <span class=\"number\">1e-5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># probability</span></span><br><span class=\"line\">p = np.linspace(eps, <span class=\"number\">1</span> - eps, <span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Information entropy</span></span><br><span class=\"line\">h = -(<span class=\"number\">1</span> - p) * np.log2(<span class=\"number\">1</span> - p) - p * np.log2(p)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(p, h, label=<span class=\"string\">&#x27;Information entropy&#x27;</span>, color=<span class=\"string\">&#x27;red&#x27;</span>, lw=<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Probability&#x27;</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Entropy&#x27;</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">&#x27;best&#x27;</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.grid(<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 结果中信息熵的峰值取决于 log 底数, e为底时峰值为0.7左右, 2为底峰值为1</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"ML_files/ML_41_0.png\" alt=\"png\"></p>\n<h3 id=\"基尼系数与-ln\">基尼系数与-ln</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">eps = <span class=\"number\">1e-4</span></span><br><span class=\"line\">p = np.linspace(eps, <span class=\"number\">1</span> - eps, <span class=\"number\">100</span>)</span><br><span class=\"line\">h = -(<span class=\"number\">1</span> - p) * np.log2(<span class=\"number\">1</span> - p) - p * np.log2(p)</span><br><span class=\"line\">gini = <span class=\"number\">2</span> * (<span class=\"number\">1</span> - p) * p</span><br><span class=\"line\"></span><br><span class=\"line\">plt.plot(p, gini, <span class=\"string\">&#x27;r-&#x27;</span>, lw=<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.plot(p, h / <span class=\"number\">2</span>, <span class=\"string\">&#x27;g-&#x27;</span>, lw=<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Gini(p) / Ln(p)&#x27;</span>, fontsize=<span class=\"number\">16</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;p&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;H&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.legend([<span class=\"string\">&#x27;Gini&#x27;</span>, <span class=\"string\">&#x27;Ln&#x27;</span>], loc=<span class=\"string\">&#x27;best&#x27;</span>, fontsize=<span class=\"number\">14</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"ML_files/ML_43_0.png\" alt=\"png\"></p>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"借物表-32\">借物表</h2>\n<p><a name='cite_note-1' href='#cite_ref-1'>[1]</a>: <a href=\"https://discover304.top/\">https://discover304.top/</a></p>\n<p><a name='cite_note-2' href='#cite_ref-2'>[2]</a>: <a href=\"https://www.bilibili.com/video/BV16L411w7oQ?p=6\">【上海交大】【腾讯】强强联合 机器学习+深度学习</a></p>\n<p><a name='cite_note-3' href='#cite_ref-3'>[3]</a>: <a href=\"https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\">The Ultimate Guide to 12 Dimensionality Reduction Techniques (with Python codes)</a></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">",
            "tags": [
                "人工智能",
                "机器学习",
                "信息论"
            ]
        },
        {
            "id": "https://weidows.github.io/post/experience/basic/%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/",
            "url": "https://weidows.github.io/post/experience/basic/%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/",
            "title": "👽通信-信息论-开坑自埋",
            "date_published": "2022-01-06T16:23:14.000Z",
            "content_html": "<h1>通信-信息论-开坑自埋</h1>\n<!--\n * @?: *********************************************************************\n * @Author: Weidows\n * @LastEditors: Weidows\n * @LastEditTime: 2022-04-20 23:15:55\n * @FilePath: \\Blog-private\\source\\_posts\\experience\\basic\\通信技术.md\n * @Description:\n * @!: *********************************************************************\n-->\n<blockquote class=\"pullquote mindmap mindmap-md\"><ul>\n<li><a href=\"#%E9%80%9A%E4%BF%A1-%E4%BF%A1%E6%81%AF%E8%AE%BA-%E5%BC%80%E5%9D%91%E8%87%AA%E5%9F%8B\">通信-信息论-开坑自埋</a>\n<ul>\n<li><a href=\"#wifi\">WIFI</a>\n<ul>\n<li><a href=\"#%E5%90%8D%E5%AD%97\">名字</a></li>\n<li><a href=\"#%E9%A2%91%E6%AE%B5\">频段</a></li>\n<li><a href=\"#%E8%B0%83%E5%88%B6%E6%89%8B%E6%AE%B5\">调制手段</a></li>\n<li><a href=\"#%E6%A0%87%E5%87%86%E5%88%B6%E5%AE%9A\">标准制定</a></li>\n<li><a href=\"#%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E9%99%85\">理论与实际</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2\">傅里叶变换</a>\n<ul>\n<li><a href=\"#%E5%BC%95%E8%A8%80\">引言</a></li>\n<li><a href=\"#fourier-transform\">fourier-transform</a></li>\n<li><a href=\"#%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8-%E9%99%A4%E5%99%AA\">实际应用-除噪</a></li>\n<li><a href=\"#inverse-fourier\">inverse-fourier</a></li>\n<li><a href=\"#%E8%B4%A8%E5%BF%83%E4%B8%8E%E5%82%85%E9%87%8C%E5%8F%B6%E5%85%AC%E5%BC%8F%E7%9A%84%E5%85%B3%E7%B3%BB\">质心与傅里叶公式的关系</a></li>\n<li><a href=\"#%E7%BC%BA%E7%82%B9\">缺点</a></li>\n<li><a href=\"#%E7%9F%AD%E6%97%B6%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2\">短时傅里叶变换</a></li>\n</ul>\n</li>\n<li><a href=\"#%E6%9E%81%E5%8C%96%E7%A0%81\">极化码</a>\n<ul>\n<li><a href=\"#%E4%BF%A1%E6%81%AF%E7%86%B5-%E5%A6%82%E4%BD%95%E5%BA%A6%E9%87%8F%E4%BF%A1%E6%81%AF\">信息熵-如何度量信息</a>\n<ul>\n<li><a href=\"#%E5%93%88%E7%89%B9%E8%8E%B1\">哈特莱</a></li>\n<li><a href=\"#%E9%A6%99%E5%86%9C\">香农</a></li>\n<li><a href=\"#%E5%9F%BA%E5%B0%BC%E7%B3%BB%E6%95%B0\">基尼系数</a></li>\n<li><a href=\"#%E6%AC%A7%E6%8B%89%E5%BC%8F-%E4%B8%A4%E7%82%B9%E5%88%86%E5%B8%83\">欧拉式-两点分布</a></li>\n<li><a href=\"#%E7%9B%B8%E5%AF%B9%E7%86%B5\">相对熵</a></li>\n<li><a href=\"#%E5%8D%95%E4%BD%8D\">单位</a></li>\n</ul>\n</li>\n<li><a href=\"#%E4%BF%A1%E9%81%93%E5%AE%B9%E9%87%8F-%E6%9C%80%E5%A4%A7%E4%BA%92%E4%BF%A1%E6%81%AF\">信道容量-最大互信息</a></li>\n<li><a href=\"#%E9%A6%99%E5%86%9C%E6%9E%81%E9%99%90\">香农极限</a></li>\n<li><a href=\"#%E6%9E%81%E5%8C%96%E7%A0%81-polarcodes\">极化码-PolarCodes</a></li>\n</ul>\n</li>\n<li><a href=\"#%E9%9F%B3%E9%A2%91\">音频</a>\n<ul>\n<li><a href=\"#%E6%9C%89-%E6%97%A0%E6%8D%9F%E5%8E%8B%E7%BC%A9\">有-无损压缩</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%80%9F%E7%89%A9%E8%A1%A8\">借物表</a></li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>draft 此文章点子来自: <a href=\"https://www.youtube.com/watch?v=4w6_zWSrZw4\">你不了解的「WiFi」从技术原理 应用 讲到行业的未来 一个视频彻底讲清楚 「硬核无线技术」系列视频 WiFi 篇</a><br>\n一串听下来发现对于通信这方面的知识还是很欠缺, 甚至有些家常知识点都没太了解.</p>\n</blockquote>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"WIFI\">WIFI</h2>\n<div class=\"video-container\"><iframe src=\"https://www.youtube.com/embed/4w6_zWSrZw4\" frameborder=\"0\" loading=\"lazy\" allowfullscreen></iframe></div>\n<h3 id=\"名字\">名字</h3>\n<p>音响领域有高保真 HIFI (High Fidelity), 之后出现的无线起名 WIFI (Wireless Fidelity),</p>\n<p>Science Fiction -&gt; SciFi (发音与上面类似,一方面考虑好记)</p>\n<hr>\n<h3 id=\"频段\">频段</h3>\n<p>2.4G 频段: 2.4~2.4835 GHz</p>\n<p>5G 频段: 5.15~5.85 GHz</p>\n<p>每个频段可分为若干信道(频宽从 1~160MHz 不等), 满足多连接/多设备<code>尽可能</code>不互相干扰下使用.</p>\n<ul>\n<li>\n<p>在小区/宿舍里经常发现信号范围内有一排别人的 WIFI/热点</p>\n<p>甭管有没有密码, 必然会对我们当前设备使用 WIFI 无线电信号<code>产生干扰</code></p>\n<p>2.4G 频段窄而且电磁波穿透力比 5G 频段强,另外默认用 2.4G 频段的设备多</p>\n<p>所以, 把自己的设备切换使用为 5G 频段可以<code>一定程度上抗干扰</code></p>\n</li>\n<li>\n<p>其实也不止 WIFI 影响 WIFI,还要好多设备也是用 2.4G 频段通信会有干扰:</p>\n<p>蓝牙,无线鼠标,无线录音麦…etc</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"调制手段\">调制手段</h3>\n<p>何为调制?</p>\n<blockquote>\n<p>把数字信号转为电磁波通过天线发送, 接收端再把电磁波解为数字信号的过程,如下图<br>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVPAl9.png\" alt=\"20220107015502\" /> <br>\n<a href=\"https://www.txrjy.com/thread-1080059-1-1.html\">https://www.txrjy.com/thread-1080059-1-1.html</a></p>\n</blockquote>\n<p>编/解码过程用到<a href=\"#%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2\">傅里叶变换和逆变</a></p>\n<ul>\n<li>\n<p>从 802.11b 到 802.11ax 应用的三种调制方式:</p>\n<p>802.11 (eight O two eleven, 0 读 O, dot 不用读)</p>\n<p>DSSS (D triple S, 直接序列扩频)</p>\n<p>FHSS (调频)</p>\n<p>OFDM (Orthogonal Frequency-Division Multiplexing. <code>正交频分复用</code>/同频分解多调制)</p>\n</li>\n<li>\n<p>由于民用频宽范围比较有限,DSSS 这种依靠大频宽保证可靠性的技术不适用,逐渐过渡到了 OFDM:</p>\n<p>这种调制方式大幅降低所需频宽, 图中上面为 OFDM</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVAkJA.png\" alt=\"20220107020556\" />\n</li>\n</ul>\n<hr>\n<h3 id=\"标准制定\">标准制定</h3>\n<p>上面所提到的 802.11 xxx 就是无线电协会所制定的 WIFI 标准, 其每次更新是为了规划未来一段时间的 WIFI 走向, 避免各做各的无法正常通信.</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVPvZm.png\" alt=\"20220107023524\" />\n<p>802.11ac 引入波束赋形 Beam Forming, 追踪设备并把信号尽可能聚束到此方向</p>\n<p>2019 年协会才把标准整体命名为 WIFI1-WIFI6, 调制方式 OFDM -&gt; OFDMA(4GLTE 蜂窝网络的调制方式)</p>\n<p>WIFI 发展越加偏向/近似蜂窝网络</p>\n<hr>\n<h3 id=\"理论与实际\">理论与实际</h3>\n<ul>\n<li>\n<p>无线通信理论速率与实际速率差距蛮大的:</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GV47CT.png\" alt=\"20220107030252\" />\n<p>生活中都有经验,离路由器越近越好</p>\n</li>\n<li>\n<p>用不用追新设备?</p>\n<p>先上结论: <code>不用</code></p>\n<p>我们大多数人不咋组内网,组内网的话也是插线而不是走 WIFI,路由器唯一线路就是走公网</p>\n<p>路由器跑的快不快在于宽带套餐,100-300M 宽带还是绝大部分家庭/学校的选择,而出于 2013 年的 WIFI5 标准完完全全够跑满</p>\n<p>WIFI6 标准的路由器可以认为, 杀鸡用牛刀</p>\n</li>\n</ul>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"傅里叶变换\">傅里叶变换</h2>\n<h3 id=\"引言\">引言</h3>\n<blockquote>\n<p><a href=\"https://mp.weixin.qq.com/s/iD4aLGwQuYVzXfFkfMfVxg\">傅里叶变换的精彩讲解</a> <br>\n简单来说傅里叶变换的作用: <code>从混合的波(声波/电磁波)中分离出某个频率的波</code></p>\n<p>高数确实是一门神秘且棘手的学科,所以听到这个傅里叶变换心理也是略有抵触的. <br>\n后话: 不做应用的单纯的数学雀食烦…但是结合应用的话就有趣起来了 <code>\\(^o^)/</code></p>\n</blockquote>\n<ul>\n<li>\n<p>多个不同频率的波叠加</p>\n<p>傅里叶变换就是在研究如何从混合波中分析出其组成波 (类似从混合色中分析原色)</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GV4UWD.png\" alt=\"20220113234230\" />\n</li>\n</ul>\n<hr>\n<h3 id=\"fourier-transform\">fourier-transform</h3>\n<ul>\n<li>\n<p>对于某个混合波,我们想知道它是<code>哪几种波</code>混合的结果,如何得知?</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVL9X0.png\" alt=\"20220114170236\" />\n<ol>\n<li>\n<p>我们把波形绕成环,并且可以调整 <code>cycles/second -&gt; Frequency</code> 的比例</p>\n</li>\n<li>\n<p>视圆环图像质量均匀,取<code>&quot;质心 center of mass&quot;</code> 的坐标 (x,y)</p>\n</li>\n<li>\n<p>取 x 坐标为 Y 轴, Frequency 为 X 轴作图</p>\n</li>\n<li>\n<p>可见 2Hz+3Hz 的波,Frequency 在 2 和 3 出出现明显波峰</p>\n</li>\n</ol>\n<hr>\n</li>\n<li>\n<p>分别叠加也符合:</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVLaMS.png\" alt=\"20220114172006\" />\n</li>\n</ul>\n<hr>\n<h3 id=\"实际应用-除噪\">实际应用-除噪</h3>\n<ul>\n<li>\n<p>比如现有声波里有一个已知高频噪音 (蚊子),但我们无法从声波中直接过滤掉,如何去掉它?</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GV4Kxo.png\" alt=\"20220114174154\" />\n<ol>\n<li>\n<p>做傅里叶变换</p>\n</li>\n<li>\n<p>找到那个频率的波峰并通过某种方法干掉它</p>\n</li>\n<li>\n<p>傅里叶反变换得到没有蚊子叫的声波</p>\n</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h3 id=\"inverse-fourier\">inverse-fourier</h3>\n<p>对傅里叶变换的图像再次变换可以<code>大致</code>获得原始波</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVANO9.png\" alt=\"20220114174856\" />\n<hr>\n<h3 id=\"质心与傅里叶公式的关系\">质心与傅里叶公式的关系</h3>\n<ul>\n<li>\n<p>&quot;质心&quot;实际指的就是公式变换的结果,下面分别为离散/连续的计算公式</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVtUo6.png\" alt=\"20220114175932\" />\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVASN1.png\" alt=\"20220114180011\" />\n<hr>\n</li>\n<li>\n<p>需要注意的是,上面公式与傅里叶变换公式有小小的区别:</p>\n<p>上面的公式只是在求 <code>单点</code>,实际傅里叶变换公式不需要除以时间</p>\n<p>使得对应频率的 x 根据时间 t 倍增延长 (也就是变换后产生波峰的原因)</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVLYsv.png\" alt=\"20220114182317\" />\n<hr>\n</li>\n<li>\n<p>比如某频率的波持续 3 秒,其对应大小乘 3 倍</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVFTHD.png\" alt=\"20220114182518\" />\n<p>持续时间越长,对应频率的波峰越大</p>\n</li>\n</ul>\n<hr>\n<h3 id=\"缺点\">缺点</h3>\n<p>比如有一段 2s 的声波,第一秒为 1Hz,第二秒为 2Hz</p>\n<p>通过傅里叶变换只能识别出存在 1Hz 和 2Hz 的波,并可以比较持续时间,但并不能分析其在时间轴上的定位</p>\n<p>针对其不能时频联合分析的缺点, 出现了 <code>短时傅里叶变换</code></p>\n<hr>\n<h3 id=\"短时傅里叶变换\">短时傅里叶变换</h3>\n<blockquote>\n<p><a href=\"https://www.eet-china.com/mp/a77376.html\">一文道破傅里叶变换的本质，优缺点一目了然</a></p>\n</blockquote>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"极化码\">极化码</h2>\n<style>.bbplayer{width: 100%; max-width: 850px; margin: auto}</style><div class=\"bbplayer\"><iframe class=\"bbplayer\" id=\"mmedia-TgadWYmMnXOFrsyS\" src=\"https://player.bilibili.com/player.html?bvid=BV1fq4y1g7hq&page=1&high_quality=1&danmaku=true\" allowfullscreen=\"allowfullscreen\" scrolling=\"no\" border=\"0\" frameborder=\"0\" framespacing=\"0\" sandbox=\"allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups\"></iframe></div><script> document.getElementById(\"mmedia-TgadWYmMnXOFrsyS\").style.height=document.getElementById(\"mmedia-TgadWYmMnXOFrsyS\").scrollWidth*0.76+\"px\";\n    window.onresize = function(){\n      document.getElementById(\"mmedia-TgadWYmMnXOFrsyS\").style.height=document.getElementById(\"mmedia-TgadWYmMnXOFrsyS\").scrollWidth*0.76+\"px\";\n    }; </script>\n<h3 id=\"信息熵-如何度量信息\">信息熵-如何度量信息</h3>\n<p><a href=\"../../../public-post/notebook/ML#%E4%B8%A4%E7%82%B9%E5%88%86%E5%B8%83%E4%BF%A1%E6%81%AF%E7%86%B5\">所用代码及结果展示</a></p>\n<h4 id=\"哈特莱\">哈特莱</h4>\n<p>哈特莱首先提出使用对数 log 来描述信息</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>后称信息熵</mtext><mo>:</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>n</mi><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><mi>s</mi><mo>=</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>10</mn></msub><msup><mi>s</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">后称信息熵: H(p) = n\\log_{10} s = \\log_{10} s^{n}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord cjk_fallback\">后称信息熵</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9386em;vertical-align:-0.2441em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">10</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9585em;vertical-align:-0.2441em;\"></span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">10</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>信息符合加法: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>h</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h(x,y)=h(x)+h(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>概率符合乘法: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">p(x,y)=p(x)p(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>log 可以把乘法变加法: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\log p(x,y) = \\log p(x)p(y) = \\log p(x)+\\log p(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>操作原理就是 <code>通过概率间接量化信息</code>, 哈特莱这里底数取得是 10, 下面香农改为了 2 (更适合计算机计算)</p>\n<hr>\n<h4 id=\"香农\">香农</h4>\n<ul>\n<li>\n<p>香农首先提出信息熵来度量信息,可以粗略解释为:</p>\n<p>n 个连续的 “是(1)” 或 “否(0)” 可以消除 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">2^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6644em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span> 比特内容的不确定性(疑义度)</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>信息熵</mtext><mo>:</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><mi>k</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">信息熵: H(p) = -k \\sum_{i=1}^{n} p_{i} \\log_{2} p_{i}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord cjk_fallback\">信息熵</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9291em;vertical-align:-1.2777em;\"></span><span class=\"mord\">−</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>比如:</p>\n<blockquote>\n<p>常用的汉字大约有 7000 个,假设每个字使用概率相等,至少需要用 13 比特表示才能完全消除一个字的疑义度 (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mn>13</mn></msup></mrow><annotation encoding=\"application/x-tex\">2^{13}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">13</span></span></span></span></span></span></span></span></span></span></span></span>=8192 &gt; 7000) <br>\n那么在此条件下每个字的信息熵为 13 比特 <br>\n现实中每个字的使用频率概率, 出现场景, 上下文关联都会影响实际的信息熵 (比如文盲说话的信息熵不如学者高) <br>\n<a href=\"https://blog.csdn.net/chenKFKevin/article/details/72074250\">信息的度量——信息熵</a></p>\n</blockquote>\n</li>\n<li>\n<p>关于为什么前面带了个 <code>-k</code></p>\n<blockquote>\n<p>与直觉相反, 一个事件发生概率越大,实际所带的信息越小<br>\n比如太阳从东边升起,没什么信息含量; 换为从西边升起,即使概率无限接近 0, 它所含信息权重也是很高的 <sup id='cite_ref-3'><a href=\"#cite_note-3\">[3]</a></sup></p>\n</blockquote>\n<p><img src=\"https://www.helloimg.com/images/2022/04/11/RtspVm.png\" alt=\"\"></p>\n</li>\n<li>\n<p>具体计算一个:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.1</mn><mo>⋅</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo stretchy=\"false\">(</mo><mn>0.1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.33</mn><mspace linebreak=\"newline\"></mspace><mi>H</mi><mo stretchy=\"false\">(</mo><mn>0.2</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.2</mn><mo>⋅</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo stretchy=\"false\">(</mo><mn>0.2</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.46</mn><mspace linebreak=\"newline\"></mspace><mi>H</mi><mo stretchy=\"false\">(</mo><mn>0.3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.3</mn><mo>⋅</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo stretchy=\"false\">(</mo><mn>0.3</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.52</mn></mrow><annotation encoding=\"application/x-tex\">H(0.1) = 0.1 \\cdot log_2 (0.1) = 0.33 \\\\\nH(0.2) = 0.2 \\cdot log_2 (0.2) = 0.46 \\\\\nH(0.3) = 0.3 \\cdot log_2 (0.3) = 0.52\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord\">0.1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">0.1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.33</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord\">0.2</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">0.2</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.46</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord\">0.3</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.3</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">0.3</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.52</span></span></span></span></span></p>\n</li>\n</ul>\n<hr>\n<h4 id=\"基尼系数\">基尼系数</h4>\n<p><img src=\"https://www.helloimg.com/images/2022/04/13/R4tdlM.png\" alt=\"\"></p>\n<p>我们把曲线 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">- \\log P</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span></span></span></span> 换为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>−</mo><mi>P</mi></mrow><annotation encoding=\"application/x-tex\">1-P</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span></span></span></span>, 得到的就是基尼系数</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>基尼系数</mtext><mo>:</mo><mi>G</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msubsup><mi>p</mi><mi>i</mi><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">基尼系数: G(p)\n= \\sum_{i=1}^{n} p_i (1-p_i)\n= 1- \\sum_{i=1}^{n} p_{i}^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord cjk_fallback\">基尼系数</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">G</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9291em;vertical-align:-1.2777em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9291em;vertical-align:-1.2777em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641em;\"><span style=\"top:-2.453em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>基尼系数与熵是十分近似的, 在决策树中可以用基尼系数来代替熵 (效率更高)</p>\n<p><a href=\"https://www.bilibili.com/video/BV16L411w7oQ?p=6&amp;t=3716.0\">第二定义: 社会财富分配</a></p>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h4 id=\"欧拉式-两点分布\">欧拉式-两点分布</h4>\n<ul>\n<li>\n<p>两点分布的熵:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>令</mtext><mi>P</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>p</mi><mspace width=\"2em\"/><mi>p</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mi>p</mi><mspace linebreak=\"newline\"></mspace><mtext> </mtext><mspace linebreak=\"newline\"></mspace><mtable rowspacing=\"0.25em\" columnalign=\"right left\" columnspacing=\"0em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mo>−</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>−</mo><mi>p</mi><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mi>p</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>⋅</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo>−</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">]</mo><mo>+</mo><mi>p</mi><mo>⋅</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"true\"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><mi>p</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy=\"false\">)</mo></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding=\"application/x-tex\">令 P(0) = 1-p \\qquad p(1) = p\n\n\\\\ \\ \\\\\n\n\\begin{aligned}\n  H(p)\n  &amp;= - (1-p) \\log_2 (1-p) - p \\log_2 p \\\\\n\n  Gini(p)\n  &amp;= (1-p) \\cdot [1-(1-p)] + p \\cdot (1-p) \\\\\n  &amp;= 2p(1-p)\n\\end{aligned}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord cjk_fallback\">令</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:2em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0em;\"></span><span class=\"mspace\"> </span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:4.5em;vertical-align:-2em;\"></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-r\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.5em;\"><span style=\"top:-4.66em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span></span></span><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">G</span><span class=\"mord mathnormal\">ini</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span></span></span><span style=\"top:-1.66em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2em;\"><span></span></span></span></span></span><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.5em;\"><span style=\"top:-4.66em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">−</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.207em;\"><span style=\"top:-2.4559em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2441em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">p</span></span></span><span style=\"top:-3.16em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)]</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span></span></span><span style=\"top:-1.66em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><img src=\"https://www.helloimg.com/images/2022/04/13/R4tKlh.png\" alt=\"\"></p>\n<p>可见在概率为 0.5 时,信息熵 (不确定度) 最高</p>\n</li>\n</ul>\n<hr>\n<h4 id=\"相对熵-2\">相对熵</h4>\n<p>也叫互熵/交叉熵/鉴别信息/Kullback 熵/KL 散度/K-L 距离…</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>D</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>q</mi><mo stretchy=\"false\">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mfrac><msub><mi>p</mi><mi>i</mi></msub><msub><mi>q</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding=\"application/x-tex\">D(p||q) = \\sum_{i=1}^{n} p_{i} \\log{\\frac{p_i}{q_i}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord\">∣∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9291em;vertical-align:-1.2777em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8804em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span></p>\n<hr>\n<h4 id=\"单位\">单位</h4>\n<ul>\n<li>\n<p>经典熵底数为 2,单位为 bit</p>\n<p>在做数据分析时有用 e 为底数的定义, 单位为 nat (奈特)</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><mi>k</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>p</mi><mi>i</mi></msub><mi>ln</mi><mo>⁡</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">H(p) = -k \\sum_{i=1}^{n} p_{i} \\ln p_{i}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.9291em;vertical-align:-1.2777em;\"></span><span class=\"mord\">−</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6514em;\"><span style=\"top:-1.8723em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.05em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2777em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">ln</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n</li>\n</ul>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h3 id=\"信道容量-最大互信息\">信道容量-最大互信息</h3>\n<ul>\n<li>\n<p>信道容量(Channel Capacity) 也叫最大互信息</p>\n<blockquote>\n<p>互信息: <code>它是一个随机变量包含另一个随机变量信息量的度量</code></p>\n</blockquote>\n<p>比如一条河从 A-&gt;B 端, 但只有 70% 的河水能流到 B,其他的河水流失了; 那么在这里 A-&gt;B 端河水的互信息为 70%</p>\n<p>当然, 互信息的度量单位并不是百分比, 概念上也略有偏颇</p>\n<blockquote>\n<p>视频中的例子: X-&gt;Y 传递信息熵为 <code>H(X)</code> 的信息, 传递过程中丢失/不能还原的信息熵为 <code>H(X|Y)</code>, 那么</p>\n</blockquote>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>互信息</mtext><mo>:</mo><mi>I</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mi mathvariant=\"normal\">∣</mi><mi>Y</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo><mo>−</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mi mathvariant=\"normal\">∣</mi><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">互信息: I(X|Y) = H(X) - H(X|Y)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord cjk_fallback\">互信息</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<hr>\n</li>\n<li>\n<p>什么是信道/信道容量? 举个栗子:</p>\n<p>有个工厂里有好多流水线从 A-&gt;B 处输送产品; 每条流水线可以理解为是一个信道</p>\n<p>流水线运输速度太快会使产品不合格,需要限制在 T 时间内运输 N(T) 件产品才可以保证质量; 同样道理通信时一味地加速发送会使通信状态变差,也需要限制在一定范围之内,<code>这个范围就是信道容量</code></p>\n<p>(理论条件下,单位时间内可以传过去的信息量)</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>信道容量</mtext><mo>:</mo><mi>C</mi><mo>=</mo><msub><mrow><mi mathvariant=\"normal\">Lim</mi><mo>⁡</mo></mrow><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></msub><mfrac><mrow><mi>log</mi><mo>⁡</mo><mi>N</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">信道容量: C=\\operatorname{Lim}_{T \\rightarrow \\infty} \\frac{\\log N(T)}{T}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord cjk_fallback\">信道容量</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.113em;vertical-align:-0.686em;\"></span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">Lim</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<hr>\n</li>\n</ul>\n<h3 id=\"香农极限\">香农极限</h3>\n<p>实际条件下,通信接收方会因为丢包/信号干扰/磁场等<code>噪声</code>无法接收到部分信息,导致无法真实达到信道容量</p>\n<p>香农提出通过合适的编码,信道容量 C 可以被尽可能的无限逼近,但对于大于 C 的速率不成立.<code>即香农极限</code>(香农提出,后人证明)</p>\n  <img src=\"https://www.helloimg.com/images/2022/02/27/GV4j4v.png\" alt=\"20220203184654\" />\n<hr>\n<ul>\n<li>\n<p>经典教材计算机网络也有提及</p>\n<p><img src=\"https://www.helloimg.com/images/2022/03/03/Gh3Pnz.png\" alt=\"\"></p>\n<p><img src=\"https://www.helloimg.com/images/2022/03/03/Gh3a7A.png\" alt=\"Gh3a7A.png\"></p>\n</li>\n</ul>\n<hr>\n<h3 id=\"极化码-PolarCodes\">极化码-PolarCodes</h3>\n<ul>\n<li>\n<p>核心思想: 通过异或操作把信息分流</p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVPxut.png\" alt=\"20220203221617\" />\n<p>通过异或操作,把信道一/二两个实际信道转换成信道<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mo>−</mo></msup><mi mathvariant=\"normal\">/</mi><msup><mi>W</mi><mo>+</mo></msup></mrow><annotation encoding=\"application/x-tex\">W^-/W^+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0213em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7713em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">−</span></span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7713em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span></span></span></span></span></span></span></span></span></p>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GVSFtR.png\" alt=\"20220203222548\" />\n<p>这里可能会疑惑信道<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mo>+</mo></msup></mrow><annotation encoding=\"application/x-tex\">W^+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7713em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7713em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span></span></span></span></span></span></span></span></span>第四种情况 “U2=U1=Y1” 中 U1 从何得知?</p>\n<p>实际上这里我们让<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>W</mi><mo>−</mo></msup></mrow><annotation encoding=\"application/x-tex\">W^-</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7713em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7713em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">−</span></span></span></span></span></span></span></span></span></span></span>信道不传输信息,U1 是通信双方预先约定好的内容</p>\n<hr>\n</li>\n<li>\n<p>当处理的码长(信道数)足够多时,好信道的互信息会无限逼近 1 <sup id='cite_ref-1'><a href=\"#cite_note-1\">[1]</a></sup></p>\n<blockquote>\n<img src=\"https://www.helloimg.com/images/2022/02/27/GV4Ent.png\" alt=\"20220203224853\" />\n</blockquote>\n<p>当然凡事不是越多越好:</p>\n<ol>\n<li>\n<p>这里信息传输的条件是<code>信道连接能保持稳定</code></p>\n</li>\n<li>\n<p>每增加信道数,需要做的处理指数级增长</p>\n</li>\n</ol>\n<hr>\n</li>\n</ul>\n<p>具体如何编码/构建, 详见论文 <sup id='cite_ref-1'><a href=\"#cite_note-1\">[1]</a></sup> (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mtext>🥵</mtext><mrow><mi>h</mi><mi>a</mi><mi>r</mi><mi>d</mi></mrow><mrow><mi>t</mi><mi>o</mi><mi>o</mi></mrow></msubsup></mrow><annotation encoding=\"application/x-tex\">🥵 ^{too}_{hard}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0767em;vertical-align:-0.2831em;\"></span><span class=\"mord\"><span class=\"mord\">🥵</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7936em;\"><span style=\"top:-2.4169em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">ha</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal mtight\">d</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">oo</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2831em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"音频\">音频</h2>\n<h3 id=\"有-无损压缩\">有-无损压缩</h3>\n<p>对于大部分人的<code>木耳</code>来说,完全听不出来差别; 极小部分人<code>金耳</code>才能听出来 (年轻,耳朵从出生没受过损伤)</p>\n<p>可以试试双盲测试: <sup id='cite_ref-2'><a href=\"#cite_note-2\">[2]</a></sup></p>\n<p><a href=\"https://www.zhihu.com/question/20699962\">耳机厂商为什么不把耳机煲好了再卖？</a></p>\n<p><a><img src=\"https://cdn.jsdelivr.net/gh/Weidows/Images/img/divider.png\" alt=\"分割线\"></a></p>\n<h2 id=\"借物表-26\">借物表</h2>\n<p><a name='cite_note-1' href='#cite_ref-1'>[1]</a>: <a href=\"https://res-www.zte.com.cn/mediares/magazine/publication/com_cn/article/201901/cn201901004.pdf\">“太极混一”——极化码原理及 5G 应用</a></p>\n<p><a name='cite_note-2' href='#cite_ref-2'>[2]</a>: <a href=\"http://www.erji.net/forum.php?mod=viewthread&amp;tid=1598502\">【双盲测试】你听得出有损和无损的区别么</a></p>\n<p><a name='cite_note-3' href='#cite_ref-3'>[3]</a>: <a href=\"https://www.bilibili.com/video/BV16L411w7oQ?p=6\">https://www.bilibili.com/video/BV16L411w7oQ?p=6</a></p>\n<script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kity@2.0.4/dist/kity.min.js\"></script><script type=\"text&#x2F;javascript\" src=\"https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js\"></script><script defer=\"true\" type=\"text&#x2F;javascript\" src=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js\"></script><link rel=\"stylesheet\" type=\"text&#x2F;css\" href=\"https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css\">",
            "tags": [
                "笔记",
                "通信",
                "音频",
                "傅里叶变换",
                "极化码",
                "信息论"
            ]
        }
    ]
}