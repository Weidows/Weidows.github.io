<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://weidows.github.io</id>
    <title>⭐️齐下无贰⭐️ • Posts by &#34;深度学习&#34; tag</title>
    <link href="https://weidows.github.io" />
    <updated>2022-07-10T13:21:09.000Z</updated>
    <category term="备忘录" />
    <category term="API" />
    <category term="Twitter" />
    <category term="cloudflare" />
    <category term="推荐" />
    <category term="浏览器" />
    <category term="扩展" />
    <category term="FFmpeg" />
    <category term="算法" />
    <category term="hexdump" />
    <category term="HLS" />
    <category term="openssl" />
    <category term="shell" />
    <category term="密码学" />
    <category term="QQ" />
    <category term="PS" />
    <category term="设计" />
    <category term="配色" />
    <category term="架构" />
    <category term="公司" />
    <category term="管理" />
    <category term="doing" />
    <category term="ideas" />
    <category term="design" />
    <category term="摄影" />
    <category term="SSH" />
    <category term="Linux" />
    <category term="Regex" />
    <category term="yaml" />
    <category term="生活" />
    <category term="游戏" />
    <category term="哲学" />
    <category term="Dev" />
    <category term="医学" />
    <category term="健身" />
    <category term="猫" />
    <category term="笔记" />
    <category term="工作" />
    <category term="闲鱼" />
    <category term="购物" />
    <category term="English" />
    <category term="VScode" />
    <category term="IDEA" />
    <category term="HTML" />
    <category term="CSS" />
    <category term="JavaScript" />
    <category term="成长路线" />
    <category term="基础知识" />
    <category term="Java" />
    <category term="cpp" />
    <category term="Python" />
    <category term="工具" />
    <category term="大前端" />
    <category term="Font" />
    <category term="VR" />
    <category term="网课" />
    <category term="Manjaro" />
    <category term="操作系统" />
    <category term="服务器" />
    <category term="虚拟机" />
    <category term="树莓派" />
    <category term="Windows" />
    <category term="office" />
    <category term="Docker" />
    <category term="多线程" />
    <category term="进程" />
    <category term="CPU" />
    <category term="Scoop" />
    <category term="Maven" />
    <category term="Git" />
    <category term="nodejs" />
    <category term="wsl2" />
    <category term="Aria2" />
    <category term="PyCharm" />
    <category term="Goland" />
    <category term="图床" />
    <category term="爬虫" />
    <category term="SM.MS" />
    <category term="package" />
    <category term="homebrew" />
    <category term="Tomcat" />
    <category term="Website" />
    <category term="AI" />
    <category term="GPT" />
    <category term="手机" />
    <category term="耳机" />
    <category term="电脑" />
    <category term="npm" />
    <category term="yarn" />
    <category term="LeetCode" />
    <category term="数据结构" />
    <category term="面试" />
    <category term="OpenGL" />
    <category term="C" />
    <category term="conan" />
    <category term="计网" />
    <category term="硬件" />
    <category term="OneNote" />
    <category term="复变函数" />
    <category term="人工智能" />
    <category term="通信" />
    <category term="音频" />
    <category term="傅里叶变换" />
    <category term="极化码" />
    <category term="信息论" />
    <category term="SQL" />
    <category term="前端" />
    <category term="JSON" />
    <category term="Mariadb" />
    <category term="后端" />
    <category term="k8s" />
    <category term="天文学" />
    <category term="物理" />
    <category term="LaTeX" />
    <category term="Butterfly" />
    <category term="KaTeX" />
    <category term="Math" />
    <category term="research" />
    <category term="math" />
    <category term="dataset" />
    <category term="深度学习" />
    <category term="点云" />
    <category term="自动驾驶" />
    <category term="Color" />
    <category term="创业" />
    <category term="Javadoc" />
    <category term="编码" />
    <category term="设计模式" />
    <category term="JVM" />
    <category term="Lambda" />
    <category term="CORS" />
    <category term="JQuery" />
    <category term="Vue" />
    <category term="Cmake" />
    <category term="区块链" />
    <category term="Golang" />
    <category term="tools" />
    <category term="doc" />
    <category term="Markdown" />
    <category term="markdown" />
    <category term="slidev" />
    <category term="PHP" />
    <category term="Processing" />
    <category term="Anaconda" />
    <category term="python" />
    <category term="opengl" />
    <category term="PowerShell" />
    <category term="zsh" />
    <category term="宝塔面板" />
    <category term="guitar" />
    <category term="music" />
    <category term="音乐" />
    <category term="心理学" />
    <category term="搞笑" />
    <category term="高能" />
    <category term="微信" />
    <category term="relationship" />
    <category term="快捷键" />
    <category term="theme" />
    <category term="AWS" />
    <category term="Server" />
    <category term="Ubuntu" />
    <category term="alist" />
    <category term="system" />
    <category term="蓝易云" />
    <category term="Hexo" />
    <category term="Github" />
    <category term="Gitee" />
    <category term="Action" />
    <category term="branch" />
    <category term="release" />
    <category term="Copilot" />
    <category term="插件" />
    <category term="Emmet" />
    <category term="美化" />
    <category term="snippet" />
    <category term="SEO" />
    <category term="Pjax" />
    <category term="butterfly" />
    <category term="pug" />
    <category term="styl" />
    <category term="优化" />
    <category term="魔改" />
    <category term="MyBatis" />
    <category term="Map" />
    <category term="CRUD" />
    <category term="日志" />
    <category term="分页" />
    <category term="数据库" />
    <category term="注解" />
    <category term="MySQL" />
    <category term="JDBC" />
    <category term="JavaWeb" />
    <category term="Servlet" />
    <category term="Cookie" />
    <category term="Session" />
    <category term="JSP" />
    <category term="Filter" />
    <category term="对象" />
    <category term="反射" />
    <category term="机器学习" />
    <category term="MMDetection" />
    <category term="Colab" />
    <category term="概率论" />
    <entry>
        <id>https://weidows.github.io/post/experience/research/research/</id>
        <title>⏲️误入科研海</title>
        <link rel="alternate" href="https://weidows.github.io/post/experience/research/research/"/>
        <content type="html">&lt;h1&gt;误入科研海&lt;/h1&gt;
&lt;!--
 * @?: *********************************************************************
 * @Author: Weidows
 * @LastEditors: Weidows
 * @LastEditTime: 2023-04-20 18:28:55
 * @FilePath: \Blog-private\source\_posts\experience\research\research.md
 * @Description:
 * @!: *********************************************************************
--&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-md&#34;&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E8%AF%AF%E5%85%A5%E7%A7%91%E7%A0%94%E6%B5%B7&#34;&gt;误入科研海&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%BA%8F&#34;&gt;序&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%85%B3%E4%BA%8E%E8%B0%83%E7%A0%94&#34;&gt;关于调研&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C&#34;&gt;一些经验&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%AD%A6%E4%BC%9A%E6%8B%86%E5%AD%97&#34;&gt;学会拆字&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E8%AF%BB%E8%AE%BA%E6%96%87&#34;&gt;读论文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%89%BE%E8%AE%BA%E6%96%87&#34;&gt;找论文&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E7%82%B9%E4%BA%91&#34;&gt;点云&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7&#34;&gt;分析工具&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cloudcompare&#34;&gt;CloudCompare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pcd-decode&#34;&gt;PCD-Decode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%9F%90%E6%AC%A1%E7%BB%84%E4%BC%9A%E5%88%86%E4%BA%AB&#34;&gt;某次组会分享&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E7%BB%84%E6%88%90%E6%88%90%E5%88%86-%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2%E5%88%86%E6%9E%90&#34;&gt;组成成分-数据转换分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#virtuallidar-%E8%BD%AC%E6%8D%A2%E5%92%8C%E7%BB%84%E6%88%90&#34;&gt;VirtualLiDAR-转换和组成&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5-%E9%85%8D%E5%87%86%E9%97%AE%E9%A2%98&#34;&gt;时间同步-配准问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E8%99%9A%E6%8B%9F%E9%97%AE%E9%A2%98%E5%8F%8A%E5%8F%8C%E7%AB%AF%E4%BB%BB%E5%8A%A1%E6%B5%81&#34;&gt;虚拟问题及双端任务流&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98&#34;&gt;标注问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%85%B6%E5%AE%83%E9%97%AE%E9%A2%98&#34;&gt;其它问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%AC%A7%E9%98%B3%E8%80%81%E5%B8%88%E7%BB%99%E7%9A%84%E6%8F%90%E8%AE%AE&#34;&gt;欧阳老师给的提议&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#auto-mos&#34;&gt;auto-mos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%80%9F%E7%89%A9%E8%A1%A8&#34;&gt;借物表&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;序&#34;&gt;序&lt;/h2&gt;
&lt;p&gt;偶然的机会进了某大学的 Lab (简历里写了), 很感谢某位大佬 🥰&lt;/p&gt;
&lt;p&gt;就这样, 下面记一些个人经验…&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;关于调研&#34;&gt;关于调研&lt;/h2&gt;
&lt;p&gt;师姐开会时经常提到, 要站在第三人称视角读 paper, 不要被代入读者身份或者完全顺着作者思路思考&lt;/p&gt;
&lt;p&gt;now.clear, 意思大概就是: &lt;code&gt;how &amp;gt; what&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;how they think, not what…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;how they do, not what…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;how they show, not what…&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在做调研时着重看下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;paper 提出的问题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何着手解决和实现 (精髓就是 1. -&amp;gt; 2. 中间的思路, 应该叫&lt;code&gt;问题建模&lt;/code&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于优秀和有借鉴价值的实现, 可以看一看. 至于研究背景, 结果分析对比之类的, 是作者为了给 paper 加分, 对我们调研没啥用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;一些经验&#34;&gt;一些经验&lt;/h2&gt;
&lt;h3 id=&#34;学会拆字&#34;&gt;学会拆字&lt;/h3&gt;
&lt;p&gt;听到一个概念不要马上去大脑数据库搜索, 之所以叫脑海, 是因为它有乱流和旋涡&lt;/p&gt;
&lt;p&gt;比如 &lt;code&gt;元数据&lt;/code&gt; 这个词, 乍一听很抽象是吧, 脑子也能马上返回 Metadata 这个词, 但具体想解释就会云里雾里&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;‘元’即为’关于…的’, 所以一组元数据是指’一组关于 xxx 的映射数据’ &lt;sup id=&#39;cite_ref-1&#39;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;读论文&#34;&gt;读论文&lt;/h3&gt;
&lt;p&gt;入门时还是相当困难的, 拿过来一篇英文文献不知道怎么下手, 来回翻译也不知所云&lt;/p&gt;
&lt;p&gt;所以还是建议练一下 &lt;code&gt;论文跟读&lt;/code&gt; &lt;sup id=&#39;cite_ref-2&#39;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;按注意力/重要程度分级:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;abstract: 60%&lt;/p&gt;
&lt;p&gt;现状 &amp;amp; paper 大体上做了什么&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;introduction: 80%&lt;/p&gt;
&lt;p&gt;paper 为什么要做这个工作&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;related works: 50%&lt;/p&gt;
&lt;p&gt;别人怎么做的, 同时支撑起本 paper 的意义和推进&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;contributions/goal: 80%&lt;/p&gt;
&lt;p&gt;此工作做了哪些要点 (大标题的作用)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;figure image: 100%&lt;/p&gt;
&lt;p&gt;好的论文, 营养全浓缩在图里&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LaTeX math: 40%~90%&lt;/p&gt;
&lt;p&gt;公式虽然很优雅, 但是远不如图直观, 除非想深入研究改进, 不然不建议耗费蛮力看公式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;experiment: 20%~50%&lt;/p&gt;
&lt;p&gt;一般是作为论文科学性和可行性的支撑, 大部分是给审稿人看的, 除非想入手复现研究此工作, 但更建议去代码库研究&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conclusion: 30%&lt;/p&gt;
&lt;p&gt;大多数都是走个形式, 没啥作用的段落…&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;找论文&#34;&gt;找论文&lt;/h3&gt;
&lt;p&gt;关键词, 关键词, 关键词!&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Zh_CN&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;En&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;综述&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;survey, overview, review&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;点云&#34;&gt;点云&lt;/h2&gt;
&lt;p&gt;没地方写了, 暂时写在这…&lt;/p&gt;
&lt;h3 id=&#34;分析工具&#34;&gt;分析工具&lt;/h3&gt;
&lt;h4 id=&#34;CloudCompare&#34;&gt;CloudCompare&lt;/h4&gt;
&lt;p&gt;默认密度颜色 蓝-&amp;gt;绿-&amp;gt;黄-&amp;gt;红&lt;/p&gt;
&lt;p&gt;双击右键拖动, 按下中键上下移动会缩放&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;PCD-Decode&#34;&gt;PCD-Decode&lt;/h4&gt;
&lt;p&gt;如下通过 ImHex 提取出来的 PCD 文件头, 第三行说的是含有反射率 intensity 信息&lt;/p&gt;
&lt;figure class=&#34;highlight apache&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# .PCD v0.7 - Point Cloud Data file format&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;VERSION&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;.&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;FIELDS&lt;/span&gt; x y z intensity&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;SIZE&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;TYPE&lt;/span&gt; F F F F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;COUNT&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;WIDTH&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;54298&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;HEIGHT&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;VIEWPOINT&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;POINTS&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;54298&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;DATA&lt;/span&gt; binary_compressed&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;attribute&#34;&gt;5&lt;/span&gt;�&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;某次组会分享&#34;&gt;某次组会分享&lt;/h3&gt;
&lt;h4 id=&#34;组成成分-数据转换分析&#34;&gt;组成成分-数据转换分析&lt;/h4&gt;
&lt;p&gt;此数据集并没很清晰的给出制作流程/数据流向, 分析起来难在这里, 就像是分析饭店里的菜是怎么做的一样, 知道原料和结果但不知道过程&lt;/p&gt;
&lt;p&gt;下面通过数据流形式做的分析, 下图全流程为核心, 本质上是 &lt;code&gt;两个跨模态融合系统+一个通信系统&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z0AQzP.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight json&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;images&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      &lt;span class=&#34;attr&#34;&gt;&amp;quot;file_name&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;/root/DataSets/DAIR-V2X/cooperative-vehicle-infrastructure//infrastructure-sideimage/000009.jpg&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      &lt;span class=&#34;attr&#34;&gt;&amp;quot;calib&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;attr&#34;&gt;&amp;quot;cam_intrinsic&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;number&#34;&gt;2186.359688&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;968.712906&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;2332.160319&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;542.356703&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.0&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;number&#34;&gt;1.0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;attr&#34;&gt;&amp;quot;Tr_velo_to_cam&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;attr&#34;&gt;&amp;quot;translation&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;-5.779144404715124&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;6.037615758600886&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;1.0636424034755758&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;attr&#34;&gt;&amp;quot;rotation&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;-0.0638033225610772&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.9910914864003576&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.04429948490729328&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;-0.2102873406178483&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.043997692433495696&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.7987692871343754&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;punctuation&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;0.97575114561348&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.06031492538699515&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.17158543199893228&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;          &lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;punctuation&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上面是 annos 内的文件格式, 为图像的内/外参, 下面是分析 (&lt;code&gt;-&amp;gt;&lt;/code&gt;所指向的为&amp;quot;原料&amp;quot;)&lt;/p&gt;
&lt;figure class=&#34;highlight clean&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;# annotations 标注&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;annos&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  # 图片文件&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;string&#34;&gt;&amp;quot;file_name&amp;quot;&lt;/span&gt; -&amp;gt; image&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  # 相机内参&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;string&#34;&gt;&amp;quot;cam_intrinsic&amp;quot;&lt;/span&gt; -&amp;gt; calib/camera_intrinsic.&lt;span class=&#34;string&#34;&gt;&amp;quot;cam_K&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  # LiDAR 到 Camera 的外参矩阵, 反过来就是 Camera 到 LiDAR 的 (相机外参)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;string&#34;&gt;&amp;quot;Tr_velo_to_cam&amp;quot;&lt;/span&gt;-&amp;gt; calib/virtuallidar_to_camera&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;VirtualLiDAR-转换和组成&#34;&gt;VirtualLiDAR-转换和组成&lt;/h4&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z0ADvR.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;image + annos + label/camera =&amp;gt; 图像的 3D 标注&lt;/p&gt;
&lt;p&gt;velodyne(点云 pcd 文件) + label/virtuallidar =&amp;gt; 点云的 3D 标注&lt;/p&gt;
&lt;p&gt;虚拟 LiDAR 坐标系到虚拟世界坐标系的转换就简单了, 只需要通过 &lt;code&gt;calib/virtuallidar_to_world&lt;/code&gt; 就可以&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;时间同步-配准问题&#34;&gt;时间同步-配准问题&lt;/h4&gt;
&lt;p&gt;路端/车端分别有个 GPS 管位置和时间同步, 同一端内 Camera 和 LiDAR 的时间通过 GPS 授时应该是一致的&lt;/p&gt;
&lt;p&gt;所以在硬件不出问题的情况下, 同一端的时间问题可以不用考虑, 可以考虑跨端问题 (但是个人感觉, 在 GPS 授时准确的情况下, 车端与路端通信距离最远也就几十米, 也不用考虑跨端导致的时差问题)&lt;/p&gt;
&lt;p&gt;插一嘴, 感觉文档里所说的 “分别以 Camera 和 LiDAR 时间戳为基准” 有歧义, 他想表达的应该是 “同一时间戳下的 Camera 与 LiDAR 是一对”, 而不是说 Camera 与 LiDAR 各自为政分别计时&lt;/p&gt;
&lt;p&gt;在时间方面, 需要考虑的应该是车-路两端的通信时延, 几十 ms 的短时延是没问题的, 可以视为软实时, 车端的决策可以滞后一些来等待路端的指示&lt;/p&gt;
&lt;p&gt;从经验上来看, 难点应该是如何让车-路两端设备 &lt;code&gt;迅速匹配连接&lt;/code&gt;, 日常用的手机 4G/5G 网正常就是几十 ms 延迟, 但是手机与基站在匹配连接阶段需要耗费好几秒 (不知道在设备选用方面能不能解决这问题)&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;提出问题: 车端接收到路端给的数据, 必然是几十 ms 之前的, 我们可以考虑做这个配准&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;决策滞后, 比如设置阈值 100ms, 如未收到路端返回的数据,就只用车端的进行决策&lt;/li&gt;
&lt;li&gt;让路端进行路线预测, 逼近实时&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;虚拟问题及双端任务流&#34;&gt;虚拟问题及双端任务流&lt;/h4&gt;
&lt;p&gt;GPS 是精准到经纬度位置的, 为了防止路端信息泄露/侵犯隐私权(车端数据自用所以不用转换), 路端设备需要把绝对位置通过 GPS 转为相对位置 (也就是虚拟化)&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z0ANiM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;车端做的是:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;探测到前方 xx 米处有辆车, 记下来路况&lt;/li&gt;
&lt;li&gt;连接路端告诉路端本车 GPS, 等待并接收路端传回的虚拟世界坐标系, 对路况查漏补缺&lt;/li&gt;
&lt;li&gt;根据记下的路况规划行驶&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;路端做的是:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;探测到周围有车 A 和 B, 以路端设备 GPS 位置为中心构建虚拟世界坐标系&lt;/li&gt;
&lt;li&gt;收到某车 GPS 实时定位/relative pose (比如 A 车的), 把虚拟世界坐标系中心转为 A 车的 GPS, 并传给 A&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;标注问题&#34;&gt;标注问题&lt;/h4&gt;
&lt;p&gt;下面分别为图像与 LiDAR 的标注文件, 我原以为的精度问题以及数据转换是误解, 实际上是两模态都做了标注&lt;/p&gt;
&lt;figure class=&#34;highlight json&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;Car&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;truncated_state&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;occluded_state&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;alpha&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;2d_box&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;xmin&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;768.12085&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;ymin&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;747.97583&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;xmax&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1002.4884040000001&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;ymax&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1021.312134&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;3d_dimensions&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;h&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.955531&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;2.036715&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;l&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4.234148&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;3d_location&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;x&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;20.233591&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;-6.118915&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;z&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;-1.906110&amp;quot;&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;rotation&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.02090169484402715&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight json&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;type&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;Car&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;truncated_state&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;occluded_state&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;alpha&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;string&#34;&gt;&amp;quot;0&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;2d_box&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;xmin&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;768.12085&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;ymin&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;747.97583&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;xmax&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1002.4884040000001&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;ymax&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1021.312134&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;3d_dimensions&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;h&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1.688849&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1.804866&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;attr&#34;&gt;&amp;quot;l&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;4.234148&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;3d_location&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;punctuation&#34;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;x&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;20.22032661649286&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-6.165649086415965&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;attr&#34;&gt;&amp;quot;z&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;-0.8846375190174429&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;attr&#34;&gt;&amp;quot;rotation&amp;quot;&lt;/span&gt;&lt;span class=&#34;punctuation&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0.02090180743721963&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;punctuation&#34;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;图像做的是 2D+3D, 点云只做了 3D 标注, 2D 标注一模一样所以不用分析&lt;/p&gt;
&lt;p&gt;关于两模态的 3D 标注框重合度问题, 暂且认为是点云标注质量不好 (点云下车辆形状大小需要人为估量)&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;其它问题&#34;&gt;其它问题&lt;/h4&gt;
&lt;p&gt;annos.images.file_name 存在格式问题&lt;/p&gt;
&lt;p&gt;“/root/DataSets/DAIR-V2X/cooperative-vehicle-infrastructure//infrastructure-sideimage/000028.jpg”&lt;/p&gt;
&lt;!-- TODO --&gt;
&lt;p&gt;fix_require&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;欧阳老师给的提议&#34;&gt;欧阳老师给的提议&lt;/h4&gt;
&lt;p&gt;(有待商榷)&lt;/p&gt;
&lt;p&gt;清标签/找一个工具改一下&lt;/p&gt;
&lt;p&gt;图像到点云不准, 过滤地面可以降低标注难度&lt;br&gt;
有可能外参有问题&lt;/p&gt;
&lt;p&gt;一波人做数据清洗/标注修正&lt;br&gt;
另一拨人, 做一下 IoU 统计, 融合分析&lt;/p&gt;
&lt;p&gt;寻找问题所在: 什么噪声导致 3D 框重合度有问题&lt;/p&gt;
&lt;p&gt;欧阳老师提到的 &lt;code&gt;Cloud Compare&lt;/code&gt; 可以对比两点云之间的差别&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;auto-mos&#34;&gt;auto-mos&lt;/h3&gt;
&lt;p&gt;是这个 paper 的流程总结 &lt;sup id=&#39;cite_ref-3&#39;&gt;&lt;a href=&#34;#cite_note-3&#34;&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z6OgZ9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;主要需要的数据是连续帧雷达点云数据, 论文所提出的 pipeline 是一套 offline 模块:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;输入进 SLAM/测距, 首先估计位姿信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;应用 ERASOR 地图清理方法 (dynamic removal) 检测出 moving object&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;利用基于密度的聚类方法 HDBSCAN 对其进行实例分割&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过卡尔曼滤波进行多目标跟踪检测, 并通过跟踪结果判断是否为动态物体并确定其标签&lt;/p&gt;
&lt;p&gt;中心距离, 重叠的边界框量以及基于其边界框之间的每对实例之间的 volume 更改&lt;/p&gt;
&lt;p&gt;根据运动确定其标签&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;连续帧雷达点云数据 -&amp;gt; 自动检测移动物体并生成标签&lt;/p&gt;
&lt;p&gt;之后使用生成的 label 作为监督数据训练 online 模型, 测试多个方法以及多组不同场景的雷达数据, 结果显示生成结果与人为标注结果差距小&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z6cOvP.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;线性插值生成的汽车的轨迹显示灰色, 插值还考虑了旋转和缩放。&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z67vqX.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;借物表&#34;&gt;借物表&lt;/h2&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-1&#39; href=&#39;#cite_ref-1&#39;&gt;[1]&lt;/a&gt;: &lt;a href=&#34;http://www.ruanyifeng.com/blog/2007/03/metadata.html&#34;&gt;元数据（MetaData）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-2&#39; href=&#39;#cite_ref-2&#39;&gt;[2]&lt;/a&gt;: &lt;a href=&#34;https://www.bilibili.com/video/BV1XU4y1X7b5/&#34;&gt;【论文必读 ResNet】residual 如此多娇，引无数英雄竞折腰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-3&#39; href=&#39;#cite_ref-3&#39;&gt;[3]&lt;/a&gt;: &lt;a href=&#34;https://github.com/PRBonn/auto-mos&#34;&gt;GitHub - PRBonn/auto-mos: Automatic Labeling to Generate Training Data for Online LiDAR-based Moving Object Segmentation&lt;/a&gt;&lt;/p&gt;
&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kity@2.0.4/dist/kity.min.js&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js&#34;&gt;&lt;/script&gt;&lt;script defer=&#34;true&#34; type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js&#34;&gt;&lt;/script&gt;&lt;link rel=&#34;stylesheet&#34; type=&#34;text&amp;#x2F;css&#34; href=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css&#34;&gt;</content>
        <category term="人工智能" />
        <category term="research" />
        <category term="math" />
        <category term="dataset" />
        <category term="深度学习" />
        <category term="点云" />
        <category term="自动驾驶" />
        <updated>2022-07-10T13:21:09.000Z</updated>
    </entry>
    <entry>
        <id>https://weidows.github.io/post/lang/python/code/MM-Detection/</id>
        <title>🐳MM-Detection-Colab</title>
        <link rel="alternate" href="https://weidows.github.io/post/lang/python/code/MM-Detection/"/>
        <content type="html">&lt;!--
 * @?: *********************************************************************
 * @Author: Weidows
 * @LastEditors: Weidows
 * @LastEditTime: 2023-04-20 18:34:42
 * @FilePath: \Blog-private\source\_posts\python\code\MM-Detection.md
 * @Description:
 * @!: *********************************************************************
--&gt;
&lt;h2 id=&#34;序&#34;&gt;序&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Colab 平台对于 &lt;code&gt;轻量级/边缘计算&lt;/code&gt; 比较方便, 尤其是对这种教程性质的 notebook, 分享和运行都开箱即用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但另一方面:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;因&lt;/code&gt;: 免费版的 Colab 所给的硬件资源不是很稳定, 用太久的话会分不到 GPU, 虽然给的 GPU 肯定是比自己的开发机强很多, 但是跑大型项目肯定带不动 (而且 Colab 单次运行最多持续 6h, 一段时间没动作的话会断连, 断开后再过一阵 runtime 会被重置)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;果&lt;/code&gt;: 可以用它来学习下怎么搭环境以及一些小测试&lt;/p&gt;
&lt;p&gt;毕竟生产服务器申请不易 / 环境也不能乱动&lt;/p&gt;
&lt;p&gt;受系统和网络限制, 在开发机搭环境并不理想&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;装环境&#34;&gt;装环境&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;从安装到放弃到爬出坑 :( &lt;br&gt;
跟着这几篇装的环境:&lt;sup id=&#39;cite_ref-2&#39;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#39;cite_ref-3&#39;&gt;&lt;a href=&#34;#cite_note-3&#34;&gt;[3]&lt;/a&gt;&lt;/sup&gt;, 有借鉴意义但是指导不明确 &lt;br&gt;
个人先跟着官方出的视频教程和 openbayes 上的 notebook 试了试水, 很深 &lt;sup id=&#39;cite_ref-1&#39;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[1]&lt;/a&gt;&lt;/sup&gt;; 最后找到一个源库 tutorial-fork 的 colab-notebook &lt;sup id=&#39;cite_ref-4&#39;&gt;&lt;a href=&#34;#cite_note-4&#34;&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;预先装上 cuda, cudnn (colab自带)&lt;/p&gt;
&lt;p&gt;依赖链: &lt;code&gt;cuda &amp;lt;- pytorch &amp;lt;- mmcv-full &amp;lt;- mmdet&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;每一步依赖前面环境的版本, 即使后面能装上也可能不适配, 任何一步有问题都 &lt;code&gt;can&#39;t run&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZtZpOm.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ====================可选, colab并不自带conda=====================&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!conda create -n openmmlab -y&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!conda activate openmmlab&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!conda init&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/bin/bash: conda: command not found
/bin/bash: conda: command not found
/bin/bash: conda: command not found
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# ================== 一键装好环境 =======================&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 如果这里有问题可以重启一下内核: 代码执行程序 -&amp;gt; 重新启动代码执行程序&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python -m pip install --upgrade pip&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 注意对应机子配置: https://pytorch.org/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# install dependencies: (use cu111 because colab has CUDA 11.1)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%pip install torch==&lt;span class=&#34;number&#34;&gt;1.9&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;+cu111 torchvision==&lt;span class=&#34;number&#34;&gt;0.10&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;+cu111 -f https://download.pytorch.org/whl/torch_stable.html&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# windows 平台不用装了, 一定会卡在这&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# https://github.com/open-mmlab/mmcv/blob/master/README_zh-CN.md&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1&lt;span class=&#34;number&#34;&gt;.9&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;/index.html&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 与pip/conda同级的专门给mm-lab用的包管理器, 报错率很高&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%pip install openmim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 依赖 mmcv, 如果用mim装的话大概率有问题&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 后面要用到源码库的 config, 可选用源库安装&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%pip install mmdet mmsegmentation&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)
Collecting pip
  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)
[K     |████████████████████████████████| 2.1 MB 37.1 MB/s
[?25hInstalling collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 21.1.3
    Uninstalling pip-21.1.3:
      Successfully uninstalled pip-21.1.3
Successfully installed pip-22.1.2
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Looking in links: https://download.pytorch.org/whl/torch_stable.html
Collecting torch==1.9.0+cu111
  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)
[2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m2.0/2.0 GB[0m [31m83.9 MB/s[0m eta [36m0:00:01[0mtcmalloc: large alloc 2041348096 bytes == 0x25c6000 @  0x7fb296fd21e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c
[2K     [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m2.0/2.0 GB[0m [31m82.2 MB/s[0m eta [36m0:00:01[0mtcmalloc: large alloc 2551685120 bytes == 0x7c08e000 @  0x7fb296fd3615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549576 0x593fce
tcmalloc: large alloc 2041348096 bytes == 0x25c6000 @  0x7fb296fd21e7 0x4a3940 0x5b438c 0x5b46f7 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5fbece 0x594b72 0x548cc1 0x51566f 0x593dd7 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.0/2.0 GB[0m [31m836.7 kB/s[0m eta [36m0:00:00[0m
[?25hCollecting torchvision==0.10.0+cu111
  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.2/23.2 MB[0m [31m19.8 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)
Requirement already satisfied: pillow&amp;gt;=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.21.6)
Installing collected packages: torch, torchvision
  Attempting uninstall: torch
    Found existing installation: torch 1.11.0+cu113
    Uninstalling torch-1.11.0+cu113:
      Successfully uninstalled torch-1.11.0+cu113
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.12.0+cu113
    Uninstalling torchvision-0.12.0+cu113:
      Successfully uninstalled torchvision-0.12.0+cu113
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.
torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0+cu111 which is incompatible.[0m[31m
[0mSuccessfully installed torch-1.9.0+cu111 torchvision-0.10.0+cu111
[33mWARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html
Collecting mmcv-full
  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (46.3 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m46.3/46.3 MB[0m [31m8.1 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting addict
  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)
Requirement already satisfied: opencv-python&amp;gt;=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)
Collecting yapf
  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m190.2/190.2 kB[0m [31m20.0 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)
Requirement already satisfied: pyparsing!=3.0.5,&amp;gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&amp;gt;mmcv-full) (3.0.9)
Installing collected packages: yapf, addict, mmcv-full
Successfully installed addict-2.4.0 mmcv-full-1.5.3 yapf-0.32.0
[33mWARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting openmim
  Downloading openmim-0.1.6.tar.gz (37 kB)
  Preparing metadata (setup.py) ... [?25l[?25hdone
Requirement already satisfied: Click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)
Collecting colorama
  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)
Collecting model-index
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)
Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.9)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index-&amp;gt;openmim) (3.13)
Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index-&amp;gt;openmim) (3.3.7)
Collecting ordered-set
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: numpy&amp;gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&amp;gt;openmim) (1.21.6)
Requirement already satisfied: python-dateutil&amp;gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&amp;gt;openmim) (2.8.2)
Requirement already satisfied: pytz&amp;gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&amp;gt;openmim) (2022.1)
Requirement already satisfied: certifi&amp;gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&amp;gt;openmim) (2022.6.15)
Requirement already satisfied: chardet&amp;lt;4,&amp;gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&amp;gt;openmim) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&amp;lt;1.26,&amp;gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&amp;gt;openmim) (1.24.3)
Requirement already satisfied: idna&amp;lt;3,&amp;gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&amp;gt;openmim) (2.10)
Requirement already satisfied: six&amp;gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&amp;gt;=2.7.3-&amp;gt;pandas-&amp;gt;openmim) (1.15.0)
Requirement already satisfied: importlib-metadata&amp;gt;=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown-&amp;gt;model-index-&amp;gt;openmim) (4.11.4)
Requirement already satisfied: typing-extensions&amp;gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&amp;gt;=4.4-&amp;gt;markdown-&amp;gt;model-index-&amp;gt;openmim) (4.1.1)
Requirement already satisfied: zipp&amp;gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&amp;gt;=4.4-&amp;gt;markdown-&amp;gt;model-index-&amp;gt;openmim) (3.8.0)
Building wheels for collected packages: openmim
  Building wheel for openmim (setup.py) ... [?25l[?25hdone
  Created wheel for openmim: filename=openmim-0.1.6-py2.py3-none-any.whl size=43919 sha256=4da5d601b4527ed104f9f6821d3c8d898197648313abcbb891328d3a1a7d1baf
  Stored in directory: /root/.cache/pip/wheels/a8/33/de/415150be8f048d1bcfd72c6a452978e71e229ee0769f1752f8
Successfully built openmim
Installing collected packages: ordered-set, colorama, model-index, openmim
Successfully installed colorama-0.4.5 model-index-0.1.11 openmim-0.1.6 ordered-set-4.1.0
[33mWARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting mmdet
  Downloading mmdet-2.25.0-py3-none-any.whl (1.4 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m60.2 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting mmsegmentation
  Downloading mmsegmentation-0.25.0-py3-none-any.whl (804 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m805.0/805.0 kB[0m [31m62.9 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet) (2.0.4)
Collecting terminaltables
  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet) (3.2.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.21.6)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.15.0)
Collecting mmcls&amp;gt;=0.20.1
  Downloading mmcls-0.23.1-py2.py3-none-any.whl (577 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m577.3/577.3 kB[0m [31m54.3 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (3.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation) (21.3)
Requirement already satisfied: cycler&amp;gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;mmdet) (0.11.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;mmdet) (3.0.9)
Requirement already satisfied: python-dateutil&amp;gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;mmdet) (2.8.2)
Requirement already satisfied: kiwisolver&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;mmdet) (1.4.3)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable-&amp;gt;mmsegmentation) (4.11.4)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable-&amp;gt;mmsegmentation) (0.2.5)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&amp;gt;=1.0.1-&amp;gt;matplotlib-&amp;gt;mmdet) (4.1.1)
Requirement already satisfied: zipp&amp;gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&amp;gt;prettytable-&amp;gt;mmsegmentation) (3.8.0)
Installing collected packages: terminaltables, mmcls, mmsegmentation, mmdet
Successfully installed mmcls-0.23.1 mmdet-2.25.0 mmsegmentation-0.25.0 terminaltables-3.1.10
[33mWARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 验证安装&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!nvcc -V&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!pip &lt;span class=&#34;built_in&#34;&gt;list&lt;/span&gt; | grep mm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmcv &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; collect_env&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;collect_env()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Oct_12_20:09:46_PDT_2020
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0
community                     1.0.0b1
googleapis-common-protos      1.56.2
mmcls                         0.23.1
mmcv-full                     1.5.2
mmdet                         2.25.0
mmsegmentation                0.25.0
pyviz-comms                   2.2.0
snowballstemmer               2.2.0
torchsummary                  1.5.1





&amp;#123;&#39;CUDA available&#39;: True,
 &#39;CUDA_HOME&#39;: &#39;/usr/local/cuda&#39;,
 &#39;GCC&#39;: &#39;x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0&#39;,
 &#39;GPU 0&#39;: &#39;Tesla T4&#39;,
 &#39;MMCV&#39;: &#39;1.5.2&#39;,
 &#39;MMCV CUDA Compiler&#39;: &#39;11.1&#39;,
 &#39;MMCV Compiler&#39;: &#39;GCC 7.3&#39;,
 &#39;NVCC&#39;: &#39;Cuda compilation tools, release 11.1, V11.1.105&#39;,
 &#39;OpenCV&#39;: &#39;4.1.2&#39;,
 &#39;PyTorch&#39;: &#39;1.9.0+cu111&#39;,
 &#39;PyTorch compiling details&#39;: &#39;PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n&#39;,
 &#39;Python&#39;: &#39;3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]&#39;,
 &#39;TorchVision&#39;: &#39;0.10.0+cu111&#39;,
 &#39;sys.platform&#39;: &#39;linux&#39;&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;Clone-repo&#34;&gt;Clone-repo&lt;/h3&gt;
&lt;p&gt;clone 项目源码库下来, 后面的 &lt;code&gt;验证/训练&lt;/code&gt; 要用到源码库的配置和工具等 (用到哪个库 Clone 哪个就行, 当然全 clone 也没问题)&lt;/p&gt;
&lt;p&gt;注意后面运行前切一下路径&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# !rm -rf /content/mmdetection&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%cd /content&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!git clone https://github.com/&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;-mmlab/mmdetection.git&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%cd mmdetection&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# %pip install -e .&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 后续 pwd = /content/mmdetection&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/content
Cloning into &#39;mmdetection&#39;...
remote: Enumerating objects: 24969, done.[K
remote: Counting objects: 100% (10/10), done.[K
remote: Compressing objects: 100% (9/9), done.[K
remote: Total 24969 (delta 3), reused 6 (delta 1), pack-reused 24959[K
Receiving objects: 100% (24969/24969), 37.76 MiB | 11.27 MiB/s, done.
Resolving deltas: 100% (17495/17495), done.
/content/mmdetection
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# !rm -rf /content/mmdetection3d&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%cd /content&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!git clone https://github.com/&lt;span class=&#34;built_in&#34;&gt;open&lt;/span&gt;-mmlab/mmdetection3d.git&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%cd mmdetection3d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mmdetection3d 有一些额外的依赖需要安装&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%pip install -e .&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# --show 用到open3D来展示, 但只能在本机create窗口, colab 上会报错&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# %pip install open3d&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 后续 pwd = /content/mmdetection3d&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/content
Cloning into &#39;mmdetection3d&#39;...
remote: Enumerating objects: 13252, done.[K
remote: Counting objects: 100% (148/148), done.[K
remote: Compressing objects: 100% (116/116), done.[K
remote: Total 13252 (delta 44), reused 102 (delta 32), pack-reused 13104[K
Receiving objects: 100% (13252/13252), 15.96 MiB | 14.34 MiB/s, done.
Resolving deltas: 100% (9134/9134), done.
/content/mmdetection3d
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Obtaining file:///content/mmdetection3d
  Preparing metadata (setup.py) ... [?25l[?25hdone
Collecting lyft_dataset_sdk
  Downloading lyft_dataset_sdk-0.0.8-py2.py3-none-any.whl (32 kB)
Collecting networkx&amp;lt;2.3,&amp;gt;=2.2
  Downloading networkx-2.2.zip (1.7 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m68.0 MB/s[0m eta [36m0:00:00[0m
[?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
Collecting numba==0.53.0
  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.4/3.4 MB[0m [31m83.6 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet3d==1.0.0rc3) (1.21.6)
Collecting nuscenes-devkit
  Downloading nuscenes_devkit-1.1.9-py3-none-any.whl (312 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m312.6/312.6 kB[0m [31m35.9 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting plyfile
  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)
Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from mmdet3d==1.0.0rc3) (0.18.3)
Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from mmdet3d==1.0.0rc3) (2.8.0)
Collecting trimesh&amp;lt;2.35.40,&amp;gt;=2.35.39
  Downloading trimesh-2.35.39.tar.gz (281 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m282.0/282.0 kB[0m [31m35.0 MB/s[0m eta [36m0:00:00[0m
[?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
Collecting llvmlite&amp;lt;0.37,&amp;gt;=0.36.0rc1
  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m25.3/25.3 MB[0m [31m60.6 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53.0-&amp;gt;mmdet3d==1.0.0rc3) (57.4.0)
Requirement already satisfied: decorator&amp;gt;=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx&amp;lt;2.3,&amp;gt;=2.2-&amp;gt;mmdet3d==1.0.0rc3) (4.4.2)
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trimesh&amp;lt;2.35.40,&amp;gt;=2.35.39-&amp;gt;mmdet3d==1.0.0rc3) (1.4.1)
Requirement already satisfied: scikit-learn&amp;gt;=0.19.2 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.0.2)
Collecting pyquaternion&amp;gt;=0.9.5
  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)
Requirement already satisfied: opencv-python&amp;gt;=3.4.2.17 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (4.1.2.30)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.3.5)
Collecting flake8
  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m64.1/64.1 kB[0m [31m9.5 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: tqdm&amp;gt;=4.25.0 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (4.64.0)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (3.2.2)
Requirement already satisfied: Pillow&amp;gt;=5.2.0 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (7.1.2)
Collecting black
  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m71.8 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting fire
  Downloading fire-0.4.0.tar.gz (87 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m87.7/87.7 kB[0m [31m10.6 MB/s[0m eta [36m0:00:00[0m
[?25h  Preparing metadata (setup.py) ... [?25l[?25hdone
Requirement already satisfied: Shapely&amp;gt;=1.6.4.post2 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.8.2)
Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (5.5.0)
Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (3.6.4)
Requirement already satisfied: cachetools&amp;gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (4.2.4)
Requirement already satisfied: pycocotools&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.0.4)
Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.0.0)
Requirement already satisfied: descartes in /usr/local/lib/python3.7/dist-packages (from nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.1.0)
Requirement already satisfied: imageio&amp;gt;=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image-&amp;gt;mmdet3d==1.0.0rc3) (2.4.1)
Requirement already satisfied: tifffile&amp;gt;=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image-&amp;gt;mmdet3d==1.0.0rc3) (2021.11.2)
Requirement already satisfied: PyWavelets&amp;gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image-&amp;gt;mmdet3d==1.0.0rc3) (1.3.0)
Requirement already satisfied: google-auth-oauthlib&amp;lt;0.5,&amp;gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (0.4.6)
Requirement already satisfied: grpcio&amp;gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.46.3)
Requirement already satisfied: wheel&amp;gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (0.37.1)
Requirement already satisfied: tensorboard-data-server&amp;lt;0.7.0,&amp;gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (0.6.1)
Requirement already satisfied: absl-py&amp;gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.1.0)
Requirement already satisfied: markdown&amp;gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (3.3.7)
Requirement already satisfied: protobuf&amp;gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (3.17.3)
Requirement already satisfied: tensorboard-plugin-wit&amp;gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.8.1)
Requirement already satisfied: werkzeug&amp;gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.0.1)
Requirement already satisfied: requests&amp;lt;3,&amp;gt;=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (2.23.0)
Requirement already satisfied: google-auth&amp;lt;3,&amp;gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.35.0)
Requirement already satisfied: six&amp;gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&amp;lt;3,&amp;gt;=1.6.3-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.15.0)
Requirement already satisfied: pyasn1-modules&amp;gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&amp;lt;3,&amp;gt;=1.6.3-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (0.2.8)
Requirement already satisfied: rsa&amp;lt;5,&amp;gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&amp;lt;3,&amp;gt;=1.6.3-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (4.8)
Requirement already satisfied: requests-oauthlib&amp;gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&amp;lt;0.5,&amp;gt;=0.4.1-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.3.1)
Requirement already satisfied: importlib-metadata&amp;gt;=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown&amp;gt;=2.6.8-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (4.11.4)
Requirement already satisfied: python-dateutil&amp;gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (2.8.2)
Requirement already satisfied: kiwisolver&amp;gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.4.3)
Requirement already satisfied: cycler&amp;gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (0.11.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (3.0.9)
Requirement already satisfied: certifi&amp;gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&amp;lt;3,&amp;gt;=2.21.0-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (2022.6.15)
Requirement already satisfied: idna&amp;lt;3,&amp;gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&amp;lt;3,&amp;gt;=2.21.0-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&amp;lt;1.26,&amp;gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&amp;lt;3,&amp;gt;=2.21.0-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (1.24.3)
Requirement already satisfied: chardet&amp;lt;4,&amp;gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&amp;lt;3,&amp;gt;=2.21.0-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (3.0.4)
Requirement already satisfied: threadpoolctl&amp;gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&amp;gt;=0.19.2-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (3.1.0)
Requirement already satisfied: joblib&amp;gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&amp;gt;=0.19.2-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.1.0)
Collecting click&amp;gt;=8.0.0
  Downloading click-8.1.3-py3-none-any.whl (96 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m96.6/96.6 kB[0m [31m14.1 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting mypy-extensions&amp;gt;=0.4.3
  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)
Requirement already satisfied: typing-extensions&amp;gt;=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (4.1.1)
Collecting pathspec&amp;gt;=0.9.0
  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)
Collecting platformdirs&amp;gt;=2
  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)
Collecting typed-ast&amp;gt;=1.4.2
  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m843.7/843.7 kB[0m [31m59.7 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: tomli&amp;gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (2.0.1)
Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.1.0)
Collecting pyflakes&amp;lt;2.5.0,&amp;gt;=2.4.0
  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m69.7/69.7 kB[0m [31m10.2 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting pycodestyle&amp;lt;2.9.0,&amp;gt;=2.8.0
  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42.1/42.1 kB[0m [31m5.2 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting flake8
  Downloading flake8-4.0.0-py2.py3-none-any.whl (64 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m64.1/64.1 kB[0m [31m8.3 MB/s[0m eta [36m0:00:00[0m
[?25h  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m73.1/73.1 kB[0m [31m10.1 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting pyflakes&amp;lt;2.4.0,&amp;gt;=2.3.0
  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m68.8/68.8 kB[0m [31m10.1 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting pycodestyle&amp;lt;2.8.0,&amp;gt;=2.7.0
  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m41.7/41.7 kB[0m [31m5.9 MB/s[0m eta [36m0:00:00[0m
[?25hCollecting mccabe&amp;lt;0.7.0,&amp;gt;=0.6.0
  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)
Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.6.1)
Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.3.1)
Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.2.0)
Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (7.7.0)
Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (4.10.1)
Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.3.1)
Requirement already satisfied: pytz&amp;gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (2022.1)
Requirement already satisfied: tenacity&amp;gt;=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (8.0.1)
Requirement already satisfied: attrs&amp;gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (21.4.0)
Requirement already satisfied: more-itertools&amp;gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (8.13.0)
Requirement already satisfied: py&amp;gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.11.0)
Requirement already satisfied: atomicwrites&amp;gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (1.4.0)
Requirement already satisfied: pluggy&amp;lt;0.8,&amp;gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest-&amp;gt;lyft_dataset_sdk-&amp;gt;mmdet3d==1.0.0rc3) (0.7.1)
Requirement already satisfied: zipp&amp;gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&amp;gt;=4.4-&amp;gt;markdown&amp;gt;=2.6.8-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (3.8.0)
Requirement already satisfied: pyasn1&amp;lt;0.5.0,&amp;gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&amp;gt;=0.2.1-&amp;gt;google-auth&amp;lt;3,&amp;gt;=1.6.3-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (0.4.8)
Requirement already satisfied: oauthlib&amp;gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&amp;gt;=0.7.0-&amp;gt;google-auth-oauthlib&amp;lt;0.5,&amp;gt;=0.4.1-&amp;gt;tensorboard-&amp;gt;mmdet3d==1.0.0rc3) (3.2.0)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.3.5)
Requirement already satisfied: traitlets&amp;gt;=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.1.1)
Requirement already satisfied: tornado&amp;gt;=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.1.1)
Requirement already satisfied: ipython&amp;gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.5.0)
Requirement already satisfied: jupyterlab-widgets&amp;gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.1.0)
Requirement already satisfied: nbformat&amp;gt;=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.4.0)
Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.2.0)
Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (3.6.0)
Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.6.1)
Requirement already satisfied: prompt-toolkit&amp;lt;2.0.0,&amp;gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.0.18)
Requirement already satisfied: pandocfilters&amp;gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.5.0)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (4.10.0)
Requirement already satisfied: mistune&amp;lt;2,&amp;gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.8.4)
Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.6.0)
Requirement already satisfied: entrypoints&amp;gt;=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.4)
Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.0.0)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.7.1)
Requirement already satisfied: jinja2&amp;gt;=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.11.3)
Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (1.8.0)
Requirement already satisfied: terminado&amp;gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.13.3)
Requirement already satisfied: qtpy&amp;gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.1.0)
Requirement already satisfied: pyzmq&amp;gt;=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (23.1.0)
Requirement already satisfied: simplegeneric&amp;gt;0.8 in /usr/local/lib/python3.7/dist-packages (from ipython&amp;gt;=4.0.0-&amp;gt;ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.8.1)
Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython&amp;gt;=4.0.0-&amp;gt;ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (4.8.0)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython&amp;gt;=4.0.0-&amp;gt;ipykernel-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.7.5)
Requirement already satisfied: MarkupSafe&amp;gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2&amp;gt;=2.4-&amp;gt;nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.0.1)
Requirement already satisfied: jsonschema&amp;gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat&amp;gt;=4.2.0-&amp;gt;ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat&amp;gt;=4.2.0-&amp;gt;ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (2.15.3)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit&amp;lt;2.0.0,&amp;gt;=1.0.0-&amp;gt;jupyter-console-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.2.5)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy&amp;gt;=2.0.1-&amp;gt;qtconsole-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (21.3)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado&amp;gt;=0.8.1-&amp;gt;notebook-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.7.0)
Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach-&amp;gt;nbconvert-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.5.1)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&amp;gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&amp;gt;=2.6-&amp;gt;nbformat&amp;gt;=4.2.0-&amp;gt;ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (0.18.1)
Requirement already satisfied: importlib-resources&amp;gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&amp;gt;=2.6-&amp;gt;nbformat&amp;gt;=4.2.0-&amp;gt;ipywidgets-&amp;gt;jupyter-&amp;gt;nuscenes-devkit-&amp;gt;mmdet3d==1.0.0rc3) (5.7.1)
Building wheels for collected packages: networkx, trimesh, fire
  Building wheel for networkx (setup.py) ... [?25l[?25hdone
  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1526923 sha256=78db1be6fc20922f3580e77e808eafa1d3e65a486412acdb9563916946595371
  Stored in directory: /root/.cache/pip/wheels/49/fb/7f/02c31ca537b34e1073844b733832e4c3a94071d8edda2c0faa
  Building wheel for trimesh (setup.py) ... [?25l[?25hdone
  Created wheel for trimesh: filename=trimesh-2.35.39-py3-none-any.whl size=324073 sha256=29142163d4899e9eba3c700ea4c47bbdd7b954992e87d68c3003f8a352422bd8
  Stored in directory: /root/.cache/pip/wheels/cb/8d/ba/483fb1c41aa97d67177547c5b380232851007c950f615b1277
  Building wheel for fire (setup.py) ... [?25l[?25hdone
  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=bf7fdd9c4beb982c2668c3bb8cbcba7f9b8df5fbccc067e369e5553869e63b5b
  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226
Successfully built networkx trimesh fire
Installing collected packages: mypy-extensions, mccabe, typed-ast, pyquaternion, pyflakes, pycodestyle, plyfile, platformdirs, pathspec, networkx, llvmlite, fire, trimesh, numba, flake8, click, black, lyft_dataset_sdk, nuscenes-devkit, mmdet3d
  Attempting uninstall: networkx
    Found existing installation: networkx 2.6.3
    Uninstalling networkx-2.6.3:
      Successfully uninstalled networkx-2.6.3
  Attempting uninstall: llvmlite
    Found existing installation: llvmlite 0.34.0
    Uninstalling llvmlite-0.34.0:
      Successfully uninstalled llvmlite-0.34.0
  Attempting uninstall: numba
    Found existing installation: numba 0.51.2
    Uninstalling numba-0.51.2:
      Successfully uninstalled numba-0.51.2
  Attempting uninstall: click
    Found existing installation: click 7.1.2
    Uninstalling click-7.1.2:
      Successfully uninstalled click-7.1.2
  Running setup.py develop for mmdet3d
[31mERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
openmim 0.1.6 requires Click==7.1.2, but you have click 8.1.3 which is incompatible.
flask 1.1.4 requires click&amp;lt;8.0,&amp;gt;=5.1, but you have click 8.1.3 which is incompatible.
albumentations 0.1.12 requires imgaug&amp;lt;0.2.7,&amp;gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible.[0m[31m
[0mSuccessfully installed black-22.3.0 click-8.1.3 fire-0.4.0 flake8-3.9.2 llvmlite-0.36.0 lyft_dataset_sdk-0.0.8 mccabe-0.6.1 mmdet3d-1.0.0rc3 mypy-extensions-0.4.3 networkx-2.2 numba-0.53.0 nuscenes-devkit-1.1.9 pathspec-0.9.0 platformdirs-2.5.2 plyfile-0.7.4 pycodestyle-2.7.0 pyflakes-2.3.1 pyquaternion-0.9.9 trimesh-2.35.39 typed-ast-1.5.4
[33mWARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;验证&#34;&gt;验证&lt;/h2&gt;
&lt;h3 id=&#34;Detection&#34;&gt;Detection&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mim 也可以用来search/download,不过 doc 在捉迷藏..不知道怎么用&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# https://github.com/open-mmlab/mmdetection/tree/master/configs/mask_rcnn&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 跟教程一样的命令...失效了?&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# !mim search mmdet --model &amp;#x27;mask r-cnn&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# !mim download mmdet --config mask_rcnn_r50_fpn_2x_coco --dest ./_model&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%cd /content/mmdetection&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 下载并分别测试下面两个 pre-trained model-checkpoints&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!mkdir checkpoints&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection/v2&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;/mask_rcnn/mask_rcnn_r50_fpn_2x_coco/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-&lt;span class=&#34;number&#34;&gt;0.392&lt;/span&gt;__segm_mAP-&lt;span class=&#34;number&#34;&gt;0.354_20200505_003907&lt;/span&gt;-3e542a40.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-&lt;span class=&#34;number&#34;&gt;0.392&lt;/span&gt;__segm_mAP-&lt;span class=&#34;number&#34;&gt;0.354_20200505_003907&lt;/span&gt;-3e542a40.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection/v2&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;--2022-06-10 12:13:06--  https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_2x_coco/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.74.197.77
Connecting to download.openmmlab.com (download.openmmlab.com)|47.74.197.77|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 177866862 (170M) [application/octet-stream]
Saving to: ‘checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth’

checkpoints/mask_rc 100%[===================&amp;gt;] 169.63M  9.84MB/s    in 18s

2022-06-10 12:13:25 (9.20 MB/s) - ‘checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth’ saved [177866862/177866862]

--2022-06-10 12:13:25--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.74.197.77
Connecting to download.openmmlab.com (download.openmmlab.com)|47.74.197.77|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 167291982 (160M) [application/octet-stream]
Saving to: ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’

checkpoints/faster_ 100%[===================&amp;gt;] 159.54M  10.9MB/s    in 14s

2022-06-10 12:13:39 (11.5 MB/s) - ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’ saved [167291982/167291982]
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.apis &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; init_detector, inference_detector, show_result_pyplot&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;config = &lt;span class=&#34;string&#34;&gt;&amp;#x27;configs/mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;checkpoint = &lt;span class=&#34;string&#34;&gt;&amp;#x27;checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在 CPU 上需要设置 device=&amp;#x27;cpu&amp;#x27; ; GPU 上设置 device=&amp;#x27;cuda:0&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 使用 mmdetection 源库自带的 demo/demo.jpg&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = init_detector(config, checkpoint, device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda:0&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = inference_detector(model, &lt;span class=&#34;string&#34;&gt;&amp;#x27;demo/demo.jpg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_result_pyplot(model, &lt;span class=&#34;string&#34;&gt;&amp;#x27;demo/demo.jpg&amp;#x27;&lt;/span&gt;, result)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;load checkpoint from local path: checkpoints/mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth


/content/mmdetection/mmdet/datasets/utils.py:70: UserWarning: &amp;quot;ImageToTensor&amp;quot; pipeline is replaced by &amp;quot;DefaultFormatBundle&amp;quot; for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.
  &#39;data pipeline in your config file.&#39;, UserWarning)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_11_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; mmcv&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmcv.runner &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; load_checkpoint&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.apis &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; inference_detector, show_result_pyplot&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; build_detector&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Choose to use a config and initialize the detector&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;config = &lt;span class=&#34;string&#34;&gt;&amp;#x27;configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Setup a checkpoint file to load&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;checkpoint = &lt;span class=&#34;string&#34;&gt;&amp;#x27;checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Set the device to be used for evaluation&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda:0&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Load the config&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;config = mmcv.Config.fromfile(config)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Set pretrained to be None since we do not need pretrained model here&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;config.model.pretrained = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Initialize the detector&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = build_detector(config.model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Load checkpoint&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;checkpoint = load_checkpoint(model, checkpoint, map_location=device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Set the classes of models for inference&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.CLASSES = checkpoint[&lt;span class=&#34;string&#34;&gt;&amp;#x27;meta&amp;#x27;&lt;/span&gt;][&lt;span class=&#34;string&#34;&gt;&amp;#x27;CLASSES&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We need to set the model&amp;#x27;s cfg for inference&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.cfg = config&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Convert the model to GPU&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.to(device)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Convert the model into evaluation mode&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Use the detector to do inference&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = &lt;span class=&#34;string&#34;&gt;&amp;#x27;demo/demo.jpg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = inference_detector(model, img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Let&amp;#x27;s plot the result&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_result_pyplot(model, img, result, score_thr=&lt;span class=&#34;number&#34;&gt;0.3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;load checkpoint from local path: checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth


/content/mmdetection/mmdet/datasets/utils.py:70: UserWarning: &amp;quot;ImageToTensor&amp;quot; pipeline is replaced by &amp;quot;DefaultFormatBundle&amp;quot; for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.
  &#39;data pipeline in your config file.&#39;, UserWarning)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_12_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;Detection3D&#34;&gt;Detection3D&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;%cd /content/mmdetection3d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!mkdir checkpoints&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v1&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/votenet/votenet_8x8_scannet-3d-&lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;/votenet_8x8_scannet-3d-&lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;class_20210823_234503-cf8134fa.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/votenet_8x8_scannet-3d-&lt;span class=&#34;number&#34;&gt;18&lt;/span&gt;class_20210823_234503-cf8134fa.pth&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/content/mmdetection3d
--2022-06-23 16:57:39--  https://download.openmmlab.com/mmdetection3d/v1.0.0_models/votenet/votenet_8x8_scannet-3d-18class/votenet_8x8_scannet-3d-18class_20210823_234503-cf8134fa.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.74.197.77
Connecting to download.openmmlab.com (download.openmmlab.com)|47.74.197.77|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3890927 (3.7M) [application/octet-stream]
Saving to: ‘checkpoints/votenet_8x8_scannet-3d-18class_20210823_234503-cf8134fa.pth’

checkpoints/votenet 100%[===================&amp;gt;]   3.71M  22.2MB/s    in 0.2s

2022-06-23 16:57:39 (22.2 MB/s) - ‘checkpoints/votenet_8x8_scannet-3d-18class_20210823_234503-cf8134fa.pth’ saved [3890927/3890927]
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# https://mmdetection3d.readthedocs.io/zh_CN/latest/getting_started.html#id10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet3d.apis &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; init_model, inference_detector&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;config_file = &lt;span class=&#34;string&#34;&gt;&amp;#x27;configs/votenet/votenet_8x8_scannet-3d-18class.py&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;checkpoint_file = &lt;span class=&#34;string&#34;&gt;&amp;#x27;checkpoints/votenet_8x8_scannet-3d-18class_20210823_234503-cf8134fa.pth&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 从配置文件和预训练的模型文件中构建模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = init_model(config_file, checkpoint_file, device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda:0&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试单个文件并可视化结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;point_cloud = &lt;span class=&#34;string&#34;&gt;&amp;#x27;demo/data/scannet/scene0000_00.bin&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result, data = inference_detector(model, point_cloud)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 可视化结果并且将结果保存到 &amp;#x27;results&amp;#x27; 文件夹&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.show_results(data, result, out_dir=&lt;span class=&#34;string&#34;&gt;&amp;#x27;results&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/conv_module.py:151: UserWarning: Unnecessary conv bias before batch/instance norm
  &#39;Unnecessary conv bias before batch/instance norm&#39;)


load checkpoint from local path: checkpoints/votenet_8x8_scannet-3d-18class_20210823_234503-cf8134fa.pth


/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;Custom-training&#34;&gt;Custom-training&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选择+下载预训练模型和数据集&lt;/p&gt;
&lt;p&gt;参数解释: &lt;code&gt;mask_rcnn_r50_fpn_2x_coco&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;mask_rcnn 中不同的 backbone (主干网络)&lt;/p&gt;
&lt;p&gt;r50: 50层ResNet&lt;/p&gt;
&lt;p&gt;fpn: 特征金字塔&lt;/p&gt;
&lt;p&gt;2x: learning rate schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;定义数据集类 + config&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;调用 API 训练 + 评估&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用训练好的模型推理测试&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;Detection-2&#34;&gt;Detection&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# pre-trained model 在上面下载好了, 这里只下载数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!unzip kitti_tiny.&lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt; &amp;gt; /dev/null&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Let&amp;#x27;s take a look at the dataset image&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; mmcv&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;img = mmcv.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/training/image_2/000073.jpeg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;25&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.imshow(mmcv.bgr2rgb(img))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;--2022-06-23 18:02:38--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip
Resolving download.openmmlab.com (download.openmmlab.com)... 47.74.197.77
Connecting to download.openmmlab.com (download.openmmlab.com)|47.74.197.77|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 6918271 (6.6M) [application/zip]
Saving to: ‘kitti_tiny.zip’

kitti_tiny.zip      100%[===================&amp;gt;]   6.60M  15.2MB/s    in 0.4s

2022-06-23 18:02:39 (15.2 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_18_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 自定义数据集格式 &amp;#x27;KittiTinyDataset&amp;#x27; 并注册到 mmdet&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; copy&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; os.path &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; osp&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; mmcv&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.datasets.builder &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DATASETS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.datasets.custom &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; CustomDataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;meta&#34;&gt;@DATASETS.register_module()&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;KittiTinyDataset&lt;/span&gt;(&lt;span class=&#34;title class_ inherited__&#34;&gt;CustomDataset&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    CLASSES = (&lt;span class=&#34;string&#34;&gt;&amp;#x27;Car&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;Pedestrian&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;Cyclist&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;load_annotations&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, ann_file&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        cat2label = &amp;#123;k: i &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i, k &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.CLASSES)&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# load image list from file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        image_list = mmcv.list_from_file(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.ann_file)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        data_infos = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# convert annotations to middle format&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; image_id &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; image_list:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            filename = &lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;self.img_prefix&amp;#125;&lt;/span&gt;/&lt;span class=&#34;subst&#34;&gt;&amp;#123;image_id&amp;#125;&lt;/span&gt;.jpeg&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            image = mmcv.imread(filename)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            height, width = image.shape[:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            data_info = &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(filename=&lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;image_id&amp;#125;&lt;/span&gt;.jpeg&amp;#x27;&lt;/span&gt;, width=width, height=height)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# load annotations&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            label_prefix = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.img_prefix.replace(&lt;span class=&#34;string&#34;&gt;&amp;#x27;image_2&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;label_2&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            lines = mmcv.list_from_file(osp.join(label_prefix, &lt;span class=&#34;string&#34;&gt;f&amp;#x27;&lt;span class=&#34;subst&#34;&gt;&amp;#123;image_id&amp;#125;&lt;/span&gt;.txt&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            content = [line.strip().split(&lt;span class=&#34;string&#34;&gt;&amp;#x27; &amp;#x27;&lt;/span&gt;) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; line &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; lines]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            bbox_names = [x[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; content]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            bboxes = [[&lt;span class=&#34;built_in&#34;&gt;float&lt;/span&gt;(info) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; info &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; x[&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;]] &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; x &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; content]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            gt_bboxes = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            gt_labels = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            gt_bboxes_ignore = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            gt_labels_ignore = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;comment&#34;&gt;# filter &amp;#x27;DontCare&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; bbox_name, bbox &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;(bbox_names, bboxes):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; bbox_name &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; cat2label:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    gt_labels.append(cat2label[bbox_name])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    gt_bboxes.append(bbox)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    gt_labels_ignore.append(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                    gt_bboxes_ignore.append(bbox)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            data_anno = &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                labels=np.array(gt_labels, dtype=np.long),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                bboxes_ignore=np.array(gt_bboxes_ignore,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                       dtype=np.float32).reshape(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            data_info.update(ann=data_anno)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            data_infos.append(data_info)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; data_infos&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# mmdet 配置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmcv &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Config&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.apis &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; set_random_seed&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg = Config.fromfile(&lt;span class=&#34;string&#34;&gt;&amp;#x27;configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# If we need to finetune a model based on a pre-trained detector, we need to use load_from to set the path of checkpoints.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.load_from = &lt;span class=&#34;string&#34;&gt;&amp;#x27;checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Modify dataset type and path&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.dataset_type = &lt;span class=&#34;string&#34;&gt;&amp;#x27;KittiTinyDataset&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data_root = &lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.test.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt; = &lt;span class=&#34;string&#34;&gt;&amp;#x27;KittiTinyDataset&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.test.data_root = &lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.test.ann_file = &lt;span class=&#34;string&#34;&gt;&amp;#x27;train.txt&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.test.img_prefix = &lt;span class=&#34;string&#34;&gt;&amp;#x27;training/image_2&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.train.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt; = &lt;span class=&#34;string&#34;&gt;&amp;#x27;KittiTinyDataset&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.train.data_root = &lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.train.ann_file = &lt;span class=&#34;string&#34;&gt;&amp;#x27;train.txt&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.train.img_prefix = &lt;span class=&#34;string&#34;&gt;&amp;#x27;training/image_2&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.val.&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt; = &lt;span class=&#34;string&#34;&gt;&amp;#x27;KittiTinyDataset&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.val.data_root = &lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.val.ann_file = &lt;span class=&#34;string&#34;&gt;&amp;#x27;val.txt&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.data.val.img_prefix = &lt;span class=&#34;string&#34;&gt;&amp;#x27;training/image_2&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# modify num classes of the model in box head&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.model.roi_head.bbox_head.num_classes = &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Set up working dir to save files and logs.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.work_dir = &lt;span class=&#34;string&#34;&gt;&amp;#x27;./tutorial_exps&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# The original learning rate (LR) is set for 8-GPU training.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We divide it by 8 since we only use one GPU.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.optimizer.lr = &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt; / &lt;span class=&#34;number&#34;&gt;8&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.lr_config.warmup = &lt;span class=&#34;literal&#34;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.log_config.interval = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Change the evaluation metric since we use customized dataset.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.evaluation.metric = &lt;span class=&#34;string&#34;&gt;&amp;#x27;mAP&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We can set the evaluation interval to reduce the evaluation times&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.evaluation.interval = &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We can set the checkpoint saving interval to reduce the storage cost&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.checkpoint_config.interval = &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Set seed thus the results are more reproducible&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.seed = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;set_random_seed(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, deterministic=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.device=&lt;span class=&#34;string&#34;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.gpu_ids = &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We can also use tensorboard to log the training process&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cfg.log_config.hooks = [&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;#x27;TextLoggerHook&amp;#x27;&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=&lt;span class=&#34;string&#34;&gt;&amp;#x27;TensorboardLoggerHook&amp;#x27;&lt;/span&gt;)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# We can initialize the logger for training and have a look at the final config used for training&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# print(f&amp;#x27;Config:\n&amp;#123;cfg.pretty_text&amp;#125;&amp;#x27;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Train a new detector&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; build_dataset&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.models &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; build_detector&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mmdet.apis &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_detector&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Build dataset&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;datasets = [build_dataset(cfg.data.train)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Build the detector&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = build_detector(cfg.model)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#  build_detector( cfg.model, train_cfg=cfg.get(&amp;#x27;train_cfg&amp;#x27;), test_cfg=cfg.get(&amp;#x27;test_cfg&amp;#x27;))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Add an attribute for visualization convenience&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.CLASSES = datasets[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].CLASSES&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# Create work_dir&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 报错:AttributeError: &amp;#x27;ConfigDict&amp;#x27; object has no attribute &amp;#x27;device&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# https://github.com/open-mmlab/mmdetection/issues/7901&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 在上面 cfg 添加了 cfg.device=&amp;#x27;cuda&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_detector(model, datasets, cfg, distributed=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;, validate=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
/content/mmdetection/mmdet/datasets/custom.py:180: UserWarning: CustomDataset does not support filtering empty gt images.
  &#39;CustomDataset does not support filtering empty gt images.&#39;)
2022-06-07 16:41:00,736 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2022-06-07 16:41:00,899 - mmdet - INFO - load checkpoint from local path: checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth
2022-06-07 16:41:01,026 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).
size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).
size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).
size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).
2022-06-07 16:41:01,035 - mmdet - INFO - Start running, host: root@7a73f7b358c4, work_dir: /content/mmdetection/tutorial_exps
2022-06-07 16:41:01,037 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook
(NORMAL      ) CheckpointHook
(LOW         ) EvalHook
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook
(NORMAL      ) NumClassCheckHook
(LOW         ) IterTimerHook
(LOW         ) EvalHook
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook
(LOW         ) IterTimerHook
(LOW         ) EvalHook
 --------------------
after_train_iter:
(ABOVE_NORMAL) OptimizerHook
(NORMAL      ) CheckpointHook
(LOW         ) IterTimerHook
(LOW         ) EvalHook
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
after_train_epoch:
(NORMAL      ) CheckpointHook
(LOW         ) EvalHook
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
before_val_epoch:
(NORMAL      ) NumClassCheckHook
(LOW         ) IterTimerHook
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
before_val_iter:
(LOW         ) IterTimerHook
 --------------------
after_val_iter:
(LOW         ) IterTimerHook
 --------------------
after_val_epoch:
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
after_run:
(VERY_LOW    ) TextLoggerHook
(VERY_LOW    ) TensorboardLoggerHook
 --------------------
2022-06-07 16:41:01,038 - mmdet - INFO - workflow: [(&#39;train&#39;, 1)], max: 12 epochs
2022-06-07 16:41:01,040 - mmdet - INFO - Checkpoints will be saved to /content/mmdetection/tutorial_exps by HardDiskBackend.
2022-06-07 16:41:17,697 - mmdet - INFO - Epoch [1][10/25]	lr: 2.500e-03, eta: 0:04:25, time: 0.914, data_time: 0.236, memory: 2790, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.0173, loss_cls: 0.5377, acc: 81.6211, loss_bbox: 0.3947, loss: 0.9764
2022-06-07 16:41:21,039 - mmdet - INFO - Epoch [1][20/25]	lr: 2.500e-03, eta: 0:02:54, time: 0.334, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0119, loss_cls: 0.1753, acc: 93.4570, loss_bbox: 0.3254, loss: 0.5275
2022-06-07 16:41:28,575 - mmdet - INFO - Epoch [2][10/25]	lr: 2.500e-03, eta: 0:02:16, time: 0.558, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0138, loss_cls: 0.1519, acc: 94.7656, loss_bbox: 0.2673, loss: 0.4497
2022-06-07 16:41:31,944 - mmdet - INFO - Epoch [2][20/25]	lr: 2.500e-03, eta: 0:02:01, time: 0.337, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0128, loss_rpn_bbox: 0.0127, loss_cls: 0.1325, acc: 94.9316, loss_bbox: 0.2084, loss: 0.3664
2022-06-07 16:41:39,445 - mmdet - INFO - Epoch [3][10/25]	lr: 2.500e-03, eta: 0:01:48, time: 0.569, data_time: 0.236, memory: 2790, loss_rpn_cls: 0.0059, loss_rpn_bbox: 0.0102, loss_cls: 0.0972, acc: 96.2500, loss_bbox: 0.1600, loss: 0.2733
2022-06-07 16:41:42,958 - mmdet - INFO - Epoch [3][20/25]	lr: 2.500e-03, eta: 0:01:40, time: 0.349, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0133, loss_cls: 0.1474, acc: 94.4336, loss_bbox: 0.2652, loss: 0.4346
2022-06-07 16:41:50,449 - mmdet - INFO - Epoch [4][10/25]	lr: 2.500e-03, eta: 0:01:31, time: 0.562, data_time: 0.231, memory: 2790, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0134, loss_cls: 0.1168, acc: 95.5566, loss_bbox: 0.2201, loss: 0.3567
2022-06-07 16:41:53,973 - mmdet - INFO - Epoch [4][20/25]	lr: 2.500e-03, eta: 0:01:25, time: 0.353, data_time: 0.027, memory: 2790, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0117, loss_cls: 0.1179, acc: 95.5566, loss_bbox: 0.2133, loss: 0.3464
2022-06-07 16:42:01,892 - mmdet - INFO - Epoch [5][10/25]	lr: 2.500e-03, eta: 0:01:18, time: 0.595, data_time: 0.237, memory: 2790, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0092, loss_cls: 0.1003, acc: 96.2695, loss_bbox: 0.2087, loss: 0.3223
2022-06-07 16:42:05,430 - mmdet - INFO - Epoch [5][20/25]	lr: 2.500e-03, eta: 0:01:13, time: 0.352, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0037, loss_rpn_bbox: 0.0107, loss_cls: 0.0903, acc: 96.7090, loss_bbox: 0.1845, loss: 0.2892
2022-06-07 16:42:12,992 - mmdet - INFO - Epoch [6][10/25]	lr: 2.500e-03, eta: 0:01:07, time: 0.567, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0082, loss_cls: 0.0786, acc: 97.1777, loss_bbox: 0.1799, loss: 0.2685
2022-06-07 16:42:16,595 - mmdet - INFO - Epoch [6][20/25]	lr: 2.500e-03, eta: 0:01:02, time: 0.363, data_time: 0.027, memory: 2790, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0100, loss_cls: 0.0891, acc: 96.5332, loss_bbox: 0.1856, loss: 0.2876
2022-06-07 16:42:24,486 - mmdet - INFO - Epoch [7][10/25]	lr: 2.500e-03, eta: 0:00:56, time: 0.591, data_time: 0.238, memory: 2790, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0096, loss_cls: 0.0904, acc: 96.6113, loss_bbox: 0.1740, loss: 0.2783
2022-06-07 16:42:28,147 - mmdet - INFO - Epoch [7][20/25]	lr: 2.500e-03, eta: 0:00:52, time: 0.364, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0116, loss_cls: 0.0926, acc: 96.1816, loss_bbox: 0.1774, loss: 0.2835
2022-06-07 16:42:35,802 - mmdet - INFO - Epoch [8][10/25]	lr: 2.500e-03, eta: 0:00:45, time: 0.572, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0091, loss_cls: 0.0777, acc: 96.8262, loss_bbox: 0.1420, loss: 0.2314
2022-06-07 16:42:39,346 - mmdet - INFO - Epoch [8][20/25]	lr: 2.500e-03, eta: 0:00:41, time: 0.354, data_time: 0.025, memory: 2790, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0082, loss_cls: 0.0777, acc: 97.2168, loss_bbox: 0.1590, loss: 0.2485
2022-06-07 16:42:46,922 - mmdet - INFO - Epoch [9][10/25]	lr: 2.500e-04, eta: 0:00:35, time: 0.565, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0082, loss_cls: 0.0658, acc: 97.4902, loss_bbox: 0.1351, loss: 0.2116
2022-06-07 16:42:50,443 - mmdet - INFO - Epoch [9][20/25]	lr: 2.500e-04, eta: 0:00:31, time: 0.352, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0066, loss_cls: 0.0571, acc: 97.8418, loss_bbox: 0.1133, loss: 0.1783
2022-06-07 16:42:58,001 - mmdet - INFO - Epoch [10][10/25]	lr: 2.500e-04, eta: 0:00:25, time: 0.567, data_time: 0.233, memory: 2790, loss_rpn_cls: 0.0034, loss_rpn_bbox: 0.0081, loss_cls: 0.0678, acc: 97.3926, loss_bbox: 0.1332, loss: 0.2125
2022-06-07 16:43:01,493 - mmdet - INFO - Epoch [10][20/25]	lr: 2.500e-04, eta: 0:00:21, time: 0.350, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0059, loss_cls: 0.0594, acc: 97.6758, loss_bbox: 0.1294, loss: 0.1955
2022-06-07 16:43:09,042 - mmdet - INFO - Epoch [11][10/25]	lr: 2.500e-04, eta: 0:00:15, time: 0.567, data_time: 0.234, memory: 2790, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0069, loss_cls: 0.0638, acc: 97.6270, loss_bbox: 0.1217, loss: 0.1932
2022-06-07 16:43:12,554 - mmdet - INFO - Epoch [11][20/25]	lr: 2.500e-04, eta: 0:00:11, time: 0.351, data_time: 0.023, memory: 2790, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0073, loss_cls: 0.0571, acc: 97.8711, loss_bbox: 0.1212, loss: 0.1869
2022-06-07 16:43:20,107 - mmdet - INFO - Epoch [12][10/25]	lr: 2.500e-05, eta: 0:00:05, time: 0.567, data_time: 0.232, memory: 2790, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0061, loss_cls: 0.0563, acc: 97.9199, loss_bbox: 0.1246, loss: 0.1887
2022-06-07 16:43:23,598 - mmdet - INFO - Epoch [12][20/25]	lr: 2.500e-05, eta: 0:00:01, time: 0.349, data_time: 0.024, memory: 2790, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0048, loss_cls: 0.0511, acc: 97.9297, loss_bbox: 0.0946, loss: 0.1520
2022-06-07 16:43:25,323 - mmdet - INFO - Saving checkpoint at 12 epochs


[&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;] 25/25, 9.8 task/s, elapsed: 3s, ETA:     0s
---------------iou_thr: 0.5---------------


2022-06-07 16:43:30,260 - mmdet - INFO -
+------------+-----+------+--------+-------+
| class      | gts | dets | recall | ap    |
+------------+-----+------+--------+-------+
| Car        | 62  | 133  | 0.984  | 0.888 |
| Pedestrian | 13  | 40   | 0.846  | 0.768 |
| Cyclist    | 7   | 50   | 0.571  | 0.114 |
+------------+-----+------+--------+-------+
| mAP        |     |      |        | 0.590 |
+------------+-----+------+--------+-------+
2022-06-07 16:43:30,268 - mmdet - INFO - Epoch(val) [12][25]	AP50: 0.5900, mAP: 0.5899
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# load tensorboard in colab&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%load_ext tensorboard&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# see curves in tensorboard&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;%tensorboard --logdir ./tutorial_exps&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;IPython.core.display.Javascript object&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;img = mmcv.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;kitti_tiny/training/image_2/000068.jpeg&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.cfg = cfg&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = inference_detector(model, img)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;show_result_pyplot(model, img, result)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_23_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;Detection3D-2&#34;&gt;Detection3D&lt;/h3&gt;
&lt;h4 id=&#34;单模态点云-3DDetect&#34;&gt;单模态点云-3DDetect&lt;/h4&gt;
&lt;p&gt;可以简单的把流程看做: &lt;code&gt;把. bin点云数据 转换为 .obj点云和预测 3D 框的可视化结果&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;%cd /content/mmdetection3d&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!mkdir checkpoints&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v0&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/second/hv_second_secfpn_6x8_80e_kitti-3d-car/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v1&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/votenet/votenet_16x8_sunrgbd-3d-&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;/votenet_16x8_sunrgbd-3d-&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;class_20210820_162823-bf11f014.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/votenet_16x8_sunrgbd-3d-&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;class_20210820_162823-bf11f014.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/pcd_demo.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/kitti/kitti_000008.&lt;span class=&#34;built_in&#34;&gt;bin&lt;/span&gt; \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  configs/second/hv_second_secfpn_6x8_80e_kitti-3d-car.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  checkpoints/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  --out-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; /content/mmdetection3d/result/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/pcd_demo.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/sunrgbd/sunrgbd_000017.&lt;span class=&#34;built_in&#34;&gt;bin&lt;/span&gt; \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  configs/votenet/votenet_16x8_sunrgbd-3d-&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  checkpoints/votenet_16x8_sunrgbd-3d-&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;class_20210820_162823-bf11f014.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  --out-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; /content/mmdetection3d/result/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;/content/mmdetection3d
mkdir: cannot create directory ‘checkpoints’: File exists
--2022-06-20 16:05:19--  https://download.openmmlab.com/mmdetection3d/v0.1.0_models/second/hv_second_secfpn_6x8_80e_kitti-3d-car/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.72
Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.72|:443... connected.
HTTP request sent, awaiting response... 200 OK

    The file is already fully retrieved; nothing to do.

--2022-06-20 16:05:20--  https://download.openmmlab.com/mmdetection3d/v1.0.0_models/votenet/votenet_16x8_sunrgbd-3d-10class/votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.72
Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.72|:443... connected.
HTTP request sent, awaiting response... 200 OK

    The file is already fully retrieved; nothing to do.

/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
/content/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:85: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future
  &#39;dir_offset and dir_limit_offset will be depressed and be &#39;
load checkpoint from local path: checkpoints/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth
[0m/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/conv_module.py:151: UserWarning: Unnecessary conv bias before batch/instance norm
  &#39;Unnecessary conv bias before batch/instance norm&#39;)
load checkpoint from local path: checkpoints/votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;多模态点云加图像-3DDetect&#34;&gt;多模态点云加图像-3DDetect&lt;/h4&gt;
&lt;p&gt;通常是 点云+图像, 数据集需要额外的 annotation 提供 3D 到 2D 的仿射矩阵&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v1&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;class_20210831_060805-&lt;span class=&#34;number&#34;&gt;83442923.&lt;/span&gt;pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;class_20210831_060805-&lt;span class=&#34;number&#34;&gt;83442923.&lt;/span&gt;pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!rm -rf result/kitti_000008&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/multi_modality_demo.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/kitti/kitti_000008.&lt;span class=&#34;built_in&#34;&gt;bin&lt;/span&gt; \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/kitti/kitti_000008.png \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/kitti/kitti_000008_infos.pkl \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  configs/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  checkpoints/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;class_20210831_060805-&lt;span class=&#34;number&#34;&gt;83442923.&lt;/span&gt;pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  --out-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; /content/mmdetection3d/result/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;25&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.imshow(plt.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;result/kitti_000008/kitti_000008_pred.png&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;--2022-06-23 18:07:17--  https://download.openmmlab.com/mmdetection3d/v1.0.0_models/mvxnet/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28
Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.
HTTP request sent, awaiting response... 200 OK

    The file is already fully retrieved; nothing to do.

/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
/content/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:85: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future
  &#39;dir_offset and dir_limit_offset will be depressed and be &#39;
load checkpoint from local path: checkpoints/dv_mvx-fpn_second_secfpn_adamw_2x8_80e_kitti-3d-3class_20210831_060805-83442923.pth
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/content/mmdetection3d/mmdet3d/models/fusion_layers/coord_transform.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  if &#39;pcd_rotation&#39; in img_meta else torch.eye(
[0m




&amp;lt;matplotlib.image.AxesImage at 0x7f7100889490&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_28_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;单目图像-3DDetect&#34;&gt;单目图像-3DDetect&lt;/h4&gt;
&lt;p&gt;可以理解为在多模态上去掉点云数据 (当然数据集会有所变动), 效果不如多模态&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v0&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_20210715_235813-4bed5239.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_20210715_235813-4bed5239.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/mono_det_demo.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/nuscenes/n015-&lt;span class=&#34;number&#34;&gt;2018&lt;/span&gt;-07-&lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;11&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;22&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;45&lt;/span&gt;+0800__CAM_BACK__1532402927637525.jpg \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/nuscenes/n015-&lt;span class=&#34;number&#34;&gt;2018&lt;/span&gt;-07-&lt;span class=&#34;number&#34;&gt;24&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;11&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;22&lt;/span&gt;-&lt;span class=&#34;number&#34;&gt;45&lt;/span&gt;+0800__CAM_BACK__1532402927637525_mono3d.coco.json \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  configs/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  checkpoints/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_20210715_235813-4bed5239.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  --out-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; /content/mmdetection3d/result/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;25&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.imshow(plt.imread(&lt;span class=&#34;string&#34;&gt;&amp;#x27;result/n015-2018-07-24-11-22-45+0800__CAM_BACK__1532402927637525/n015-2018-07-24-11-22-45+0800__CAM_BACK__1532402927637525_pred.png&amp;#x27;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;--2022-06-23 18:06:22--  https://download.openmmlab.com/mmdetection3d/v0.1.0_models/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_20210715_235813-4bed5239.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.74.197.77
Connecting to download.openmmlab.com (download.openmmlab.com)|47.74.197.77|:443... connected.
HTTP request sent, awaiting response... 200 OK

    The file is already fully retrieved; nothing to do.

/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
load checkpoint from local path: checkpoints/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_20210715_235813-4bed5239.pth
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
[0m




&amp;lt;matplotlib.image.AxesImage at 0x7f7100999a50&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;MM-Detection_files/MM-Detection_30_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;点云-Segment&#34;&gt;点云-Segment&lt;/h4&gt;
&lt;p&gt;由于图像/视频很难做到定位以及测距的目标, 目前做 segmentation 只能用点云, 而且目前的模型仅支持室内&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;!wget -c https://download.openmmlab.com/mmdetection3d/v0&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;number&#34;&gt;.0&lt;/span&gt;_models/pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;class_20210514_143644-ee73704a.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;      -O checkpoints/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;class_20210514_143644-ee73704a.pth&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;!python \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/pc_seg_demo.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  demo/data/scannet/scene0000_00.&lt;span class=&#34;built_in&#34;&gt;bin&lt;/span&gt; \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  configs/pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt;.py \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  checkpoints/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;class_20210514_143644-ee73704a.pth \&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  --out-&lt;span class=&#34;built_in&#34;&gt;dir&lt;/span&gt; /content/mmdetection3d/result/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;--2022-06-20 17:28:15--  https://download.openmmlab.com/mmdetection3d/v0.1.0_models/pointnet2/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth
Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.72
Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.72|:443... connected.
HTTP request sent, awaiting response... 200 OK

    The file is already fully retrieved; nothing to do.

/content/mmdetection3d/mmdet3d/models/backbones/mink_resnet.py:10: UserWarning: Please follow `getting_started.md` to install MinkowskiEngine.`
  &#39;Please follow `getting_started.md` to install MinkowskiEngine.`&#39;)
/usr/local/lib/python3.7/dist-packages/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.
  &#39;Default ``avg_non_ignore`` is False, if you would like to &#39;
/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/conv_module.py:151: UserWarning: Unnecessary conv bias before batch/instance norm
  &#39;Unnecessary conv bias before batch/instance norm&#39;)
load checkpoint from local path: checkpoints/pointnet2_ssg_16x2_cosine_200e_scannet_seg-3d-20class_20210514_143644-ee73704a.pth
/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;借物表&#34;&gt;借物表&lt;/h2&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-1&#39; href=&#39;#cite_ref-1&#39;&gt;[1]&lt;/a&gt;: &lt;a href=&#34;https://openbayes.com/console/wrh/containers/t93t3LTXlgU&#34;&gt;https://openbayes.com/console/wrh/containers/t93t3LTXlgU&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-2&#39; href=&#39;#cite_ref-2&#39;&gt;[2]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/163645165&#34;&gt;MMDetection 2.3 安装教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-3&#39; href=&#39;#cite_ref-3&#39;&gt;[3]&lt;/a&gt;: &lt;a href=&#34;https://mmdetection.readthedocs.io/zh_CN/latest/get_started.html#mmdetection&#34;&gt;https://mmdetection.readthedocs.io/zh_CN/latest/get_started.html#mmdetection&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-4&#39; href=&#39;#cite_ref-4&#39;&gt;[4]&lt;/a&gt;: &lt;a href=&#34;https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=8M5KUnX7Np3h&#34;&gt;https://colab.research.google.com/github/ZwwWayne/mmdetection/blob/update-colab/demo/MMDet_Tutorial.ipynb#scrollTo=8M5KUnX7Np3h&lt;/a&gt;&lt;/p&gt;
&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kity@2.0.4/dist/kity.min.js&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js&#34;&gt;&lt;/script&gt;&lt;script defer=&#34;true&#34; type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js&#34;&gt;&lt;/script&gt;&lt;link rel=&#34;stylesheet&#34; type=&#34;text&amp;#x2F;css&#34; href=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css&#34;&gt;</content>
        <category term="深度学习" />
        <category term="MMDetection" />
        <category term="Colab" />
        <updated>2022-06-07T09:06:50.000Z</updated>
    </entry>
    <entry>
        <id>https://weidows.github.io/post/lang/python/code/DL/</id>
        <title>👩‍❤️‍💋‍👨Code-4-Deep-Learning</title>
        <link rel="alternate" href="https://weidows.github.io/post/lang/python/code/DL/"/>
        <content type="html">&lt;!--
 * @?: *********************************************************************
 * @Author: Weidows
 * @LastEditors: Weidows
 * @LastEditTime: 2024-08-07 12:54:47
 * @FilePath: \Blog-private\source\_posts\python\code\DL.md
 * @Description:
 * @!: *********************************************************************
--&gt;
&lt;h2 id=&#34;序&#34;&gt;序&lt;/h2&gt;
&lt;p&gt;此文为其他文章的代码部分:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;../../AI/DL&#34;&gt;⚡再啃-Deep-Learning&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也提供了 notebook 形式: &lt;a href=&#34;https://github.com/Weidows-projects/public-post/blob/main/notebook/DL/DL.ipynb&#34;&gt;代码地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;神经网络&#34;&gt;神经网络&lt;/h2&gt;
&lt;h3 id=&#34;感知器&#34;&gt;感知器&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;AND&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x1, x2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    w1, w2, theta = &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.7&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tmp = x1 * w1 + x2 * w2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; tmp &amp;lt;= theta:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;OR&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x1, x2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    w1, w2, theta = &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tmp = x1 * w1 + x2 * w2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; tmp &amp;lt;= theta:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 非门只取一个输入,另一个不管&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;NOT&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x1, x2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    w1, w2, theta = -&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    tmp = x1 * w1 + x2 * w2 + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; tmp&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 异或门是非线性运算, 需要多层感知器组合&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;XOR&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;x1, x2&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 异或门 = (与非门 与 或门)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; AND(OR(x1, x2), &lt;span class=&#34;keyword&#34;&gt;not&lt;/span&gt; AND(x1, x2))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(AND(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), AND(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), OR(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), OR(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(NOT(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), NOT(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), NOT(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), NOT(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(XOR(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), XOR(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;), XOR(&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;), XOR(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;0 1 1 0
1 0 1 0
1 0 0 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;Pytorch&#34;&gt;Pytorch&lt;/h2&gt;
&lt;h3 id=&#34;MNIST-手写数字识别&#34;&gt;MNIST-手写数字识别&lt;/h3&gt;
&lt;p&gt;入门典中典 &lt;sup id=&#39;cite_ref-1&#39;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[1]&lt;/a&gt;&lt;/sup&gt;, 具体教程推荐 &lt;sup id=&#39;cite_ref-2&#39;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[2]&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#39;cite_ref-3&#39;&gt;&lt;a href=&#34;#cite_note-3&#34;&gt;[3]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torchvision&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; torch.utils.data &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DataLoader&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 超参&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;n_epochs = &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size_train = &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_size_test = &lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;learning_rate = &lt;span class=&#34;number&#34;&gt;0.01&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;momentum = &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;log_interval = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;random_seed = &lt;span class=&#34;number&#34;&gt;42&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;torch.manual_seed(random_seed)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;MINST_mean = &lt;span class=&#34;number&#34;&gt;0.1307&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;MINST_std = &lt;span class=&#34;number&#34;&gt;0.3081&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transform=torchvision.transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        torchvision.transforms.ToTensor(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        torchvision.transforms.Normalize((MINST_mean, ), (MINST_std, ))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ])),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                           batch_size=batch_size_train,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                           shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train=&lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    download=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    transform=torchvision.transforms.Compose([&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        torchvision.transforms.ToTensor(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        torchvision.transforms.Normalize((MINST_mean, ), (MINST_std, ))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ])),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                          batch_size=batch_size_test,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                          shuffle=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;batch_idx, (example_data, example_targets) = &lt;span class=&#34;built_in&#34;&gt;next&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(train_loader))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 每批次有 64 张单通道 28x28 大小的图片&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(example_data.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 每个图片实际的数字标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(example_targets)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;fig = plt.figure()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.subplot(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, i + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.tight_layout()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.imshow(example_data[i][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], cmap=&lt;span class=&#34;string&#34;&gt;&amp;#x27;gray&amp;#x27;&lt;/span&gt;, interpolation=&lt;span class=&#34;string&#34;&gt;&amp;#x27;none&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# plt.title(&amp;quot;数字: &amp;#123;&amp;#125;&amp;quot;.format(example_targets[i]))&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.title(&lt;span class=&#34;string&#34;&gt;f&amp;#x27;number: &lt;span class=&#34;subst&#34;&gt;&amp;#123;example_targets[i]&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.xticks([])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.yticks([])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;torch.Size([64, 1, 28, 28])
tensor([1, 2, 8, 5, 2, 6, 9, 9, 9, 4, 0, 3, 9, 9, 5, 6, 7, 8, 8, 9, 2, 6, 9, 3,
        0, 5, 0, 7, 6, 1, 2, 0, 7, 4, 6, 0, 6, 9, 7, 0, 7, 3, 2, 5, 9, 0, 4, 8,
        3, 6, 4, 0, 3, 2, 6, 6, 3, 2, 2, 3, 6, 7, 8, 4])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;DL_files/DL_4_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; nn&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.nn.functional &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; F&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; torch.optim &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; optim&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;title class_&#34;&gt;Net&lt;/span&gt;(nn.Module):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;__init__&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;built_in&#34;&gt;super&lt;/span&gt;(Net, &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 卷积层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv1 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv2 = nn.Conv2d(&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, kernel_size=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 加一层 dropout (删除神经元), 防止过拟合; 不要直接用 F.dropout2d&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv2_drop = nn.Dropout2d()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 全连接层&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.fc1 = nn.Linear(&lt;span class=&#34;number&#34;&gt;320&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.fc2 = nn.Linear(&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;forward&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 原28x28x1 -&amp;gt; 卷积24x24x10 -&amp;gt; 池化12x12x10 -&amp;gt; 激活12x12x10&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(F.max_pool2d(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv1(x), &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 原12x12x10 -&amp;gt; 卷积8x8x20 -&amp;gt; 池化4x4x20 -&amp;gt; 激活4x4x20&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(F.max_pool2d(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv2_drop(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.conv2(x)), &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;comment&#34;&gt;# 320 = 4x4x20 将张量x变形成一维向量形式，总特征数不变，为全连接层做准备&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = x.view(-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;320&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.relu(&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.fc1(x))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = F.dropout(x, training=&lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.training)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        x = &lt;span class=&#34;variable language_&#34;&gt;self&lt;/span&gt;.fc2(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; F.log_softmax(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network = Net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer = optim.SGD(network.parameters(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                      lr=learning_rate,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                      momentum=momentum)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_losses = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;train_counter = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_losses = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_counter = [i * &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loader.dataset) &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(n_epochs + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;train&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;epoch&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    network.train()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; batch_idx, (data, target) &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(train_loader):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.zero_grad()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        output = network(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss = F.nll_loss(output, target)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        loss.backward()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        optimizer.step()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; batch_idx % log_interval == &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Train Epoch: &amp;#123;&amp;#125; [&amp;#123;&amp;#125;/&amp;#123;&amp;#125; (&amp;#123;:.0f&amp;#125;%)]\tLoss: &amp;#123;:.6f&amp;#125;&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                epoch + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, batch_idx * &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(data), &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loader.dataset),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                &lt;span class=&#34;number&#34;&gt;100.&lt;/span&gt; * batch_idx / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loader), loss.item()))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_losses.append(loss.item())&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            train_counter.append((batch_idx * &lt;span class=&#34;number&#34;&gt;64&lt;/span&gt;) +&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                 (epoch * &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loader.dataset)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.save(network.state_dict(), &lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/MNIST/model.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            torch.save(optimizer.state_dict(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                       &lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/MNIST/optimizer.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;test&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    network.&lt;span class=&#34;built_in&#34;&gt;eval&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_loss = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    correct = &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 测试集不需要反向传播，所以使用 torch.no_grad() 方法关闭计算图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;with&lt;/span&gt; torch.no_grad():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; data, target &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; test_loader:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            output = network(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            test_loss += F.nll_loss(output, target, reduction=&lt;span class=&#34;string&#34;&gt;&amp;#x27;sum&amp;#x27;&lt;/span&gt;).item()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            pred = output.data.&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, keepdim=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            correct += pred.eq(target.data.view_as(pred)).&lt;span class=&#34;built_in&#34;&gt;sum&lt;/span&gt;()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_loss /= &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(test_loader.dataset)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_losses.append(test_loss)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;\nTest set: Avg. loss: &amp;#123;:.4f&amp;#125;, Accuracy: &amp;#123;&amp;#125;/&amp;#123;&amp;#125; (&amp;#123;:.0f&amp;#125;%)\n&amp;#x27;&lt;/span&gt;.&lt;span class=&#34;built_in&#34;&gt;format&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        test_loss, correct, &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(test_loader.dataset),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;number&#34;&gt;100.&lt;/span&gt; * correct / &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(test_loader.dataset)))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; __name__ == &lt;span class=&#34;string&#34;&gt;&amp;#x27;__main__&amp;#x27;&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# train(0)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 不加这个，后面画图就会报错：x and y must be the same size&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; epoch &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(n_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        train(epoch)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        test()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;C:\Users\Administrator\AppData\Local\Temp\ipykernel_18752\2337744027.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)


Train Epoch: 1 [0/60000 (0%)]	Loss: 2.306355
Train Epoch: 1 [640/60000 (1%)]	Loss: 2.309732
Train Epoch: 1 [1280/60000 (2%)]	Loss: 2.263060
Train Epoch: 1 [1920/60000 (3%)]	Loss: 2.253021
Train Epoch: 1 [2560/60000 (4%)]	Loss: 2.239486
Train Epoch: 1 [3200/60000 (5%)]	Loss: 2.232780
Train Epoch: 1 [3840/60000 (6%)]	Loss: 2.223558
Train Epoch: 1 [4480/60000 (7%)]	Loss: 2.174626
Train Epoch: 1 [5120/60000 (9%)]	Loss: 2.122881
Train Epoch: 1 [5760/60000 (10%)]	Loss: 2.025848
Train Epoch: 1 [6400/60000 (11%)]	Loss: 1.923471
Train Epoch: 1 [7040/60000 (12%)]	Loss: 1.832063
Train Epoch: 1 [7680/60000 (13%)]	Loss: 1.906025
Train Epoch: 1 [8320/60000 (14%)]	Loss: 1.673950
Train Epoch: 1 [8960/60000 (15%)]	Loss: 1.537203
Train Epoch: 1 [9600/60000 (16%)]	Loss: 1.439621
Train Epoch: 1 [10240/60000 (17%)]	Loss: 1.275429
Train Epoch: 1 [10880/60000 (18%)]	Loss: 1.183242
Train Epoch: 1 [11520/60000 (19%)]	Loss: 1.182200
Train Epoch: 1 [12160/60000 (20%)]	Loss: 1.154036
Train Epoch: 1 [12800/60000 (21%)]	Loss: 0.921464
Train Epoch: 1 [13440/60000 (22%)]	Loss: 0.877538
Train Epoch: 1 [14080/60000 (23%)]	Loss: 0.917646
Train Epoch: 1 [14720/60000 (25%)]	Loss: 0.928683
Train Epoch: 1 [15360/60000 (26%)]	Loss: 0.883320
Train Epoch: 1 [16000/60000 (27%)]	Loss: 0.829271
Train Epoch: 1 [16640/60000 (28%)]	Loss: 0.843372
Train Epoch: 1 [17280/60000 (29%)]	Loss: 0.962177
Train Epoch: 1 [17920/60000 (30%)]	Loss: 0.816695
Train Epoch: 1 [18560/60000 (31%)]	Loss: 0.803838
Train Epoch: 1 [19200/60000 (32%)]	Loss: 0.706732
Train Epoch: 1 [19840/60000 (33%)]	Loss: 0.697531
Train Epoch: 1 [20480/60000 (34%)]	Loss: 0.748919
Train Epoch: 1 [21120/60000 (35%)]	Loss: 0.599384
Train Epoch: 1 [21760/60000 (36%)]	Loss: 0.873525
Train Epoch: 1 [22400/60000 (37%)]	Loss: 0.730187
Train Epoch: 1 [23040/60000 (38%)]	Loss: 0.780188
Train Epoch: 1 [23680/60000 (39%)]	Loss: 0.688149
Train Epoch: 1 [24320/60000 (41%)]	Loss: 0.578381
Train Epoch: 1 [24960/60000 (42%)]	Loss: 0.679022
Train Epoch: 1 [25600/60000 (43%)]	Loss: 0.597318
Train Epoch: 1 [26240/60000 (44%)]	Loss: 0.885319
Train Epoch: 1 [26880/60000 (45%)]	Loss: 0.586243
Train Epoch: 1 [27520/60000 (46%)]	Loss: 0.832649
Train Epoch: 1 [28160/60000 (47%)]	Loss: 0.541850
Train Epoch: 1 [28800/60000 (48%)]	Loss: 0.997807
Train Epoch: 1 [29440/60000 (49%)]	Loss: 0.680030
Train Epoch: 1 [30080/60000 (50%)]	Loss: 0.546325
Train Epoch: 1 [30720/60000 (51%)]	Loss: 0.812084
Train Epoch: 1 [31360/60000 (52%)]	Loss: 0.659495
Train Epoch: 1 [32000/60000 (53%)]	Loss: 0.880883
Train Epoch: 1 [32640/60000 (54%)]	Loss: 0.788217
Train Epoch: 1 [33280/60000 (55%)]	Loss: 0.810931
Train Epoch: 1 [33920/60000 (57%)]	Loss: 0.572216
Train Epoch: 1 [34560/60000 (58%)]	Loss: 0.481873
Train Epoch: 1 [35200/60000 (59%)]	Loss: 0.502513
Train Epoch: 1 [35840/60000 (60%)]	Loss: 0.410055
Train Epoch: 1 [36480/60000 (61%)]	Loss: 0.489813
Train Epoch: 1 [37120/60000 (62%)]	Loss: 0.507667
Train Epoch: 1 [37760/60000 (63%)]	Loss: 0.497175
Train Epoch: 1 [38400/60000 (64%)]	Loss: 0.433524
Train Epoch: 1 [39040/60000 (65%)]	Loss: 0.448550
Train Epoch: 1 [39680/60000 (66%)]	Loss: 0.451818
Train Epoch: 1 [40320/60000 (67%)]	Loss: 0.501129
Train Epoch: 1 [40960/60000 (68%)]	Loss: 0.605211
Train Epoch: 1 [41600/60000 (69%)]	Loss: 0.332027
Train Epoch: 1 [42240/60000 (70%)]	Loss: 0.483988
Train Epoch: 1 [42880/60000 (71%)]	Loss: 0.887791
Train Epoch: 1 [43520/60000 (72%)]	Loss: 0.273152
Train Epoch: 1 [44160/60000 (74%)]	Loss: 0.590317
Train Epoch: 1 [44800/60000 (75%)]	Loss: 0.459316
Train Epoch: 1 [45440/60000 (76%)]	Loss: 0.492083
Train Epoch: 1 [46080/60000 (77%)]	Loss: 0.477218
Train Epoch: 1 [46720/60000 (78%)]	Loss: 0.421333
Train Epoch: 1 [47360/60000 (79%)]	Loss: 0.576612
Train Epoch: 1 [48000/60000 (80%)]	Loss: 0.359032
Train Epoch: 1 [48640/60000 (81%)]	Loss: 0.434221
Train Epoch: 1 [49280/60000 (82%)]	Loss: 0.506898
Train Epoch: 1 [49920/60000 (83%)]	Loss: 0.342816
Train Epoch: 1 [50560/60000 (84%)]	Loss: 0.287471
Train Epoch: 1 [51200/60000 (85%)]	Loss: 0.250604
Train Epoch: 1 [51840/60000 (86%)]	Loss: 0.386828
Train Epoch: 1 [52480/60000 (87%)]	Loss: 0.331759
Train Epoch: 1 [53120/60000 (88%)]	Loss: 0.388772
Train Epoch: 1 [53760/60000 (90%)]	Loss: 0.509017
Train Epoch: 1 [54400/60000 (91%)]	Loss: 0.517717
Train Epoch: 1 [55040/60000 (92%)]	Loss: 0.393285
Train Epoch: 1 [55680/60000 (93%)]	Loss: 0.341990
Train Epoch: 1 [56320/60000 (94%)]	Loss: 0.434098
Train Epoch: 1 [56960/60000 (95%)]	Loss: 0.342924
Train Epoch: 1 [57600/60000 (96%)]	Loss: 0.617892
Train Epoch: 1 [58240/60000 (97%)]	Loss: 0.488426
Train Epoch: 1 [58880/60000 (98%)]	Loss: 0.356584
Train Epoch: 1 [59520/60000 (99%)]	Loss: 0.548745

Test set: Avg. loss: 0.1674, Accuracy: 9512/10000 (95%)

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.315766
Train Epoch: 2 [640/60000 (1%)]	Loss: 0.468051
Train Epoch: 2 [1280/60000 (2%)]	Loss: 0.464737
Train Epoch: 2 [1920/60000 (3%)]	Loss: 0.357223
Train Epoch: 2 [2560/60000 (4%)]	Loss: 0.317739
Train Epoch: 2 [3200/60000 (5%)]	Loss: 0.684018
Train Epoch: 2 [3840/60000 (6%)]	Loss: 0.464855
Train Epoch: 2 [4480/60000 (7%)]	Loss: 0.420857
Train Epoch: 2 [5120/60000 (9%)]	Loss: 0.508732
Train Epoch: 2 [5760/60000 (10%)]	Loss: 0.318191
Train Epoch: 2 [6400/60000 (11%)]	Loss: 0.346217
Train Epoch: 2 [7040/60000 (12%)]	Loss: 0.559674
Train Epoch: 2 [7680/60000 (13%)]	Loss: 0.409686
Train Epoch: 2 [8320/60000 (14%)]	Loss: 0.535685
Train Epoch: 2 [8960/60000 (15%)]	Loss: 0.480220
Train Epoch: 2 [9600/60000 (16%)]	Loss: 0.519283
Train Epoch: 2 [10240/60000 (17%)]	Loss: 0.329807
Train Epoch: 2 [10880/60000 (18%)]	Loss: 0.393071
Train Epoch: 2 [11520/60000 (19%)]	Loss: 0.444064
Train Epoch: 2 [12160/60000 (20%)]	Loss: 0.533698
Train Epoch: 2 [12800/60000 (21%)]	Loss: 0.511128
Train Epoch: 2 [13440/60000 (22%)]	Loss: 0.346371
Train Epoch: 2 [14080/60000 (23%)]	Loss: 0.307755
Train Epoch: 2 [14720/60000 (25%)]	Loss: 0.536841
Train Epoch: 2 [15360/60000 (26%)]	Loss: 0.310219
Train Epoch: 2 [16000/60000 (27%)]	Loss: 0.493684
Train Epoch: 2 [16640/60000 (28%)]	Loss: 0.395575
Train Epoch: 2 [17280/60000 (29%)]	Loss: 0.252499
Train Epoch: 2 [17920/60000 (30%)]	Loss: 0.238181
Train Epoch: 2 [18560/60000 (31%)]	Loss: 0.323044
Train Epoch: 2 [19200/60000 (32%)]	Loss: 0.421634
Train Epoch: 2 [19840/60000 (33%)]	Loss: 0.409919
Train Epoch: 2 [20480/60000 (34%)]	Loss: 0.325331
Train Epoch: 2 [21120/60000 (35%)]	Loss: 0.396984
Train Epoch: 2 [21760/60000 (36%)]	Loss: 0.395612
Train Epoch: 2 [22400/60000 (37%)]	Loss: 0.378807
Train Epoch: 2 [23040/60000 (38%)]	Loss: 0.368943
Train Epoch: 2 [23680/60000 (39%)]	Loss: 0.525262
Train Epoch: 2 [24320/60000 (41%)]	Loss: 0.227805
Train Epoch: 2 [24960/60000 (42%)]	Loss: 0.278575
Train Epoch: 2 [25600/60000 (43%)]	Loss: 0.404145
Train Epoch: 2 [26240/60000 (44%)]	Loss: 0.467817
Train Epoch: 2 [26880/60000 (45%)]	Loss: 0.279880
Train Epoch: 2 [27520/60000 (46%)]	Loss: 0.539638
Train Epoch: 2 [28160/60000 (47%)]	Loss: 0.257472
Train Epoch: 2 [28800/60000 (48%)]	Loss: 0.220950
Train Epoch: 2 [29440/60000 (49%)]	Loss: 0.448459
Train Epoch: 2 [30080/60000 (50%)]	Loss: 0.280728
Train Epoch: 2 [30720/60000 (51%)]	Loss: 0.321694
Train Epoch: 2 [31360/60000 (52%)]	Loss: 0.234594
Train Epoch: 2 [32000/60000 (53%)]	Loss: 0.249877
Train Epoch: 2 [32640/60000 (54%)]	Loss: 0.443569
Train Epoch: 2 [33280/60000 (55%)]	Loss: 0.358985
Train Epoch: 2 [33920/60000 (57%)]	Loss: 0.350358
Train Epoch: 2 [34560/60000 (58%)]	Loss: 0.240932
Train Epoch: 2 [35200/60000 (59%)]	Loss: 0.400578
Train Epoch: 2 [35840/60000 (60%)]	Loss: 0.451478
Train Epoch: 2 [36480/60000 (61%)]	Loss: 0.366277
Train Epoch: 2 [37120/60000 (62%)]	Loss: 0.464619
Train Epoch: 2 [37760/60000 (63%)]	Loss: 0.219236
Train Epoch: 2 [38400/60000 (64%)]	Loss: 0.310383
Train Epoch: 2 [39040/60000 (65%)]	Loss: 0.318048
Train Epoch: 2 [39680/60000 (66%)]	Loss: 0.598020
Train Epoch: 2 [40320/60000 (67%)]	Loss: 0.248990
Train Epoch: 2 [40960/60000 (68%)]	Loss: 0.153452
Train Epoch: 2 [41600/60000 (69%)]	Loss: 0.155354
Train Epoch: 2 [42240/60000 (70%)]	Loss: 0.249885
Train Epoch: 2 [42880/60000 (71%)]	Loss: 0.198647
Train Epoch: 2 [43520/60000 (72%)]	Loss: 0.394697
Train Epoch: 2 [44160/60000 (74%)]	Loss: 0.450222
Train Epoch: 2 [44800/60000 (75%)]	Loss: 0.202541
Train Epoch: 2 [45440/60000 (76%)]	Loss: 0.268529
Train Epoch: 2 [46080/60000 (77%)]	Loss: 0.348173
Train Epoch: 2 [46720/60000 (78%)]	Loss: 0.359101
Train Epoch: 2 [47360/60000 (79%)]	Loss: 0.522160
Train Epoch: 2 [48000/60000 (80%)]	Loss: 0.488034
Train Epoch: 2 [48640/60000 (81%)]	Loss: 0.350620
Train Epoch: 2 [49280/60000 (82%)]	Loss: 0.523037
Train Epoch: 2 [49920/60000 (83%)]	Loss: 0.124925
Train Epoch: 2 [50560/60000 (84%)]	Loss: 0.299917
Train Epoch: 2 [51200/60000 (85%)]	Loss: 0.302186
Train Epoch: 2 [51840/60000 (86%)]	Loss: 0.323338
Train Epoch: 2 [52480/60000 (87%)]	Loss: 0.256383
Train Epoch: 2 [53120/60000 (88%)]	Loss: 0.313699
Train Epoch: 2 [53760/60000 (90%)]	Loss: 0.442143
Train Epoch: 2 [54400/60000 (91%)]	Loss: 0.234823
Train Epoch: 2 [55040/60000 (92%)]	Loss: 0.356765
Train Epoch: 2 [55680/60000 (93%)]	Loss: 0.425722
Train Epoch: 2 [56320/60000 (94%)]	Loss: 0.260159
Train Epoch: 2 [56960/60000 (95%)]	Loss: 0.307709
Train Epoch: 2 [57600/60000 (96%)]	Loss: 0.368729
Train Epoch: 2 [58240/60000 (97%)]	Loss: 0.554495
Train Epoch: 2 [58880/60000 (98%)]	Loss: 0.151344
Train Epoch: 2 [59520/60000 (99%)]	Loss: 0.332558

Test set: Avg. loss: 0.1095, Accuracy: 9664/10000 (97%)

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.606901
Train Epoch: 3 [640/60000 (1%)]	Loss: 0.217843
Train Epoch: 3 [1280/60000 (2%)]	Loss: 0.225650
Train Epoch: 3 [1920/60000 (3%)]	Loss: 0.359506
Train Epoch: 3 [2560/60000 (4%)]	Loss: 0.380754
Train Epoch: 3 [3200/60000 (5%)]	Loss: 0.283387
Train Epoch: 3 [3840/60000 (6%)]	Loss: 0.318688
Train Epoch: 3 [4480/60000 (7%)]	Loss: 0.335678
Train Epoch: 3 [5120/60000 (9%)]	Loss: 0.157370
Train Epoch: 3 [5760/60000 (10%)]	Loss: 0.220007
Train Epoch: 3 [6400/60000 (11%)]	Loss: 0.291860
Train Epoch: 3 [7040/60000 (12%)]	Loss: 0.464692
Train Epoch: 3 [7680/60000 (13%)]	Loss: 0.229839
Train Epoch: 3 [8320/60000 (14%)]	Loss: 0.342332
Train Epoch: 3 [8960/60000 (15%)]	Loss: 0.313431
Train Epoch: 3 [9600/60000 (16%)]	Loss: 0.341073
Train Epoch: 3 [10240/60000 (17%)]	Loss: 0.208354
Train Epoch: 3 [10880/60000 (18%)]	Loss: 0.188568
Train Epoch: 3 [11520/60000 (19%)]	Loss: 0.213437
Train Epoch: 3 [12160/60000 (20%)]	Loss: 0.327615
Train Epoch: 3 [12800/60000 (21%)]	Loss: 0.240687
Train Epoch: 3 [13440/60000 (22%)]	Loss: 0.347590
Train Epoch: 3 [14080/60000 (23%)]	Loss: 0.367349
Train Epoch: 3 [14720/60000 (25%)]	Loss: 0.270027
Train Epoch: 3 [15360/60000 (26%)]	Loss: 0.549701
Train Epoch: 3 [16000/60000 (27%)]	Loss: 0.265491
Train Epoch: 3 [16640/60000 (28%)]	Loss: 0.264681
Train Epoch: 3 [17280/60000 (29%)]	Loss: 0.259617
Train Epoch: 3 [17920/60000 (30%)]	Loss: 0.193016
Train Epoch: 3 [18560/60000 (31%)]	Loss: 0.405925
Train Epoch: 3 [19200/60000 (32%)]	Loss: 0.230640
Train Epoch: 3 [19840/60000 (33%)]	Loss: 0.298929
Train Epoch: 3 [20480/60000 (34%)]	Loss: 0.508493
Train Epoch: 3 [21120/60000 (35%)]	Loss: 0.253897
Train Epoch: 3 [21760/60000 (36%)]	Loss: 0.201565
Train Epoch: 3 [22400/60000 (37%)]	Loss: 0.276484
Train Epoch: 3 [23040/60000 (38%)]	Loss: 0.447977
Train Epoch: 3 [23680/60000 (39%)]	Loss: 0.542686
Train Epoch: 3 [24320/60000 (41%)]	Loss: 0.340117
Train Epoch: 3 [24960/60000 (42%)]	Loss: 0.238209
Train Epoch: 3 [25600/60000 (43%)]	Loss: 0.151151
Train Epoch: 3 [26240/60000 (44%)]	Loss: 0.365213
Train Epoch: 3 [26880/60000 (45%)]	Loss: 0.362948
Train Epoch: 3 [27520/60000 (46%)]	Loss: 0.237704
Train Epoch: 3 [28160/60000 (47%)]	Loss: 0.398583
Train Epoch: 3 [28800/60000 (48%)]	Loss: 0.397255
Train Epoch: 3 [29440/60000 (49%)]	Loss: 0.262200
Train Epoch: 3 [30080/60000 (50%)]	Loss: 0.152108
Train Epoch: 3 [30720/60000 (51%)]	Loss: 0.372339
Train Epoch: 3 [31360/60000 (52%)]	Loss: 0.372472
Train Epoch: 3 [32000/60000 (53%)]	Loss: 0.259656
Train Epoch: 3 [32640/60000 (54%)]	Loss: 0.435441
Train Epoch: 3 [33280/60000 (55%)]	Loss: 0.378388
Train Epoch: 3 [33920/60000 (57%)]	Loss: 0.177515
Train Epoch: 3 [34560/60000 (58%)]	Loss: 0.283689
Train Epoch: 3 [35200/60000 (59%)]	Loss: 0.131174
Train Epoch: 3 [35840/60000 (60%)]	Loss: 0.171783
Train Epoch: 3 [36480/60000 (61%)]	Loss: 0.104585
Train Epoch: 3 [37120/60000 (62%)]	Loss: 0.389055
Train Epoch: 3 [37760/60000 (63%)]	Loss: 0.360526
Train Epoch: 3 [38400/60000 (64%)]	Loss: 0.259271
Train Epoch: 3 [39040/60000 (65%)]	Loss: 0.525336
Train Epoch: 3 [39680/60000 (66%)]	Loss: 0.196208
Train Epoch: 3 [40320/60000 (67%)]	Loss: 0.374461
Train Epoch: 3 [40960/60000 (68%)]	Loss: 0.216166
Train Epoch: 3 [41600/60000 (69%)]	Loss: 0.221857
Train Epoch: 3 [42240/60000 (70%)]	Loss: 0.223318
Train Epoch: 3 [42880/60000 (71%)]	Loss: 0.185287
Train Epoch: 3 [43520/60000 (72%)]	Loss: 0.382659
Train Epoch: 3 [44160/60000 (74%)]	Loss: 0.262684
Train Epoch: 3 [44800/60000 (75%)]	Loss: 0.388742
Train Epoch: 3 [45440/60000 (76%)]	Loss: 0.286496
Train Epoch: 3 [46080/60000 (77%)]	Loss: 0.301708
Train Epoch: 3 [46720/60000 (78%)]	Loss: 0.451360
Train Epoch: 3 [47360/60000 (79%)]	Loss: 0.279125
Train Epoch: 3 [48000/60000 (80%)]	Loss: 0.197034
Train Epoch: 3 [48640/60000 (81%)]	Loss: 0.240700
Train Epoch: 3 [49280/60000 (82%)]	Loss: 0.594597
Train Epoch: 3 [49920/60000 (83%)]	Loss: 0.108885
Train Epoch: 3 [50560/60000 (84%)]	Loss: 0.199601
Train Epoch: 3 [51200/60000 (85%)]	Loss: 0.184297
Train Epoch: 3 [51840/60000 (86%)]	Loss: 0.175885
Train Epoch: 3 [52480/60000 (87%)]	Loss: 0.365624
Train Epoch: 3 [53120/60000 (88%)]	Loss: 0.236363
Train Epoch: 3 [53760/60000 (90%)]	Loss: 0.508030
Train Epoch: 3 [54400/60000 (91%)]	Loss: 0.379145
Train Epoch: 3 [55040/60000 (92%)]	Loss: 0.304528
Train Epoch: 3 [55680/60000 (93%)]	Loss: 0.184158
Train Epoch: 3 [56320/60000 (94%)]	Loss: 0.323510
Train Epoch: 3 [56960/60000 (95%)]	Loss: 0.192909
Train Epoch: 3 [57600/60000 (96%)]	Loss: 0.275473
Train Epoch: 3 [58240/60000 (97%)]	Loss: 0.397780
Train Epoch: 3 [58880/60000 (98%)]	Loss: 0.159153
Train Epoch: 3 [59520/60000 (99%)]	Loss: 0.231473

Test set: Avg. loss: 0.0909, Accuracy: 9709/10000 (97%)
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(train_counter, train_losses, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;blue&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(test_counter, test_losses, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;red&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.legend([&lt;span class=&#34;string&#34;&gt;&amp;#x27;Train Loss&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;Test Loss&amp;#x27;&lt;/span&gt;], loc=&lt;span class=&#34;string&#34;&gt;&amp;#x27;upper right&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;number of training examples seen&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.ylabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;negative log likelihood loss&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;DL_files/DL_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;continued_network = Net()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;continued_optimizer = optim.SGD(network.parameters(),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                lr=learning_rate,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                                momentum=momentum)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;network_state_dict = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/MNIST/model.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;continued_network.load_state_dict(network_state_dict)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;optimizer_state_dict = torch.load(&lt;span class=&#34;string&#34;&gt;&amp;#x27;./_data_set/MNIST/optimizer.pth&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;continued_optimizer.load_state_dict(optimizer_state_dict)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;9&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    train(i)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    test_counter.append(i * &lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(train_loader.dataset))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;C:\Users\Administrator\AppData\Local\Temp\ipykernel_18752\2337744027.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)


Train Epoch: 4 [0/60000 (0%)]	Loss: 0.180916
Train Epoch: 4 [640/60000 (1%)]	Loss: 0.188782
Train Epoch: 4 [1280/60000 (2%)]	Loss: 0.250786
Train Epoch: 4 [1920/60000 (3%)]	Loss: 0.185484
Train Epoch: 4 [2560/60000 (4%)]	Loss: 0.295455
Train Epoch: 4 [3200/60000 (5%)]	Loss: 0.172000
Train Epoch: 4 [3840/60000 (6%)]	Loss: 0.117650
Train Epoch: 4 [4480/60000 (7%)]	Loss: 0.423349
Train Epoch: 4 [5120/60000 (9%)]	Loss: 0.285250
Train Epoch: 4 [5760/60000 (10%)]	Loss: 0.360192
Train Epoch: 4 [6400/60000 (11%)]	Loss: 0.362748
Train Epoch: 4 [7040/60000 (12%)]	Loss: 0.292238
Train Epoch: 4 [7680/60000 (13%)]	Loss: 0.238687
Train Epoch: 4 [8320/60000 (14%)]	Loss: 0.150868
Train Epoch: 4 [8960/60000 (15%)]	Loss: 0.427452
Train Epoch: 4 [9600/60000 (16%)]	Loss: 0.230040
Train Epoch: 4 [10240/60000 (17%)]	Loss: 0.275437
Train Epoch: 4 [10880/60000 (18%)]	Loss: 0.158874
Train Epoch: 4 [11520/60000 (19%)]	Loss: 0.162058
Train Epoch: 4 [12160/60000 (20%)]	Loss: 0.177609
Train Epoch: 4 [12800/60000 (21%)]	Loss: 0.416331
Train Epoch: 4 [13440/60000 (22%)]	Loss: 0.255415
Train Epoch: 4 [14080/60000 (23%)]	Loss: 0.150464
Train Epoch: 4 [14720/60000 (25%)]	Loss: 0.285846
Train Epoch: 4 [15360/60000 (26%)]	Loss: 0.175966
Train Epoch: 4 [16000/60000 (27%)]	Loss: 0.385556
Train Epoch: 4 [16640/60000 (28%)]	Loss: 0.217486
Train Epoch: 4 [17280/60000 (29%)]	Loss: 0.243101
Train Epoch: 4 [17920/60000 (30%)]	Loss: 0.182876
Train Epoch: 4 [18560/60000 (31%)]	Loss: 0.094987
Train Epoch: 4 [19200/60000 (32%)]	Loss: 0.225338
Train Epoch: 4 [19840/60000 (33%)]	Loss: 0.145325
Train Epoch: 4 [20480/60000 (34%)]	Loss: 0.165757
Train Epoch: 4 [21120/60000 (35%)]	Loss: 0.218088
Train Epoch: 4 [21760/60000 (36%)]	Loss: 0.085633
Train Epoch: 4 [22400/60000 (37%)]	Loss: 0.122317
Train Epoch: 4 [23040/60000 (38%)]	Loss: 0.272857
Train Epoch: 4 [23680/60000 (39%)]	Loss: 0.155769
Train Epoch: 4 [24320/60000 (41%)]	Loss: 0.212894
Train Epoch: 4 [24960/60000 (42%)]	Loss: 0.117393
Train Epoch: 4 [25600/60000 (43%)]	Loss: 0.211204
Train Epoch: 4 [26240/60000 (44%)]	Loss: 0.071398
Train Epoch: 4 [26880/60000 (45%)]	Loss: 0.091613
Train Epoch: 4 [27520/60000 (46%)]	Loss: 0.267689
Train Epoch: 4 [28160/60000 (47%)]	Loss: 0.194783
Train Epoch: 4 [28800/60000 (48%)]	Loss: 0.207981
Train Epoch: 4 [29440/60000 (49%)]	Loss: 0.367123
Train Epoch: 4 [30080/60000 (50%)]	Loss: 0.179464
Train Epoch: 4 [30720/60000 (51%)]	Loss: 0.204890
Train Epoch: 4 [31360/60000 (52%)]	Loss: 0.219245
Train Epoch: 4 [32000/60000 (53%)]	Loss: 0.229217
Train Epoch: 4 [32640/60000 (54%)]	Loss: 0.139216
Train Epoch: 4 [33280/60000 (55%)]	Loss: 0.300938
Train Epoch: 4 [33920/60000 (57%)]	Loss: 0.133212
Train Epoch: 4 [34560/60000 (58%)]	Loss: 0.352936
Train Epoch: 4 [35200/60000 (59%)]	Loss: 0.153349
Train Epoch: 4 [35840/60000 (60%)]	Loss: 0.208317
Train Epoch: 4 [36480/60000 (61%)]	Loss: 0.164447
Train Epoch: 4 [37120/60000 (62%)]	Loss: 0.227367
Train Epoch: 4 [37760/60000 (63%)]	Loss: 0.241028
Train Epoch: 4 [38400/60000 (64%)]	Loss: 0.307894
Train Epoch: 4 [39040/60000 (65%)]	Loss: 0.461609
Train Epoch: 4 [39680/60000 (66%)]	Loss: 0.381326
Train Epoch: 4 [40320/60000 (67%)]	Loss: 0.135251
Train Epoch: 4 [40960/60000 (68%)]	Loss: 0.518683
Train Epoch: 4 [41600/60000 (69%)]	Loss: 0.210409
Train Epoch: 4 [42240/60000 (70%)]	Loss: 0.187576
Train Epoch: 4 [42880/60000 (71%)]	Loss: 0.115259
Train Epoch: 4 [43520/60000 (72%)]	Loss: 0.259883
Train Epoch: 4 [44160/60000 (74%)]	Loss: 0.177242
Train Epoch: 4 [44800/60000 (75%)]	Loss: 0.345635
Train Epoch: 4 [45440/60000 (76%)]	Loss: 0.213670
Train Epoch: 4 [46080/60000 (77%)]	Loss: 0.193606
Train Epoch: 4 [46720/60000 (78%)]	Loss: 0.173757
Train Epoch: 4 [47360/60000 (79%)]	Loss: 0.215879
Train Epoch: 4 [48000/60000 (80%)]	Loss: 0.171952
Train Epoch: 4 [48640/60000 (81%)]	Loss: 0.119270
Train Epoch: 4 [49280/60000 (82%)]	Loss: 0.324480
Train Epoch: 4 [49920/60000 (83%)]	Loss: 0.104771
Train Epoch: 4 [50560/60000 (84%)]	Loss: 0.163072
Train Epoch: 4 [51200/60000 (85%)]	Loss: 0.160245
Train Epoch: 4 [51840/60000 (86%)]	Loss: 0.249122
Train Epoch: 4 [52480/60000 (87%)]	Loss: 0.282949
Train Epoch: 4 [53120/60000 (88%)]	Loss: 0.152365
Train Epoch: 4 [53760/60000 (90%)]	Loss: 0.102036
Train Epoch: 4 [54400/60000 (91%)]	Loss: 0.162332
Train Epoch: 4 [55040/60000 (92%)]	Loss: 0.182912
Train Epoch: 4 [55680/60000 (93%)]	Loss: 0.468722
Train Epoch: 4 [56320/60000 (94%)]	Loss: 0.421446
Train Epoch: 4 [56960/60000 (95%)]	Loss: 0.254925
Train Epoch: 4 [57600/60000 (96%)]	Loss: 0.345340
Train Epoch: 4 [58240/60000 (97%)]	Loss: 0.293855
Train Epoch: 4 [58880/60000 (98%)]	Loss: 0.200609
Train Epoch: 4 [59520/60000 (99%)]	Loss: 0.045524

Test set: Avg. loss: 0.0696, Accuracy: 9772/10000 (98%)

Train Epoch: 5 [0/60000 (0%)]	Loss: 0.270343
Train Epoch: 5 [640/60000 (1%)]	Loss: 0.275511
Train Epoch: 5 [1280/60000 (2%)]	Loss: 0.209185
Train Epoch: 5 [1920/60000 (3%)]	Loss: 0.172124
Train Epoch: 5 [2560/60000 (4%)]	Loss: 0.176122
Train Epoch: 5 [3200/60000 (5%)]	Loss: 0.469673
Train Epoch: 5 [3840/60000 (6%)]	Loss: 0.113855
Train Epoch: 5 [4480/60000 (7%)]	Loss: 0.241289
Train Epoch: 5 [5120/60000 (9%)]	Loss: 0.123443
Train Epoch: 5 [5760/60000 (10%)]	Loss: 0.153661
Train Epoch: 5 [6400/60000 (11%)]	Loss: 0.069777
Train Epoch: 5 [7040/60000 (12%)]	Loss: 0.372212
Train Epoch: 5 [7680/60000 (13%)]	Loss: 0.158761
Train Epoch: 5 [8320/60000 (14%)]	Loss: 0.231457
Train Epoch: 5 [8960/60000 (15%)]	Loss: 0.235761
Train Epoch: 5 [9600/60000 (16%)]	Loss: 0.208866
Train Epoch: 5 [10240/60000 (17%)]	Loss: 0.511828
Train Epoch: 5 [10880/60000 (18%)]	Loss: 0.333603
Train Epoch: 5 [11520/60000 (19%)]	Loss: 0.254337
Train Epoch: 5 [12160/60000 (20%)]	Loss: 0.260536
Train Epoch: 5 [12800/60000 (21%)]	Loss: 0.263866
Train Epoch: 5 [13440/60000 (22%)]	Loss: 0.483610
Train Epoch: 5 [14080/60000 (23%)]	Loss: 0.178215
Train Epoch: 5 [14720/60000 (25%)]	Loss: 0.137731
Train Epoch: 5 [15360/60000 (26%)]	Loss: 0.177714
Train Epoch: 5 [16000/60000 (27%)]	Loss: 0.132543
Train Epoch: 5 [16640/60000 (28%)]	Loss: 0.146177
Train Epoch: 5 [17280/60000 (29%)]	Loss: 0.398970
Train Epoch: 5 [17920/60000 (30%)]	Loss: 0.120811
Train Epoch: 5 [18560/60000 (31%)]	Loss: 0.147756
Train Epoch: 5 [19200/60000 (32%)]	Loss: 0.317457
Train Epoch: 5 [19840/60000 (33%)]	Loss: 0.310727
Train Epoch: 5 [20480/60000 (34%)]	Loss: 0.144468
Train Epoch: 5 [21120/60000 (35%)]	Loss: 0.515887
Train Epoch: 5 [21760/60000 (36%)]	Loss: 0.113731
Train Epoch: 5 [22400/60000 (37%)]	Loss: 0.326223
Train Epoch: 5 [23040/60000 (38%)]	Loss: 0.275539
Train Epoch: 5 [23680/60000 (39%)]	Loss: 0.261113
Train Epoch: 5 [24320/60000 (41%)]	Loss: 0.198070
Train Epoch: 5 [24960/60000 (42%)]	Loss: 0.380463
Train Epoch: 5 [25600/60000 (43%)]	Loss: 0.130256
Train Epoch: 5 [26240/60000 (44%)]	Loss: 0.234225
Train Epoch: 5 [26880/60000 (45%)]	Loss: 0.284392
Train Epoch: 5 [27520/60000 (46%)]	Loss: 0.168175
Train Epoch: 5 [28160/60000 (47%)]	Loss: 0.346845
Train Epoch: 5 [28800/60000 (48%)]	Loss: 0.206521
Train Epoch: 5 [29440/60000 (49%)]	Loss: 0.149305
Train Epoch: 5 [30080/60000 (50%)]	Loss: 0.248684
Train Epoch: 5 [30720/60000 (51%)]	Loss: 0.245173
Train Epoch: 5 [31360/60000 (52%)]	Loss: 0.201854
Train Epoch: 5 [32000/60000 (53%)]	Loss: 0.182244
Train Epoch: 5 [32640/60000 (54%)]	Loss: 0.160925
Train Epoch: 5 [33280/60000 (55%)]	Loss: 0.251155
Train Epoch: 5 [33920/60000 (57%)]	Loss: 0.137573
Train Epoch: 5 [34560/60000 (58%)]	Loss: 0.305431
Train Epoch: 5 [35200/60000 (59%)]	Loss: 0.260936
Train Epoch: 5 [35840/60000 (60%)]	Loss: 0.298855
Train Epoch: 5 [36480/60000 (61%)]	Loss: 0.209435
Train Epoch: 5 [37120/60000 (62%)]	Loss: 0.152100
Train Epoch: 5 [37760/60000 (63%)]	Loss: 0.322987
Train Epoch: 5 [38400/60000 (64%)]	Loss: 0.245070
Train Epoch: 5 [39040/60000 (65%)]	Loss: 0.079185
Train Epoch: 5 [39680/60000 (66%)]	Loss: 0.286104
Train Epoch: 5 [40320/60000 (67%)]	Loss: 0.134519
Train Epoch: 5 [40960/60000 (68%)]	Loss: 0.256614
Train Epoch: 5 [41600/60000 (69%)]	Loss: 0.230492
Train Epoch: 5 [42240/60000 (70%)]	Loss: 0.081532
Train Epoch: 5 [42880/60000 (71%)]	Loss: 0.174270
Train Epoch: 5 [43520/60000 (72%)]	Loss: 0.123896
Train Epoch: 5 [44160/60000 (74%)]	Loss: 0.126517
Train Epoch: 5 [44800/60000 (75%)]	Loss: 0.333949
Train Epoch: 5 [45440/60000 (76%)]	Loss: 0.369903
Train Epoch: 5 [46080/60000 (77%)]	Loss: 0.207948
Train Epoch: 5 [46720/60000 (78%)]	Loss: 0.080965
Train Epoch: 5 [47360/60000 (79%)]	Loss: 0.117344
Train Epoch: 5 [48000/60000 (80%)]	Loss: 0.419863
Train Epoch: 5 [48640/60000 (81%)]	Loss: 0.265613
Train Epoch: 5 [49280/60000 (82%)]	Loss: 0.256468
Train Epoch: 5 [49920/60000 (83%)]	Loss: 0.509733
Train Epoch: 5 [50560/60000 (84%)]	Loss: 0.144000
Train Epoch: 5 [51200/60000 (85%)]	Loss: 0.174094
Train Epoch: 5 [51840/60000 (86%)]	Loss: 0.335760
Train Epoch: 5 [52480/60000 (87%)]	Loss: 0.363208
Train Epoch: 5 [53120/60000 (88%)]	Loss: 0.199396
Train Epoch: 5 [53760/60000 (90%)]	Loss: 0.276358
Train Epoch: 5 [54400/60000 (91%)]	Loss: 0.063482
Train Epoch: 5 [55040/60000 (92%)]	Loss: 0.107777
Train Epoch: 5 [55680/60000 (93%)]	Loss: 0.273694
Train Epoch: 5 [56320/60000 (94%)]	Loss: 0.111036
Train Epoch: 5 [56960/60000 (95%)]	Loss: 0.242194
Train Epoch: 5 [57600/60000 (96%)]	Loss: 0.192879
Train Epoch: 5 [58240/60000 (97%)]	Loss: 0.140068
Train Epoch: 5 [58880/60000 (98%)]	Loss: 0.053538
Train Epoch: 5 [59520/60000 (99%)]	Loss: 0.282342

Test set: Avg. loss: 0.0648, Accuracy: 9794/10000 (98%)

Train Epoch: 6 [0/60000 (0%)]	Loss: 0.157271
Train Epoch: 6 [640/60000 (1%)]	Loss: 0.125083
Train Epoch: 6 [1280/60000 (2%)]	Loss: 0.324760
Train Epoch: 6 [1920/60000 (3%)]	Loss: 0.233483
Train Epoch: 6 [2560/60000 (4%)]	Loss: 0.305379
Train Epoch: 6 [3200/60000 (5%)]	Loss: 0.133055
Train Epoch: 6 [3840/60000 (6%)]	Loss: 0.308374
Train Epoch: 6 [4480/60000 (7%)]	Loss: 0.361411
Train Epoch: 6 [5120/60000 (9%)]	Loss: 0.263687
Train Epoch: 6 [5760/60000 (10%)]	Loss: 0.136558
Train Epoch: 6 [6400/60000 (11%)]	Loss: 0.187681
Train Epoch: 6 [7040/60000 (12%)]	Loss: 0.249220
Train Epoch: 6 [7680/60000 (13%)]	Loss: 0.206636
Train Epoch: 6 [8320/60000 (14%)]	Loss: 0.151353
Train Epoch: 6 [8960/60000 (15%)]	Loss: 0.195330
Train Epoch: 6 [9600/60000 (16%)]	Loss: 0.361656
Train Epoch: 6 [10240/60000 (17%)]	Loss: 0.366321
Train Epoch: 6 [10880/60000 (18%)]	Loss: 0.166131
Train Epoch: 6 [11520/60000 (19%)]	Loss: 0.075402
Train Epoch: 6 [12160/60000 (20%)]	Loss: 0.151120
Train Epoch: 6 [12800/60000 (21%)]	Loss: 0.115874
Train Epoch: 6 [13440/60000 (22%)]	Loss: 0.144778
Train Epoch: 6 [14080/60000 (23%)]	Loss: 0.063986
Train Epoch: 6 [14720/60000 (25%)]	Loss: 0.174532
Train Epoch: 6 [15360/60000 (26%)]	Loss: 0.261803
Train Epoch: 6 [16000/60000 (27%)]	Loss: 0.251123
Train Epoch: 6 [16640/60000 (28%)]	Loss: 0.145080
Train Epoch: 6 [17280/60000 (29%)]	Loss: 0.354523
Train Epoch: 6 [17920/60000 (30%)]	Loss: 0.187603
Train Epoch: 6 [18560/60000 (31%)]	Loss: 0.082521
Train Epoch: 6 [19200/60000 (32%)]	Loss: 0.154904
Train Epoch: 6 [19840/60000 (33%)]	Loss: 0.165881
Train Epoch: 6 [20480/60000 (34%)]	Loss: 0.115822
Train Epoch: 6 [21120/60000 (35%)]	Loss: 0.603689
Train Epoch: 6 [21760/60000 (36%)]	Loss: 0.164415
Train Epoch: 6 [22400/60000 (37%)]	Loss: 0.107442
Train Epoch: 6 [23040/60000 (38%)]	Loss: 0.196783
Train Epoch: 6 [23680/60000 (39%)]	Loss: 0.220013
Train Epoch: 6 [24320/60000 (41%)]	Loss: 0.207349
Train Epoch: 6 [24960/60000 (42%)]	Loss: 0.178466
Train Epoch: 6 [25600/60000 (43%)]	Loss: 0.149325
Train Epoch: 6 [26240/60000 (44%)]	Loss: 0.169802
Train Epoch: 6 [26880/60000 (45%)]	Loss: 0.205438
Train Epoch: 6 [27520/60000 (46%)]	Loss: 0.121831
Train Epoch: 6 [28160/60000 (47%)]	Loss: 0.169774
Train Epoch: 6 [28800/60000 (48%)]	Loss: 0.138925
Train Epoch: 6 [29440/60000 (49%)]	Loss: 0.183873
Train Epoch: 6 [30080/60000 (50%)]	Loss: 0.108401
Train Epoch: 6 [30720/60000 (51%)]	Loss: 0.087508
Train Epoch: 6 [31360/60000 (52%)]	Loss: 0.114378
Train Epoch: 6 [32000/60000 (53%)]	Loss: 0.124145
Train Epoch: 6 [32640/60000 (54%)]	Loss: 0.368228
Train Epoch: 6 [33280/60000 (55%)]	Loss: 0.353432
Train Epoch: 6 [33920/60000 (57%)]	Loss: 0.239896
Train Epoch: 6 [34560/60000 (58%)]	Loss: 0.341117
Train Epoch: 6 [35200/60000 (59%)]	Loss: 0.280842
Train Epoch: 6 [35840/60000 (60%)]	Loss: 0.303140
Train Epoch: 6 [36480/60000 (61%)]	Loss: 0.340119
Train Epoch: 6 [37120/60000 (62%)]	Loss: 0.165236
Train Epoch: 6 [37760/60000 (63%)]	Loss: 0.113621
Train Epoch: 6 [38400/60000 (64%)]	Loss: 0.313772
Train Epoch: 6 [39040/60000 (65%)]	Loss: 0.258854
Train Epoch: 6 [39680/60000 (66%)]	Loss: 0.158878
Train Epoch: 6 [40320/60000 (67%)]	Loss: 0.160731
Train Epoch: 6 [40960/60000 (68%)]	Loss: 0.166837
Train Epoch: 6 [41600/60000 (69%)]	Loss: 0.226772
Train Epoch: 6 [42240/60000 (70%)]	Loss: 0.160613
Train Epoch: 6 [42880/60000 (71%)]	Loss: 0.157473
Train Epoch: 6 [43520/60000 (72%)]	Loss: 0.279009
Train Epoch: 6 [44160/60000 (74%)]	Loss: 0.157638
Train Epoch: 6 [44800/60000 (75%)]	Loss: 0.202747
Train Epoch: 6 [45440/60000 (76%)]	Loss: 0.123593
Train Epoch: 6 [46080/60000 (77%)]	Loss: 0.164986
Train Epoch: 6 [46720/60000 (78%)]	Loss: 0.285264
Train Epoch: 6 [47360/60000 (79%)]	Loss: 0.211086
Train Epoch: 6 [48000/60000 (80%)]	Loss: 0.125422
Train Epoch: 6 [48640/60000 (81%)]	Loss: 0.076380
Train Epoch: 6 [49280/60000 (82%)]	Loss: 0.274299
Train Epoch: 6 [49920/60000 (83%)]	Loss: 0.128968
Train Epoch: 6 [50560/60000 (84%)]	Loss: 0.100312
Train Epoch: 6 [51200/60000 (85%)]	Loss: 0.173260
Train Epoch: 6 [51840/60000 (86%)]	Loss: 0.375576
Train Epoch: 6 [52480/60000 (87%)]	Loss: 0.359121
Train Epoch: 6 [53120/60000 (88%)]	Loss: 0.137199
Train Epoch: 6 [53760/60000 (90%)]	Loss: 0.280192
Train Epoch: 6 [54400/60000 (91%)]	Loss: 0.345643
Train Epoch: 6 [55040/60000 (92%)]	Loss: 0.213638
Train Epoch: 6 [55680/60000 (93%)]	Loss: 0.142949
Train Epoch: 6 [56320/60000 (94%)]	Loss: 0.188716
Train Epoch: 6 [56960/60000 (95%)]	Loss: 0.067698
Train Epoch: 6 [57600/60000 (96%)]	Loss: 0.227284
Train Epoch: 6 [58240/60000 (97%)]	Loss: 0.141719
Train Epoch: 6 [58880/60000 (98%)]	Loss: 0.166098
Train Epoch: 6 [59520/60000 (99%)]	Loss: 0.251494

Test set: Avg. loss: 0.0615, Accuracy: 9814/10000 (98%)

Train Epoch: 7 [0/60000 (0%)]	Loss: 0.091176
Train Epoch: 7 [640/60000 (1%)]	Loss: 0.269873
Train Epoch: 7 [1280/60000 (2%)]	Loss: 0.132484
Train Epoch: 7 [1920/60000 (3%)]	Loss: 0.181744
Train Epoch: 7 [2560/60000 (4%)]	Loss: 0.119089
Train Epoch: 7 [3200/60000 (5%)]	Loss: 0.172001
Train Epoch: 7 [3840/60000 (6%)]	Loss: 0.288416
Train Epoch: 7 [4480/60000 (7%)]	Loss: 0.282734
Train Epoch: 7 [5120/60000 (9%)]	Loss: 0.274102
Train Epoch: 7 [5760/60000 (10%)]	Loss: 0.224655
Train Epoch: 7 [6400/60000 (11%)]	Loss: 0.227839
Train Epoch: 7 [7040/60000 (12%)]	Loss: 0.202125
Train Epoch: 7 [7680/60000 (13%)]	Loss: 0.176258
Train Epoch: 7 [8320/60000 (14%)]	Loss: 0.198535
Train Epoch: 7 [8960/60000 (15%)]	Loss: 0.119568
Train Epoch: 7 [9600/60000 (16%)]	Loss: 0.204526
Train Epoch: 7 [10240/60000 (17%)]	Loss: 0.259647
Train Epoch: 7 [10880/60000 (18%)]	Loss: 0.216371
Train Epoch: 7 [11520/60000 (19%)]	Loss: 0.098282
Train Epoch: 7 [12160/60000 (20%)]	Loss: 0.156163
Train Epoch: 7 [12800/60000 (21%)]	Loss: 0.194898
Train Epoch: 7 [13440/60000 (22%)]	Loss: 0.172166
Train Epoch: 7 [14080/60000 (23%)]	Loss: 0.231052
Train Epoch: 7 [14720/60000 (25%)]	Loss: 0.135253
Train Epoch: 7 [15360/60000 (26%)]	Loss: 0.144452
Train Epoch: 7 [16000/60000 (27%)]	Loss: 0.162540
Train Epoch: 7 [16640/60000 (28%)]	Loss: 0.136042
Train Epoch: 7 [17280/60000 (29%)]	Loss: 0.236265
Train Epoch: 7 [17920/60000 (30%)]	Loss: 0.208569
Train Epoch: 7 [18560/60000 (31%)]	Loss: 0.158493
Train Epoch: 7 [19200/60000 (32%)]	Loss: 0.161767
Train Epoch: 7 [19840/60000 (33%)]	Loss: 0.066611
Train Epoch: 7 [20480/60000 (34%)]	Loss: 0.322254
Train Epoch: 7 [21120/60000 (35%)]	Loss: 0.233296
Train Epoch: 7 [21760/60000 (36%)]	Loss: 0.086176
Train Epoch: 7 [22400/60000 (37%)]	Loss: 0.125919
Train Epoch: 7 [23040/60000 (38%)]	Loss: 0.148241
Train Epoch: 7 [23680/60000 (39%)]	Loss: 0.108953
Train Epoch: 7 [24320/60000 (41%)]	Loss: 0.223288
Train Epoch: 7 [24960/60000 (42%)]	Loss: 0.243924
Train Epoch: 7 [25600/60000 (43%)]	Loss: 0.224430
Train Epoch: 7 [26240/60000 (44%)]	Loss: 0.230509
Train Epoch: 7 [26880/60000 (45%)]	Loss: 0.326988
Train Epoch: 7 [27520/60000 (46%)]	Loss: 0.229315
Train Epoch: 7 [28160/60000 (47%)]	Loss: 0.315817
Train Epoch: 7 [28800/60000 (48%)]	Loss: 0.137005
Train Epoch: 7 [29440/60000 (49%)]	Loss: 0.116640
Train Epoch: 7 [30080/60000 (50%)]	Loss: 0.167090
Train Epoch: 7 [30720/60000 (51%)]	Loss: 0.173242
Train Epoch: 7 [31360/60000 (52%)]	Loss: 0.191092
Train Epoch: 7 [32000/60000 (53%)]	Loss: 0.134305
Train Epoch: 7 [32640/60000 (54%)]	Loss: 0.138862
Train Epoch: 7 [33280/60000 (55%)]	Loss: 0.125831
Train Epoch: 7 [33920/60000 (57%)]	Loss: 0.129372
Train Epoch: 7 [34560/60000 (58%)]	Loss: 0.120971
Train Epoch: 7 [35200/60000 (59%)]	Loss: 0.268926
Train Epoch: 7 [35840/60000 (60%)]	Loss: 0.170120
Train Epoch: 7 [36480/60000 (61%)]	Loss: 0.455412
Train Epoch: 7 [37120/60000 (62%)]	Loss: 0.182606
Train Epoch: 7 [37760/60000 (63%)]	Loss: 0.085986
Train Epoch: 7 [38400/60000 (64%)]	Loss: 0.229982
Train Epoch: 7 [39040/60000 (65%)]	Loss: 0.165970
Train Epoch: 7 [39680/60000 (66%)]	Loss: 0.125090
Train Epoch: 7 [40320/60000 (67%)]	Loss: 0.149905
Train Epoch: 7 [40960/60000 (68%)]	Loss: 0.382724
Train Epoch: 7 [41600/60000 (69%)]	Loss: 0.155642
Train Epoch: 7 [42240/60000 (70%)]	Loss: 0.059763
Train Epoch: 7 [42880/60000 (71%)]	Loss: 0.305220
Train Epoch: 7 [43520/60000 (72%)]	Loss: 0.209007
Train Epoch: 7 [44160/60000 (74%)]	Loss: 0.309034
Train Epoch: 7 [44800/60000 (75%)]	Loss: 0.049236
Train Epoch: 7 [45440/60000 (76%)]	Loss: 0.305584
Train Epoch: 7 [46080/60000 (77%)]	Loss: 0.187595
Train Epoch: 7 [46720/60000 (78%)]	Loss: 0.117563
Train Epoch: 7 [47360/60000 (79%)]	Loss: 0.147911
Train Epoch: 7 [48000/60000 (80%)]	Loss: 0.233994
Train Epoch: 7 [48640/60000 (81%)]	Loss: 0.198659
Train Epoch: 7 [49280/60000 (82%)]	Loss: 0.302784
Train Epoch: 7 [49920/60000 (83%)]	Loss: 0.204405
Train Epoch: 7 [50560/60000 (84%)]	Loss: 0.053611
Train Epoch: 7 [51200/60000 (85%)]	Loss: 0.635807
Train Epoch: 7 [51840/60000 (86%)]	Loss: 0.101712
Train Epoch: 7 [52480/60000 (87%)]	Loss: 0.097702
Train Epoch: 7 [53120/60000 (88%)]	Loss: 0.257620
Train Epoch: 7 [53760/60000 (90%)]	Loss: 0.121270
Train Epoch: 7 [54400/60000 (91%)]	Loss: 0.191442
Train Epoch: 7 [55040/60000 (92%)]	Loss: 0.127309
Train Epoch: 7 [55680/60000 (93%)]	Loss: 0.148693
Train Epoch: 7 [56320/60000 (94%)]	Loss: 0.073504
Train Epoch: 7 [56960/60000 (95%)]	Loss: 0.184949
Train Epoch: 7 [57600/60000 (96%)]	Loss: 0.072307
Train Epoch: 7 [58240/60000 (97%)]	Loss: 0.296258
Train Epoch: 7 [58880/60000 (98%)]	Loss: 0.415298
Train Epoch: 7 [59520/60000 (99%)]	Loss: 0.309931

Test set: Avg. loss: 0.0576, Accuracy: 9823/10000 (98%)

Train Epoch: 8 [0/60000 (0%)]	Loss: 0.411129
Train Epoch: 8 [640/60000 (1%)]	Loss: 0.082472
Train Epoch: 8 [1280/60000 (2%)]	Loss: 0.232263
Train Epoch: 8 [1920/60000 (3%)]	Loss: 0.184606
Train Epoch: 8 [2560/60000 (4%)]	Loss: 0.082728
Train Epoch: 8 [3200/60000 (5%)]	Loss: 0.173117
Train Epoch: 8 [3840/60000 (6%)]	Loss: 0.111649
Train Epoch: 8 [4480/60000 (7%)]	Loss: 0.442360
Train Epoch: 8 [5120/60000 (9%)]	Loss: 0.227383
Train Epoch: 8 [5760/60000 (10%)]	Loss: 0.288936
Train Epoch: 8 [6400/60000 (11%)]	Loss: 0.227669
Train Epoch: 8 [7040/60000 (12%)]	Loss: 0.238741
Train Epoch: 8 [7680/60000 (13%)]	Loss: 0.276109
Train Epoch: 8 [8320/60000 (14%)]	Loss: 0.173926
Train Epoch: 8 [8960/60000 (15%)]	Loss: 0.167442
Train Epoch: 8 [9600/60000 (16%)]	Loss: 0.178728
Train Epoch: 8 [10240/60000 (17%)]	Loss: 0.181267
Train Epoch: 8 [10880/60000 (18%)]	Loss: 0.213851
Train Epoch: 8 [11520/60000 (19%)]	Loss: 0.130871
Train Epoch: 8 [12160/60000 (20%)]	Loss: 0.074143
Train Epoch: 8 [12800/60000 (21%)]	Loss: 0.090848
Train Epoch: 8 [13440/60000 (22%)]	Loss: 0.262355
Train Epoch: 8 [14080/60000 (23%)]	Loss: 0.112236
Train Epoch: 8 [14720/60000 (25%)]	Loss: 0.237863
Train Epoch: 8 [15360/60000 (26%)]	Loss: 0.128822
Train Epoch: 8 [16000/60000 (27%)]	Loss: 0.325940
Train Epoch: 8 [16640/60000 (28%)]	Loss: 0.059681
Train Epoch: 8 [17280/60000 (29%)]	Loss: 0.297807
Train Epoch: 8 [17920/60000 (30%)]	Loss: 0.193296
Train Epoch: 8 [18560/60000 (31%)]	Loss: 0.101481
Train Epoch: 8 [19200/60000 (32%)]	Loss: 0.319415
Train Epoch: 8 [19840/60000 (33%)]	Loss: 0.221697
Train Epoch: 8 [20480/60000 (34%)]	Loss: 0.128780
Train Epoch: 8 [21120/60000 (35%)]	Loss: 0.365089
Train Epoch: 8 [21760/60000 (36%)]	Loss: 0.114066
Train Epoch: 8 [22400/60000 (37%)]	Loss: 0.178602
Train Epoch: 8 [23040/60000 (38%)]	Loss: 0.198497
Train Epoch: 8 [23680/60000 (39%)]	Loss: 0.113458
Train Epoch: 8 [24320/60000 (41%)]	Loss: 0.084631
Train Epoch: 8 [24960/60000 (42%)]	Loss: 0.220370
Train Epoch: 8 [25600/60000 (43%)]	Loss: 0.112375
Train Epoch: 8 [26240/60000 (44%)]	Loss: 0.180620
Train Epoch: 8 [26880/60000 (45%)]	Loss: 0.174218
Train Epoch: 8 [27520/60000 (46%)]	Loss: 0.220530
Train Epoch: 8 [28160/60000 (47%)]	Loss: 0.322495
Train Epoch: 8 [28800/60000 (48%)]	Loss: 0.108935
Train Epoch: 8 [29440/60000 (49%)]	Loss: 0.302106
Train Epoch: 8 [30080/60000 (50%)]	Loss: 0.143926
Train Epoch: 8 [30720/60000 (51%)]	Loss: 0.132183
Train Epoch: 8 [31360/60000 (52%)]	Loss: 0.295584
Train Epoch: 8 [32000/60000 (53%)]	Loss: 0.153446
Train Epoch: 8 [32640/60000 (54%)]	Loss: 0.356207
Train Epoch: 8 [33280/60000 (55%)]	Loss: 0.049660
Train Epoch: 8 [33920/60000 (57%)]	Loss: 0.134523
Train Epoch: 8 [34560/60000 (58%)]	Loss: 0.107794
Train Epoch: 8 [35200/60000 (59%)]	Loss: 0.152601
Train Epoch: 8 [35840/60000 (60%)]	Loss: 0.183556
Train Epoch: 8 [36480/60000 (61%)]	Loss: 0.139419
Train Epoch: 8 [37120/60000 (62%)]	Loss: 0.217243
Train Epoch: 8 [37760/60000 (63%)]	Loss: 0.067120
Train Epoch: 8 [38400/60000 (64%)]	Loss: 0.140370
Train Epoch: 8 [39040/60000 (65%)]	Loss: 0.118206
Train Epoch: 8 [39680/60000 (66%)]	Loss: 0.068067
Train Epoch: 8 [40320/60000 (67%)]	Loss: 0.390102
Train Epoch: 8 [40960/60000 (68%)]	Loss: 0.362602
Train Epoch: 8 [41600/60000 (69%)]	Loss: 0.151053
Train Epoch: 8 [42240/60000 (70%)]	Loss: 0.329660
Train Epoch: 8 [42880/60000 (71%)]	Loss: 0.030132
Train Epoch: 8 [43520/60000 (72%)]	Loss: 0.214005
Train Epoch: 8 [44160/60000 (74%)]	Loss: 0.177053
Train Epoch: 8 [44800/60000 (75%)]	Loss: 0.270380
Train Epoch: 8 [45440/60000 (76%)]	Loss: 0.160427
Train Epoch: 8 [46080/60000 (77%)]	Loss: 0.152326
Train Epoch: 8 [46720/60000 (78%)]	Loss: 0.173051
Train Epoch: 8 [47360/60000 (79%)]	Loss: 0.213168
Train Epoch: 8 [48000/60000 (80%)]	Loss: 0.148429
Train Epoch: 8 [48640/60000 (81%)]	Loss: 0.179701
Train Epoch: 8 [49280/60000 (82%)]	Loss: 0.115524
Train Epoch: 8 [49920/60000 (83%)]	Loss: 0.203157
Train Epoch: 8 [50560/60000 (84%)]	Loss: 0.092355
Train Epoch: 8 [51200/60000 (85%)]	Loss: 0.241119
Train Epoch: 8 [51840/60000 (86%)]	Loss: 0.214614
Train Epoch: 8 [52480/60000 (87%)]	Loss: 0.133498
Train Epoch: 8 [53120/60000 (88%)]	Loss: 0.139286
Train Epoch: 8 [53760/60000 (90%)]	Loss: 0.271059
Train Epoch: 8 [54400/60000 (91%)]	Loss: 0.126945
Train Epoch: 8 [55040/60000 (92%)]	Loss: 0.098850
Train Epoch: 8 [55680/60000 (93%)]	Loss: 0.224279
Train Epoch: 8 [56320/60000 (94%)]	Loss: 0.166734
Train Epoch: 8 [56960/60000 (95%)]	Loss: 0.143847
Train Epoch: 8 [57600/60000 (96%)]	Loss: 0.146182
Train Epoch: 8 [58240/60000 (97%)]	Loss: 0.226856
Train Epoch: 8 [58880/60000 (98%)]	Loss: 0.049229
Train Epoch: 8 [59520/60000 (99%)]	Loss: 0.534476

Test set: Avg. loss: 0.0554, Accuracy: 9817/10000 (98%)

Train Epoch: 9 [0/60000 (0%)]	Loss: 0.054686
Train Epoch: 9 [640/60000 (1%)]	Loss: 0.235064
Train Epoch: 9 [1280/60000 (2%)]	Loss: 0.106654
Train Epoch: 9 [1920/60000 (3%)]	Loss: 0.234180
Train Epoch: 9 [2560/60000 (4%)]	Loss: 0.198757
Train Epoch: 9 [3200/60000 (5%)]	Loss: 0.162267
Train Epoch: 9 [3840/60000 (6%)]	Loss: 0.271285
Train Epoch: 9 [4480/60000 (7%)]	Loss: 0.080265
Train Epoch: 9 [5120/60000 (9%)]	Loss: 0.122332
Train Epoch: 9 [5760/60000 (10%)]	Loss: 0.217631
Train Epoch: 9 [6400/60000 (11%)]	Loss: 0.185639
Train Epoch: 9 [7040/60000 (12%)]	Loss: 0.168876
Train Epoch: 9 [7680/60000 (13%)]	Loss: 0.112571
Train Epoch: 9 [8320/60000 (14%)]	Loss: 0.125877
Train Epoch: 9 [8960/60000 (15%)]	Loss: 0.188810
Train Epoch: 9 [9600/60000 (16%)]	Loss: 0.105145
Train Epoch: 9 [10240/60000 (17%)]	Loss: 0.188370
Train Epoch: 9 [10880/60000 (18%)]	Loss: 0.117349
Train Epoch: 9 [11520/60000 (19%)]	Loss: 0.069228
Train Epoch: 9 [12160/60000 (20%)]	Loss: 0.162447
Train Epoch: 9 [12800/60000 (21%)]	Loss: 0.108819
Train Epoch: 9 [13440/60000 (22%)]	Loss: 0.263229
Train Epoch: 9 [14080/60000 (23%)]	Loss: 0.292624
Train Epoch: 9 [14720/60000 (25%)]	Loss: 0.248468
Train Epoch: 9 [15360/60000 (26%)]	Loss: 0.119649
Train Epoch: 9 [16000/60000 (27%)]	Loss: 0.109907
Train Epoch: 9 [16640/60000 (28%)]	Loss: 0.580101
Train Epoch: 9 [17280/60000 (29%)]	Loss: 0.177047
Train Epoch: 9 [17920/60000 (30%)]	Loss: 0.178420
Train Epoch: 9 [18560/60000 (31%)]	Loss: 0.221444
Train Epoch: 9 [19200/60000 (32%)]	Loss: 0.133854
Train Epoch: 9 [19840/60000 (33%)]	Loss: 0.282360
Train Epoch: 9 [20480/60000 (34%)]	Loss: 0.136910
Train Epoch: 9 [21120/60000 (35%)]	Loss: 0.280332
Train Epoch: 9 [21760/60000 (36%)]	Loss: 0.174279
Train Epoch: 9 [22400/60000 (37%)]	Loss: 0.083278
Train Epoch: 9 [23040/60000 (38%)]	Loss: 0.188579
Train Epoch: 9 [23680/60000 (39%)]	Loss: 0.102640
Train Epoch: 9 [24320/60000 (41%)]	Loss: 0.163085
Train Epoch: 9 [24960/60000 (42%)]	Loss: 0.158967
Train Epoch: 9 [25600/60000 (43%)]	Loss: 0.192901
Train Epoch: 9 [26240/60000 (44%)]	Loss: 0.163242
Train Epoch: 9 [26880/60000 (45%)]	Loss: 0.157237
Train Epoch: 9 [27520/60000 (46%)]	Loss: 0.088420
Train Epoch: 9 [28160/60000 (47%)]	Loss: 0.094397
Train Epoch: 9 [28800/60000 (48%)]	Loss: 0.156636
Train Epoch: 9 [29440/60000 (49%)]	Loss: 0.150083
Train Epoch: 9 [30080/60000 (50%)]	Loss: 0.077640
Train Epoch: 9 [30720/60000 (51%)]	Loss: 0.172498
Train Epoch: 9 [31360/60000 (52%)]	Loss: 0.228058
Train Epoch: 9 [32000/60000 (53%)]	Loss: 0.162368
Train Epoch: 9 [32640/60000 (54%)]	Loss: 0.278008
Train Epoch: 9 [33280/60000 (55%)]	Loss: 0.256715
Train Epoch: 9 [33920/60000 (57%)]	Loss: 0.196984
Train Epoch: 9 [34560/60000 (58%)]	Loss: 0.205926
Train Epoch: 9 [35200/60000 (59%)]	Loss: 0.103880
Train Epoch: 9 [35840/60000 (60%)]	Loss: 0.053308
Train Epoch: 9 [36480/60000 (61%)]	Loss: 0.117932
Train Epoch: 9 [37120/60000 (62%)]	Loss: 0.080018
Train Epoch: 9 [37760/60000 (63%)]	Loss: 0.423203
Train Epoch: 9 [38400/60000 (64%)]	Loss: 0.088841
Train Epoch: 9 [39040/60000 (65%)]	Loss: 0.157737
Train Epoch: 9 [39680/60000 (66%)]	Loss: 0.196193
Train Epoch: 9 [40320/60000 (67%)]	Loss: 0.164245
Train Epoch: 9 [40960/60000 (68%)]	Loss: 0.199979
Train Epoch: 9 [41600/60000 (69%)]	Loss: 0.188702
Train Epoch: 9 [42240/60000 (70%)]	Loss: 0.199731
Train Epoch: 9 [42880/60000 (71%)]	Loss: 0.102235
Train Epoch: 9 [43520/60000 (72%)]	Loss: 0.087075
Train Epoch: 9 [44160/60000 (74%)]	Loss: 0.128069
Train Epoch: 9 [44800/60000 (75%)]	Loss: 0.148430
Train Epoch: 9 [45440/60000 (76%)]	Loss: 0.232641
Train Epoch: 9 [46080/60000 (77%)]	Loss: 0.082571
Train Epoch: 9 [46720/60000 (78%)]	Loss: 0.283418
Train Epoch: 9 [47360/60000 (79%)]	Loss: 0.233733
Train Epoch: 9 [48000/60000 (80%)]	Loss: 0.096537
Train Epoch: 9 [48640/60000 (81%)]	Loss: 0.109687
Train Epoch: 9 [49280/60000 (82%)]	Loss: 0.216523
Train Epoch: 9 [49920/60000 (83%)]	Loss: 0.181914
Train Epoch: 9 [50560/60000 (84%)]	Loss: 0.139312
Train Epoch: 9 [51200/60000 (85%)]	Loss: 0.238586
Train Epoch: 9 [51840/60000 (86%)]	Loss: 0.109351
Train Epoch: 9 [52480/60000 (87%)]	Loss: 0.076942
Train Epoch: 9 [53120/60000 (88%)]	Loss: 0.221999
Train Epoch: 9 [53760/60000 (90%)]	Loss: 0.178757
Train Epoch: 9 [54400/60000 (91%)]	Loss: 0.219890
Train Epoch: 9 [55040/60000 (92%)]	Loss: 0.136030
Train Epoch: 9 [55680/60000 (93%)]	Loss: 0.238617
Train Epoch: 9 [56320/60000 (94%)]	Loss: 0.195722
Train Epoch: 9 [56960/60000 (95%)]	Loss: 0.252661
Train Epoch: 9 [57600/60000 (96%)]	Loss: 0.149977
Train Epoch: 9 [58240/60000 (97%)]	Loss: 0.061803
Train Epoch: 9 [58880/60000 (98%)]	Loss: 0.105117
Train Epoch: 9 [59520/60000 (99%)]	Loss: 0.054359

Test set: Avg. loss: 0.0508, Accuracy: 9843/10000 (98%)
&lt;/code&gt;&lt;/pre&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;plt.figure(figsize=(&lt;span class=&#34;number&#34;&gt;15&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;12&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(train_counter, train_losses, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;blue&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(test_counter, test_losses, color=&lt;span class=&#34;string&#34;&gt;&amp;#x27;red&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.legend([&lt;span class=&#34;string&#34;&gt;&amp;#x27;Train Loss&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;Test Loss&amp;#x27;&lt;/span&gt;], loc=&lt;span class=&#34;string&#34;&gt;&amp;#x27;upper right&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;number of training examples seen&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.ylabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;negative log likelihood loss&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;DL_files/DL_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;借物表&#34;&gt;借物表&lt;/h2&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-1&#39; href=&#39;#cite_ref-1&#39;&gt;[1]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/137571225&#34;&gt;用 PyTorch 实现 MNIST 手写数字识别(非常详细)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-2&#39; href=&#39;#cite_ref-2&#39;&gt;[2]&lt;/a&gt;: &lt;a href=&#34;https://www.bilibili.com/video/BV1cL411V7Gh?p=6&#34;&gt;PyTorch 深度学习入门与实战 2022 最简明易懂的 PyTorch 代码精讲 最新版本 PyTorch PyTorch 安装&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-3&#39; href=&#39;#cite_ref-3&#39;&gt;[3]&lt;/a&gt;: &lt;a href=&#34;https://www.jianshu.com/p/45a26d278473&#34;&gt;PyTorch 中的 nn.Conv1d 与 nn.Conv2d&lt;/a&gt;&lt;/p&gt;
&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kity@2.0.4/dist/kity.min.js&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js&#34;&gt;&lt;/script&gt;&lt;script defer=&#34;true&#34; type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js&#34;&gt;&lt;/script&gt;&lt;link rel=&#34;stylesheet&#34; type=&#34;text&amp;#x2F;css&#34; href=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css&#34;&gt;</content>
        <category term="人工智能" />
        <category term="深度学习" />
        <category term="python" />
        <updated>2022-04-20T16:26:11.000Z</updated>
    </entry>
    <entry>
        <id>https://weidows.github.io/post/lang/python/AI/DL/</id>
        <title>⚡再啃-Deep-Learning</title>
        <link rel="alternate" href="https://weidows.github.io/post/lang/python/AI/DL/"/>
        <content type="html">&lt;!--
 * @?: *********************************************************************
 * @Author: Weidows
 * @LastEditors: Weidows
 * @LastEditTime: 2023-04-20 18:31:10
 * @FilePath: \Blog-private\source\_posts\python\AI\DL.md
 * @Description:
 * @!: *********************************************************************
--&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-lg&#34;&gt;&lt;ul&gt;
&lt;li&gt;再啃-Deep-Learning
&lt;ul&gt;
&lt;li&gt;深度学习
&lt;ul&gt;
&lt;li&gt;一个好的表示学习策略必须具备一定的深度&lt;/li&gt;
&lt;li&gt;特征
&lt;ul&gt;
&lt;li&gt;像是宰鱼要分多步,每步使用不同方式/工具&lt;/li&gt;
&lt;li&gt;通常从底层特征开始经过多步非线性转换才能得到好的高层语义表示&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特点
&lt;ul&gt;
&lt;li&gt;增加特征重用性,指数级增加表示能力&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pan.weidows.tech/d/local/blog/RCdJ0c.png&#34;&gt;表示学习与深度学习关系&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;关键问题: 贡献度分配
&lt;ul&gt;
&lt;li&gt;不同组件/参数对系统输出结果的影响权重&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;神经网路
&lt;ul&gt;
&lt;li&gt;人工神经网络
&lt;ul&gt;
&lt;li&gt;由大量神经元及它们之间的有向连接构成&lt;/li&gt;
&lt;li&gt;三方面
&lt;ul&gt;
&lt;li&gt;神经元/感知器&lt;/li&gt;
&lt;li&gt;网络的拓扑结构
&lt;ul&gt;
&lt;li&gt;LeNet&lt;/li&gt;
&lt;li&gt;AlexNet&lt;/li&gt;
&lt;li&gt;VGGNet&lt;/li&gt;
&lt;li&gt;ResNet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;学习算法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pan.weidows.tech/d/local/blog/Rat37q.png&#34;&gt;分类&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;单类网络
&lt;ul&gt;
&lt;li&gt;前馈网络&lt;/li&gt;
&lt;li&gt;记忆网络&lt;/li&gt;
&lt;li&gt;图网络&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;复合型网络&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;贡献度分配问题
&lt;ul&gt;
&lt;li&gt;不同 component 或 param 对最终系统输出结果的贡献&lt;/li&gt;
&lt;li&gt;利用偏导数求解贡献度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;发展史
&lt;ul&gt;
&lt;li&gt;模型提出&lt;/li&gt;
&lt;li&gt;冰河期&lt;/li&gt;
&lt;li&gt;反向传播算法引起的复兴&lt;/li&gt;
&lt;li&gt;流行度降低&lt;/li&gt;
&lt;li&gt;深度学习崛起&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MMDetection
&lt;ul&gt;
&lt;li&gt;图像分类
&lt;ul&gt;
&lt;li&gt;模型发展
&lt;ul&gt;
&lt;li&gt;LeNet-5 (1998)&lt;/li&gt;
&lt;li&gt;AlexNet (2012)&lt;/li&gt;
&lt;li&gt;VGGNet (2014)&lt;/li&gt;
&lt;li&gt;GoogleNet (2014)&lt;/li&gt;
&lt;li&gt;ResNet (2015)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;模型训练
&lt;ul&gt;
&lt;li&gt;配置文件
&lt;ul&gt;
&lt;li&gt;模型结构
&lt;ul&gt;
&lt;li&gt;模型有几层&lt;/li&gt;
&lt;li&gt;每层多少通道数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据集
&lt;ul&gt;
&lt;li&gt;数据集划分
&lt;ul&gt;
&lt;li&gt;常用的有 COCO 格式, &lt;code&gt;annotation/test.json -&amp;gt; test/images&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据文件路径&lt;/li&gt;
&lt;li&gt;数据增强策略&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;训练策略
&lt;ul&gt;
&lt;li&gt;梯度下降算法&lt;/li&gt;
&lt;li&gt;学习率参数&lt;/li&gt;
&lt;li&gt;batch_size&lt;/li&gt;
&lt;li&gt;训练总轮次&lt;/li&gt;
&lt;li&gt;学习率变化策略&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;runtime / 运行时
&lt;ul&gt;
&lt;li&gt;GPU&lt;/li&gt;
&lt;li&gt;分布式环境配置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一些辅助功能
&lt;ul&gt;
&lt;li&gt;打印日志&lt;/li&gt;
&lt;li&gt;checkpoint / 定时保存&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MMDetection3D&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;由于 DL 是 ML 的子问题, 所以此篇着重写 &lt;a href=&#34;../ML&#34;&gt;🥵 硬啃-Machine-Learning&lt;/a&gt; 里面涉及甚少的 (解耦) &lt;br&gt;
有一些 (比如损失函数, 梯度下降) 隶属于 ML &amp;gt; DL ,所以堆在了 ML 里面&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;本篇所用到的代码在这: &lt;br&gt;
&lt;a href=&#34;../../code/DL&#34;&gt;👩‍❤️‍💋‍👨Code-4-Deep-Learning&lt;/a&gt; &lt;br&gt;
&lt;a href=&#34;../../code/MM-Detection&#34;&gt;🐳MM-Detection-Colab&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ML-2-DL&#34;&gt;ML-2-DL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;简单解释 DL 到底在做什么?&lt;/p&gt;
&lt;p&gt;传统 ML 就像是在教小学生如何通过一系列&lt;code&gt;固定公式&lt;/code&gt;搞出来一个结果,在公式不太复杂/运算量不太大时, 教起来还好&lt;/p&gt;
&lt;p&gt;那怎么教一个小学生高数题呢? 也是可以让他死记硬背公式的,但是效果并不好&lt;/p&gt;
&lt;p&gt;DL 就像是在教他转换思想 (函数,导数,积分…), 遇到题目后,具体套什么公式, 由小学生自己找到&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DL 不像 ML 一样泛泛, 对每种任务有针对性的设计&lt;/p&gt;
&lt;hr&gt;
&lt;div class=&#34;tabs&#34; id=&#34;优点&#34;&gt;&lt;ul class=&#34;nav-tabs&#34;&gt;&lt;li class=&#34;tab active&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#优点-1&#34;&gt;优点&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#优点-2&#34;&gt;缺点&lt;/button&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&#34;tab-contents&#34;&gt;&lt;div class=&#34;tab-item-content active&#34; id=&#34;优点-1&#34;&gt;&lt;p&gt;就像上面提到的, 传统 ML 需要人教给机器特征工程 (固定公式), 模型越复杂, 人的提取方法和特征结果会越差&lt;/p&gt;
&lt;p&gt;DL 对特征的处理方法/结果要优于人类 (比如深层次人类无法察觉的特征关系)&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;优点-2&#34;&gt;&lt;p&gt;DL 模型的能力是 (人类传授的基本功 + 题海战术) 得来的;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;刷题少时反不如套公式&lt;/li&gt;
&lt;li&gt;基本功构建成本高&lt;/li&gt;
&lt;li&gt;可解释性差 (虽然基本功是你教的,但你不知道机器是用的什么歪门邪道的心法)&lt;/li&gt;
&lt;/ol&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;神经网路&#34;&gt;神经网路&lt;/h2&gt;
&lt;p&gt;大多知名的模型都是属于 &lt;code&gt;深度神经网络&lt;/code&gt; 的, 比如 CNN, RNN, GAN …&lt;/p&gt;
&lt;h3 id=&#34;神经元-感知器&#34;&gt;神经元-感知器&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;感知器就是一个神经元, 神经网络的组成单元, 可自学习为回归/分类器&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RC0tEP.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;y = f(w1 \cdot x1 + w2 \cdot x2 + b)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.1944em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02691em;&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;⋅&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.7278em;vertical-align:-0.0833em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.6444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02691em;&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;⋅&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.7278em;vertical-align:-0.0833em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当调整 &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;w,b&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8889em;vertical-align:-0.1944em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02691em;&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 时,可以得到不同的变体逻辑运算(比如与或非);&lt;/p&gt;
&lt;p&gt;给定训练数据集, &lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;w,b&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8889em;vertical-align:-0.1944em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02691em;&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; 可以通过学习自动调整&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;学习规则核心思想: &lt;code&gt;错误驱动&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;权值初始化&lt;/li&gt;
&lt;li&gt;输入样本对&lt;/li&gt;
&lt;li&gt;计算输出&lt;/li&gt;
&lt;li&gt;根据感知器学习规则调整权值&lt;/li&gt;
&lt;li&gt;返回到步骤 2. 输入下一对样本,周而复始直到对所有样本,感知器的实际输出与期望输出相等&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;details&gt;
  &lt;summary&gt; 例题 &lt;/summary&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Raxa9S.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化向量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;⇒&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;W(0) = (0.5,1,-1,0)^T \rArr W^T(0) = (0.5,1,-1,0)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1413em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;⇒&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1413em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;输入样本&lt;/li&gt;
&lt;li&gt;计算输出&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;⋅&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2.5&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;W^T(0)X^1 = (0.5,1,-1,0) \cdot (-1,1,-2,0)^T = 2.5
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1413em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;⋅&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1413em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.6444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2.5&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;调整权值,这里使用上面&lt;a href=&#34;#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&#34;&gt;#激活函数&lt;/a&gt;的阶跃函数例子&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;权向量第一个分量也就是 0.5 为阈值&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mtable rowspacing=&#34;0.25em&#34; columnalign=&#34;right left&#34; columnspacing=&#34;0em&#34;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;2.5&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;[&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo fence=&#34;true&#34;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.8&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.6&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;[&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo fence=&#34;true&#34;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0.8&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;0.6&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;[&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;]&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.8&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.6&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;η&lt;/mi&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;[&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo fence=&#34;true&#34;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;msup&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mn&gt;0.7&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0.8&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;0.6&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;0.1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;[&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;]&lt;/mo&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;0.5&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;true&#34;&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;(&lt;/mo&gt;&lt;mrow&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.5&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.6&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.4&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn mathvariant=&#34;bold&#34;&gt;0.1&lt;/mn&gt;&lt;msup&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&#34;bold&#34;&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;\begin{aligned}
  o^1(0) &amp;amp;= sgn(W^T(0)X^1) \\
  &amp;amp;= sgn(2.5) = 1

    \\ \ \\

    W(1) &amp;amp;=W(0) + \eta \left[d^{1}-o^{1}(0)\right] X^{1} \\
  &amp;amp;= (0.5,1,-1,0)^{T} + 0.1 (- 1- 1)(-1,1,-2,0)^{T} \\
  &amp;amp;= \left(\mathbf{0.7,0.8,-0.6,0)^{T}}\right.

    \\ \ \\

    W(2) &amp;amp;=W(1) + \eta \left[d^{2}-o^{2}(1)\right] X^{2} \\
  &amp;amp;= (0.7,0.8,-0.6,0)^{T} + 0.1 [- 1-(- 1)](-1,0,1.5,-0.5)^{T} \\
  &amp;amp;= \left(\mathbf{0.7,0.8,-0.6,0)^{T}}\right.

    \\ \ \\

    W(3) &amp;amp;=W(2) + \eta \left[d^{3}-o^{3}(2)\right] X^{3} \\
  &amp;amp;= (0.7,0.8,-0.6,0)^{T} + 0.1 [1-(- 1)](-1,-1,1,0.5)^{T} \\
  &amp;amp;= \left(\mathbf{0.5,0.6,-0.4,0.1)^{T}}\right.
\end{aligned}
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:21.4375em;vertical-align:-10.4687em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mtable&#34;&gt;&lt;span class=&#34;col-align-r&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:10.9687em;&#34;&gt;&lt;span style=&#34;top:-13.0774em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-11.5774em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-10.0774em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-8.5533em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-7.002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-5.4487em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.9487em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.4246em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-0.8733em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:0.68em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:2.18em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:3.7041em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:5.2555em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:6.8087em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:10.4687em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;col-align-l&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:10.9687em;&#34;&gt;&lt;span style=&#34;top:-13.0774em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-11.5774em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2.5&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-8.5533em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;η&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-7.002em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-5.4487em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8933em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathbf mtight&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.4246em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;η&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-0.8733em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)]&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:0.68em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8933em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathbf mtight&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:3.7041em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.13889em;&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;η&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;[&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.07847em;&#34;&gt;X&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8641em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:5.2555em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.7&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.8&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)]&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:6.8087em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;&lt;span class=&#34;delimsizing size1&#34;&gt;(&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.6&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.4&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathbf&#34;&gt;0.1&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8933em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathbf mtight&#34;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:10.4687em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;返回 2. 直到&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/msup&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;mspace width=&#34;2em&#34;/&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo separator=&#34;true&#34;&gt;,&lt;/mo&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;d^{P} - o^{P} = 0 \qquad (p = 1,2,3)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.9747em;vertical-align:-0.0833em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;d&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8913em;&#34;&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:2em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;mpunct&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;前馈神经网络&#34;&gt;前馈神经网络&lt;/h3&gt;
&lt;p&gt;把若干个感知器叠几层, 形成单向类网状结构, 称为多层前馈神经网络 (Multi-layer Feedforward Neural Networks), &lt;code&gt;前馈&lt;/code&gt; 是指前一层输出作为后一层输入&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/R0fC7h.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个箭头直线代表一个 “向量”:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;b&lt;/mi&gt;&lt;/mrow&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msubsup&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;w ^{k}  _{a \ b}
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1.1461em;vertical-align:-0.247em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.02691em;&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.8991em;&#34;&gt;&lt;span style=&#34;top:-2.453em;margin-left:-0.0269em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;mspace mtight&#34;&gt;&lt;span class=&#34;mtight&#34;&gt; &lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal mtight&#34;&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.113em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord mathnormal mtight&#34; style=&#34;margin-right:0.03148em;&#34;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.247em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;k: 权重&lt;/p&gt;
&lt;p&gt;a: 前一层第 a 个神经元&lt;/p&gt;
&lt;p&gt;b: 后一层第 b 个神经元&lt;/p&gt;
&lt;hr&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同一层感知器之间不相连, 与前后两层全相连, 为&lt;code&gt;全连接神经网络&lt;/code&gt; (fully-connected neural network)&lt;/p&gt;
&lt;p&gt;这种网络有硬性缺点:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;丢失数据的空间信息 (比如 3d 图像会展开为向量)&lt;/li&gt;
&lt;li&gt;参数量太多,难训&lt;/li&gt;
&lt;li&gt;层级浅, 大量参数易过拟合&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后面 CNN 对此缺点做了优化&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;反向传播&#34;&gt;反向传播&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;反向传播/误差反向传播 (Backpropagation algorithm), 根据输出层输出值来反向调整隐藏层权重的一种方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我们常用 &lt;code&gt;梯度下降方法&lt;/code&gt; 来更新权重, 梯度下降应用于有明确求导/可求出误差的情况&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但是对于含有多个隐藏层的神经网络, 隐藏层求不出误差, 只有输出层有&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;反向传播就是一个把输出层误差反向传播到隐藏层的过程&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图解 &lt;sup id=&#39;cite_ref-2&#39;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RNeqlm.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RNexIh.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;实现原理就是求偏导&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RNeWuu.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;卷积神经网络-CNN&#34;&gt;卷积神经网络-CNN&lt;/h3&gt;
&lt;p&gt;卷积神经网络(Convolutional Neural Network, CNN), 视觉领域难以撼动的老大&lt;/p&gt;
&lt;h4 id=&#34;what&#34;&gt;what&lt;/h4&gt;
&lt;p&gt;对于一个 .mp3 的音乐 (频域记录, .wav 是时域记录), 某一时间点的音波可以&lt;code&gt;假定认为&lt;/code&gt;是多个函数交杂而成的&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;mtext&gt;耳机音效&lt;/mtext&gt;&lt;/msub&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;[&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mtext&gt;人声&lt;/mtext&gt;&lt;/msub&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mtext&gt;乐器&lt;/mtext&gt;&lt;/msub&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo fence=&#34;true&#34;&gt;]&lt;/mo&gt;&lt;/mrow&gt;&lt;mo&gt;∗&lt;/mo&gt;&lt;msub&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mtext&gt;响度&lt;/mtext&gt;&lt;/msub&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;y = h_{耳机音效} \left[ f_{人声}(t) * g_{乐器}(t) \right] * i_{响度}(t)
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.625em;vertical-align:-0.1944em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3283em;&#34;&gt;&lt;span style=&#34;top:-2.55em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord cjk_fallback mtight&#34;&gt;耳机音效&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.1667em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen delimcenter&#34; style=&#34;top:0em;&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3283em;&#34;&gt;&lt;span style=&#34;top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord cjk_fallback mtight&#34;&gt;人声&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;∗&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3283em;&#34;&gt;&lt;span style=&#34;top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord cjk_fallback mtight&#34;&gt;乐器&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mclose delimcenter&#34; style=&#34;top:0em;&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mbin&#34;&gt;∗&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2222em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;msupsub&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.3283em;&#34;&gt;&lt;span style=&#34;top:-2.55em;margin-left:0em;margin-right:0.05em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:2.7em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;sizing reset-size6 size3 mtight&#34;&gt;&lt;span class=&#34;mord mtight&#34;&gt;&lt;span class=&#34;mord cjk_fallback mtight&#34;&gt;响度&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:0.15em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;某一时间点的音波,就是这一堆函数的&lt;code&gt;卷积&lt;/code&gt;, 简单来说就是在某个维度上 &lt;code&gt;加权 + 叠加&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;结构&#34;&gt;结构&lt;/h4&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RytYZQ.png&#34; alt=&#34;&#34;&gt;&lt;div class=&#34;mermaid-wrap&#34;&gt;&lt;pre class=&#34;mermaid-src&#34; hidden&gt;
  graph TB
  输入层 --&amp;gt;
  卷积层(卷积层 Convolutional-layer) --&amp;gt;
  激活层(激活&amp;#x2F;ReLU层 Activation-layer) --&amp;gt;
  池化层(池化&amp;#x2F;子采样&amp;#x2F;下采样层 Pooling-layer) --&amp;gt;
  全连接网络(全连接网络 fully-connected-layer) --&amp;gt;
  输出层
  &lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;卷积层: 就像是多个科目 (卷积核) 的老师给出试卷, 让&amp;quot;输入&amp;quot;做答&lt;/li&gt;
&lt;li&gt;激活层: 不同科目老师判卷,得出有没有及格,及格的话计多少分&lt;/li&gt;
&lt;li&gt;池化层: 成绩取最大值或者平均值, 减少计算量&lt;/li&gt;
&lt;li&gt;全连接层: 年级排名&lt;/li&gt;
&lt;li&gt;输出层: 是否获奖(二分类) / 排名前百分之几十(多分类)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h4 id=&#34;卷积层&#34;&gt;卷积层&lt;/h4&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RNJpTz.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Ry4FoP.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以直观看出, 其作用为 &lt;code&gt;降维&lt;/code&gt; 和 &lt;code&gt;提取特征&lt;/code&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;激活层&#34;&gt;激活层&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;将输入信号的总和转换为输出信号的函数被称为激活函数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如下为一种简单实现: 阶跃函数:&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RaxGG1.png&#34; alt=&#34;RaxGG1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;其阈值是可以改变的:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;katex-display&#34;&gt;&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math xmlns=&#34;http://www.w3.org/1998/Math/MathML&#34; display=&#34;block&#34;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&#34;false&#34;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mrow&gt;&lt;mo fence=&#34;true&#34;&gt;{&lt;/mo&gt;&lt;mtable rowspacing=&#34;0.36em&#34; columnalign=&#34;left left&#34; columnspacing=&#34;1em&#34;&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mstyle scriptlevel=&#34;0&#34; displaystyle=&#34;false&#34;&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mtext&gt; &lt;/mtext&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;&amp;lt;&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mstyle&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;sgn(x) =
\begin{cases}
  1 &amp;amp; if \ x &amp;gt; 0 \\
  0 &amp;amp; if \ x = 0 \\
  -1 &amp;amp; if \ x &amp;lt; 0
\end{cases}
&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:1em;vertical-align:-0.25em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.03588em;&#34;&gt;g&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;mopen&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mclose&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:4.32em;vertical-align:-1.91em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;minner&#34;&gt;&lt;span class=&#34;mopen&#34;&gt;&lt;span class=&#34;delimsizing mult&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.35em;&#34;&gt;&lt;span style=&#34;top:-2.2em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size4&#34;&gt;&lt;span&gt;⎩&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.192em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.15em;&#34;&gt;&lt;/span&gt;&lt;span style=&#34;height:0.316em;width:0.8889em;&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;0.8889em&#34; height=&#34;0.316em&#34; style=&#34;width:0.8889em&#34; viewBox=&#34;0 0 888.89 316&#34; preserveAspectRatio=&#34;xMinYMin&#34;&gt;&lt;path d=&#34;M384 0 H504 V316 H384z M384 0 H504 V316 H384z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-3.15em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size4&#34;&gt;&lt;span&gt;⎨&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-4.292em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.15em;&#34;&gt;&lt;/span&gt;&lt;span style=&#34;height:0.316em;width:0.8889em;&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; width=&#34;0.8889em&#34; height=&#34;0.316em&#34; style=&#34;width:0.8889em&#34; viewBox=&#34;0 0 888.89 316&#34; preserveAspectRatio=&#34;xMinYMin&#34;&gt;&lt;path d=&#34;M384 0 H504 V316 H384z M384 0 H504 V316 H384z&#34;/&gt;&lt;/svg&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-4.6em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.15em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;delimsizinginner delim-size4&#34;&gt;&lt;span&gt;⎧&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.85em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mtable&#34;&gt;&lt;span class=&#34;col-align-l&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.41em;&#34;&gt;&lt;span style=&#34;top:-4.41em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.97em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.53em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord&#34;&gt;−&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.91em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;arraycolsep&#34; style=&#34;width:1em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;col-align-l&#34;&gt;&lt;span class=&#34;vlist-t vlist-t2&#34;&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:2.41em;&#34;&gt;&lt;span style=&#34;top:-4.41em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-2.97em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;top:-1.53em;&#34;&gt;&lt;span class=&#34;pstrut&#34; style=&#34;height:3.008em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34; style=&#34;margin-right:0.10764em;&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;mspace&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mord mathnormal&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mrel&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mspace&#34; style=&#34;margin-right:0.2778em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-s&#34;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;vlist-r&#34;&gt;&lt;span class=&#34;vlist&#34; style=&#34;height:1.91em;&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;mclose nulldelimiter&#34;&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有很多其他的激活函数, 用途各异, 详见&lt;sup id=&#39;cite_ref-1&#39;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;sigmoid 函数&lt;/p&gt;
&lt;p&gt;tanh 双曲正切函数&lt;/p&gt;
&lt;p&gt;ReLU (Rectified Linear Units, 修正线性单元, CNN 常用)&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;池化层&#34;&gt;池化层&lt;/h4&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Ry4PS6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Ry4apn.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;一方面, 缩小分辨率降低运算量, 一方面扩大神经元的&lt;code&gt;感受野&lt;/code&gt; (特征捕获范围)&lt;/p&gt;
&lt;p&gt;也就使得层次越深, 单位神经元在有损条件下捕获特征/语义信息的范围越大&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;上采样-反卷积-上池化&#34;&gt;上采样-反卷积-上池化&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;上采样指的是：任何可以让图像变成更高分辨率的技术（上池化、反卷积、插值等）&lt;sup id=&#39;cite_ref-9&#39;&gt;&lt;a href=&#34;#cite_note-9&#34;&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;多种模型特点&#34;&gt;多种模型特点&lt;/h2&gt;
&lt;h3 id=&#34;MLP&#34;&gt;MLP&lt;/h3&gt;
&lt;p&gt;Multi-Layer Perceptron 多层感知机&lt;/p&gt;
&lt;p&gt;上天下地都行, 但需要人扶着&lt;/p&gt;
&lt;h3 id=&#34;CNN&#34;&gt;CNN&lt;/h3&gt;
&lt;p&gt;深层次特征挖掘, 尤其适用于图像&lt;/p&gt;
&lt;h3 id=&#34;Transformer-ViT&#34;&gt;Transformer-ViT&lt;/h3&gt;
&lt;p&gt;适用于多场景, 打榜强手&lt;/p&gt;
&lt;p&gt;&lt;code&gt;混联电池组结构&lt;/code&gt; + &lt;code&gt;自注意力机制&lt;/code&gt; = transformer&lt;/p&gt;
&lt;p&gt;由于 self- attention, 可训练出可解释性的模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;self-attention 公式图解, 推荐视频: &lt;sup id=&#39;cite_ref-10&#39;&gt;&lt;a href=&#34;#cite_note-10&#34;&gt;[10]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZNGs8o.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZNG4ZD.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;GAN&#34;&gt;GAN&lt;/h3&gt;
&lt;p&gt;出了名的难训, 需要大量上好的数据&lt;/p&gt;
&lt;h3 id=&#34;RNN&#34;&gt;RNN&lt;/h3&gt;
&lt;p&gt;Recurrent Neural Networkx 循环神经网络&lt;/p&gt;
&lt;h3 id=&#34;VAE&#34;&gt;VAE&lt;/h3&gt;
&lt;p&gt;Variational Auto-Encoder 变分自编码器&lt;/p&gt;
&lt;p&gt;自编码器 Auto-Encoder&lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z0ZSYT.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
隐藏层就类似有损压缩算法, 也可以认为就是, 视频中介绍到 Google 就拿来压缩图片&lt;br&gt;
encoder 是拆分信息的, decoder 是重组信息的&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;MMDetection&#34;&gt;MMDetection&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;参考课程 &lt;sup id=&#39;cite_ref-3&#39;&gt;&lt;a href=&#34;#cite_note-3&#34;&gt;[3]&lt;/a&gt;&lt;/sup&gt; &lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/R7twWM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;图像分类&#34;&gt;图像分类&lt;/h3&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Ry4Xmz.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;目标检测&#34;&gt;目标检测&lt;/h3&gt;
&lt;h4 id=&#34;第一阶段-问题与方案&#34;&gt;第一阶段-问题与方案&lt;/h4&gt;
&lt;h5 id=&#34;图像分割&#34;&gt;图像分割&lt;/h5&gt;
&lt;p&gt;等大窗口 -&amp;gt; 滑动窗口 -&amp;gt; 多尺度滑窗 -&amp;gt; 图像金字塔&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZBmvYY.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZCV790.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;区域提议&#34;&gt;区域提议&lt;/h5&gt;
&lt;p&gt;但上面设计需要做的分类数太多,难以满足实时性, 可以先用 &lt;code&gt;区域提议 Region Proposal&lt;/code&gt; 提取出可能包含物体的区域&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZCYq6P.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;非极大值抑制&#34;&gt;非极大值抑制&lt;/h5&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZCYER6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;第二阶段-优化算法&#34;&gt;第二阶段-优化算法&lt;/h4&gt;
&lt;h5 id=&#34;共享特征与-RoI-Pooling&#34;&gt;共享特征与-RoI-Pooling&lt;/h5&gt;
&lt;p&gt;对于每个提议框 -&amp;gt; CNN 前传, 有大量重叠提议框(重复的卷积运算), 所以改进为: &lt;code&gt;全图单次 CNN 前传 -&amp;gt; 全图特征图 -&amp;gt; 根据提议框裁剪预测&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1PBTb.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;RPN-区域提议网络&#34;&gt;RPN-区域提议网络&lt;/h5&gt;
&lt;p&gt;Region Proposal Network&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1PLwn.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;FPN-特征金字塔网络&#34;&gt;FPN-特征金字塔网络&lt;/h5&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1a3Gh.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&#34;Faster-RCNN&#34;&gt;Faster-RCNN&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Faster - Region proposal - CNN&lt;/code&gt; 一个很经典的例子, 应用上面的优化算法网络 &lt;sup id=&#39;cite_ref-5&#39;&gt;&lt;a href=&#34;#cite_note-5&#34;&gt;[5]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1Pnqz.png&#34; alt=&#34;&#34;&gt; &lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1aeNq.png&#34; alt=&#34;&#34;&gt; &lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZLwNpK.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h4 id=&#34;目标检测划分&#34;&gt;目标检测划分&lt;/h4&gt;
&lt;p&gt;可以通过下面三种形式划分 &lt;sup id=&#39;cite_ref-6&#39;&gt;&lt;a href=&#34;#cite_note-6&#34;&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-md&#34;&gt;&lt;ul&gt;
&lt;li&gt;目标检测划分
&lt;ul&gt;
&lt;li&gt;stage
&lt;ul&gt;
&lt;li&gt;one-stage (单阶段)
&lt;ul&gt;
&lt;li&gt;RetinaNet&lt;/li&gt;
&lt;li&gt;YOLO&lt;/li&gt;
&lt;li&gt;FCOS&lt;/li&gt;
&lt;li&gt;RepPoints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;two-stage (双阶段)
&lt;ul&gt;
&lt;li&gt;FasterRCNN&lt;/li&gt;
&lt;li&gt;CascadeRCNN&lt;/li&gt;
&lt;li&gt;LibraRCNN&lt;/li&gt;
&lt;li&gt;TridentNet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;anchor (锚框)
&lt;ul&gt;
&lt;li&gt;anchor-based
&lt;ul&gt;
&lt;li&gt;FasterRCNN&lt;/li&gt;
&lt;li&gt;YOLO&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;anchor-free
&lt;ul&gt;
&lt;li&gt;FCOS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;transformer
&lt;ul&gt;
&lt;li&gt;DETR&lt;/li&gt;
&lt;li&gt;Deformable DETR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;tabs&#34; id=&#34;双阶段&#34;&gt;&lt;ul class=&#34;nav-tabs&#34;&gt;&lt;li class=&#34;tab active&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#双阶段-1&#34;&gt;单阶段&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#双阶段-2&#34;&gt;双阶段&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#双阶段-3&#34;&gt;无锚框算法&lt;/button&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&#34;tab-contents&#34;&gt;&lt;div class=&#34;tab-item-content active&#34; id=&#34;双阶段-1&#34;&gt;&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZeIeWv.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;单阶段最常用的就是 YOLO (You Only Look Once), 每代都会有设计更新和优化,如下为 v3 设计&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZeImDX.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;双阶段-2&#34;&gt;&lt;p&gt;上面介绍的都是双阶段算法,与单阶段区别主要在于&lt;code&gt;是否有区域提议阶段&lt;/code&gt;, 单阶段算法只通过不同尺寸的锚框(检测头)进行物体预测&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Z1aqjr.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体来看,与上面网络结合:&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZeDKUA.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;双阶段-3&#34;&gt;&lt;p&gt;另一类分支, 有锚框的话会有大量超参使模型复杂度上升, 无锚框的话性能又会下降&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;模型构建流程&#34;&gt;模型构建流程&lt;/h3&gt;
&lt;p&gt;现阶段 AI 领域把很多算法模块化了, 提出的新算法大多也是对某一功能模块的改进, 构建一个大型模型可以像是装高达一样挑选合适的算法/网络模块进行组合.&lt;/p&gt;
&lt;p&gt;mmdet 就是蛮复杂的, 抽象成了多个功能模块 &lt;sup id=&#39;cite_ref-6&#39;&gt;&lt;a href=&#34;#cite_note-6&#34;&gt;[6]&lt;/a&gt;&lt;/sup&gt;, 每个功能模块又有多个实现算法.&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZLwyeM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZL05TP.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;tabs&#34; id=&#34;backbone&#34;&gt;&lt;ul class=&#34;nav-tabs&#34;&gt;&lt;li class=&#34;tab active&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-1&#34;&gt;backbone&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-2&#34;&gt;neck&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-3&#34;&gt;enhance&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-4&#34;&gt;head&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-5&#34;&gt;BBox&lt;/button&gt;&lt;/li&gt;&lt;li class=&#34;tab&#34;&gt;&lt;button type=&#34;button&#34; data-href=&#34;#backbone-6&#34;&gt;tricks&lt;/button&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&#34;tab-contents&#34;&gt;&lt;div class=&#34;tab-item-content active&#34; id=&#34;backbone-1&#34;&gt;&lt;p&gt;backbone (主干网络) 经常会在预训练模型选取时看到, 作用为&lt;code&gt;特征提取&lt;/code&gt;, 常见的比如 50 层 ResNet -&amp;gt; R-50&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;backbone-2&#34;&gt;&lt;p&gt;neck 是对 backbone 提取的特征进行融合/增强, 然后传给 head. 常见的 neck 为 FPN (特征金字塔网络)&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;backbone-3&#34;&gt;&lt;blockquote&gt;
&lt;p&gt;enhance 是即插即用、能够对特征进行增强的模块&lt;/p&gt;
&lt;/blockquote&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;backbone-4&#34;&gt;&lt;p&gt;Head 检测头模块是对模型性能影响最显著的地方, 有框坐标回归和目标分类两个分支&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;backbone-5&#34;&gt;&lt;p&gt;Bonding Box 是检测头模块的一个分支, 它的作用是对检测结果进行回归, 得到框坐标&lt;br&gt;
功能模块有 BBox 分配 (进行正负样本定义或者正负样本分配),采样,编解码,后处理, 以及对应的 loss&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;div class=&#34;tab-item-content&#34; id=&#34;backbone-6&#34;&gt;&lt;p&gt;tricks 就是训练/测试的技巧/配置, 大部分的调参工作就是在调整这部分, 比如 batch, Lr, 数据增强等…&lt;/p&gt;&lt;button type=&#34;button&#34; class=&#34;tab-to-top&#34; aria-label=&#34;scroll to top&#34;&gt;&lt;i class=&#34;fas fa-arrow-up&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;模型训练&#34;&gt;模型训练&lt;/h3&gt;
&lt;p&gt;MMDetection 基本结构: &lt;code&gt;依赖 + [模型] + 数据集 + 配置文件 -&amp;gt; Trainable&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&#34;dataset-COCO&#34;&gt;dataset-COCO&lt;/h4&gt;
&lt;p&gt;数据集分很多格式, 常见的比如 COCO:&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;dataset_type = &lt;span class=&#34;string&#34;&gt;&amp;#x27;CocoDataset&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_root = &lt;span class=&#34;string&#34;&gt;&amp;#x27;data/coco/&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = &lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  samples_per_gpu=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  workers_per_gpu=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  train=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=dataset_type,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ann_file=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;annotations/instances_train2017.json&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img_prefix=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;train2017/&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pipeline=train_pipeline),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  val=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=dataset_type,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ann_file=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;annotations/instances_val2017.json&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img_prefix=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;val2017/&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pipeline=test_pipeline),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  test=&lt;span class=&#34;built_in&#34;&gt;dict&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;type&lt;/span&gt;=dataset_type,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    ann_file=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;annotations/instances_val2017.json&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    img_prefix=data_root + &lt;span class=&#34;string&#34;&gt;&amp;#x27;val2017/&amp;#x27;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    pipeline=test_pipeline)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&#34;pipeline&#34;&gt;pipeline&lt;/h4&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Zezw9E.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;Lr-Scheduler&#34;&gt;Lr-Scheduler&lt;/h4&gt;
&lt;p&gt;Learning Rate Scheduler 学习率策略, 常见模型中标注的 &lt;code&gt;1x 2x&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Ze7rmt.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;性能衡量&#34;&gt;性能衡量&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;目标检测中衡量识别精度的指标是 mAP（mean average precision）。多个类别物体检测中，每一个类别都可以根据 recall(查全率) 和 precision(查准率) 绘制一条曲线(P-R 曲线)，AP 就是该曲线下的面积，mAP 是多个类别 AP 的平均值 &lt;sup id=&#39;cite_ref-8&#39;&gt;&lt;a href=&#34;#cite_note-8&#34;&gt;[8]&lt;/a&gt;&lt;/sup&gt; &lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZnHZTz.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;MMDetection3D&#34;&gt;MMDetection3D&lt;/h2&gt;
&lt;p&gt;入门一个技术, 需要大致概览一下, 正巧 MM-Lab 应时发布了教程 &lt;sup id=&#39;cite_ref-4&#39;&gt;&lt;a href=&#34;#cite_note-4&#34;&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;MMDetection3D 依赖于 MMDetection 和 MMSegmentation, 适用于检测和分割 3D 场景下的物体&lt;/p&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/ZLvvN9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;坐标系&#34;&gt;坐标系&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;深度坐标系 Depth 主要被用于通过深度相机采集的数据集, 大多是室内场景点云检测.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;激光雷达坐标系 LiDAR, 适用于室外场景点云检测&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相机坐标系 Camera, 该坐标系在室内室外场景的点云检测均有使用, 代表彩色相机的常用坐标系, 一般用于数据格式的转换. 在多模态或者单目 3D 的检测器中, 相机坐标系是三维点云与二维图像之间的桥梁. &lt;sup id=&#39;cite_ref-7&#39;&gt;&lt;a href=&#34;#cite_note-7&#34;&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三种坐标系构造不同, 但基准点都是物体底部中心点, 不同坐标系可以转换&lt;/p&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;借物表&#34;&gt;借物表&lt;/h2&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-1&#39; href=&#39;#cite_ref-1&#39;&gt;[1]&lt;/a&gt;: &lt;a href=&#34;https://mp.weixin.qq.com/s/Um8wAtdxPcVN8ACiVtSgFg&#34;&gt;42 个激活函数的全面总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-2&#39; href=&#39;#cite_ref-2&#39;&gt;[2]&lt;/a&gt;: &lt;a href=&#34;https://discover304.top/2021/11/30/2021q4/107-1-dl-back/&#34;&gt;【深度学习】基础 叁：反向传播算法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-3&#39; href=&#39;#cite_ref-3&#39;&gt;[3]&lt;/a&gt;: &lt;a href=&#34;https://www.bilibili.com/video/BV1ou411k7fD&#34;&gt;4 小时入门深度学习+实操 MMDetection 第一课&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-4&#39; href=&#39;#cite_ref-4&#39;&gt;[4]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/478307528&#34;&gt;带你玩转 3D 检测和分割 一：MMDetection3D 整体框架介绍&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-5&#39; href=&#39;#cite_ref-5&#39;&gt;[5]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/31426458&#34;&gt;一文读懂 Faster RCNN&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-6&#39; href=&#39;#cite_ref-6&#39;&gt;[6]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/337375549&#34;&gt;轻松掌握 MMDetection 整体构建流程(一)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-7&#39; href=&#39;#cite_ref-7&#39;&gt;[7]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/491614921&#34;&gt;带你玩转 3D 检测和分割 （二）：核心组件分析之坐标系和 Box&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-8&#39; href=&#39;#cite_ref-8&#39;&gt;[8]&lt;/a&gt;: &lt;a href=&#34;https://www.zhihu.com/question/53405779&#34;&gt;目标检测中的 mAP 是什么含义？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-9&#39; href=&#39;#cite_ref-9&#39;&gt;[9]&lt;/a&gt;: &lt;a href=&#34;https://blog.csdn.net/Turbo_Come/article/details/104602765/?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1--blog-125624971.pc_relevant_default&amp;amp;spm=1001.2101.3001.4242.2&amp;amp;utm_relevant_index=4&#34;&gt;上采用、反卷积、上池化区别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-10&#39; href=&#39;#cite_ref-10&#39;&gt;[10]&lt;/a&gt;: &lt;a href=&#34;https://www.bilibili.com/video/BV1BW4y1U7gm&#34;&gt;【论文必读之 Transformer】被捧上天的玩意儿，就这？！&lt;/a&gt;&lt;/p&gt;
&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kity@2.0.4/dist/kity.min.js&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js&#34;&gt;&lt;/script&gt;&lt;script defer=&#34;true&#34; type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js&#34;&gt;&lt;/script&gt;&lt;link rel=&#34;stylesheet&#34; type=&#34;text&amp;#x2F;css&#34; href=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css&#34;&gt;</content>
        <category term="doing" />
        <category term="人工智能" />
        <category term="深度学习" />
        <category term="MMDetection" />
        <updated>2022-04-20T16:07:12.000Z</updated>
    </entry>
    <entry>
        <id>https://weidows.github.io/post/lang/python/AI/AI/</id>
        <title>🐊All-about-AI</title>
        <link rel="alternate" href="https://weidows.github.io/post/lang/python/AI/AI/"/>
        <content type="html">&lt;!--
 * @?: *********************************************************************
 * @Author: Weidows
 * @LastEditors: Weidows
 * @LastEditTime: 2023-04-20 18:30:24
 * @FilePath: \Blog-private\source\_posts\python\AI\AI.md
 * @Description:
 * @!: *********************************************************************
--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;details&gt;
  &lt;summary&gt; 文章封面图 (恐怖慎看) &lt;/summary&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RaxZ0b.png&#34; alt=&#34;RaxZ0b.png&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;/details&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此篇为本博客中 AI 领域的根, 也可以当做目录 (因为篇幅太长,就给分开了)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;文中大量使用 LaTeX 公式, 如何写的可以看 &lt;a href=&#34;../../../../experience/LaTeX&#34;&gt;🍹LaTeX~环形使者(?)&lt;/a&gt; &lt;br&gt;
强推大佬朋友的文章: &lt;a href=&#34;https://discover304.top/2021/12/21/2021q4/123-ai-question-collection/&#34;&gt;【人工智能】面试问题整理&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;嗟叹&lt;/p&gt;
&lt;p&gt;炼丹界门派好多啊, 一派一传承&lt;/p&gt;
&lt;p&gt;师出少林, 修行武当, 行至小河, 探头一照&lt;/p&gt;
&lt;p&gt;欸, 爷竟是峨眉的 🐵&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;体系概览&#34;&gt;体系概览&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;人工智能是什么? &lt;sup id=&#39;cite_ref-1&#39;&gt;&lt;a href=&#34;#cite_note-1&#34;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#39;cite_ref-2&#39;&gt;&lt;a href=&#34;#cite_note-2&#34;&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/GVidNr.png&#34; alt=&#34;&#34;&gt;&lt;br&gt;
&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/RCPHaM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面包含细分文章的索引 (可点击跳转)&lt;/p&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-lg&#34;&gt;&lt;ul&gt;
&lt;li&gt;AI
&lt;ul&gt;
&lt;li&gt;研究领域
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../ML&#34;&gt;机器学习&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../DL&#34;&gt;深度学习&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CV 计算机视觉
&lt;ul&gt;
&lt;li&gt;图像识别&lt;/li&gt;
&lt;li&gt;机器视觉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;语音信息处理
&lt;ul&gt;
&lt;li&gt;文本-&amp;gt;语音&lt;/li&gt;
&lt;li&gt;语音-&amp;gt;文本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;自然语言处理 NLP
&lt;ul&gt;
&lt;li&gt;文本生成&lt;/li&gt;
&lt;li&gt;文本分类&lt;/li&gt;
&lt;li&gt;翻译&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ROS 机器人系统&lt;/li&gt;
&lt;li&gt;专家系统&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;框架和库
&lt;ul&gt;
&lt;li&gt;Tenserflow&lt;/li&gt;
&lt;li&gt;Pytorch&lt;/li&gt;
&lt;li&gt;sklearn&lt;/li&gt;
&lt;li&gt;飞桨&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;表示学习
&lt;ul&gt;
&lt;li&gt;表示
&lt;ul&gt;
&lt;li&gt;为了提高机器学习系统的准确率,就需要将输入信息转换为有效的特征&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据表示是机器学习的核心问题&lt;/li&gt;
&lt;li&gt;底层特征与高层语义之间存在语义鸿沟,如何在鸿沟上搭桥是表示学习的关键&lt;/li&gt;
&lt;li&gt;表示方法
&lt;ul&gt;
&lt;li&gt;局部表示/离散表示/符号表示
&lt;ul&gt;
&lt;li&gt;如: 红 绿 蓝&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分布式表示
&lt;ul&gt;
&lt;li&gt;优点
&lt;ul&gt;
&lt;li&gt;表示能力强&lt;/li&gt;
&lt;li&gt;向量维度低&lt;/li&gt;
&lt;li&gt;相似度容易计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例如: (255,0,0), (0,255,0)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;嵌入
&lt;ul&gt;
&lt;li&gt;将一个度量空间中的一些对象映射到另一个低维的度量空间中&lt;/li&gt;
&lt;li&gt;并尽可能保持不同对象之间的拓扑关系,比如自然语言中词的分布式表示&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据分析&#34;&gt;数据分析&lt;/h2&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-md&#34;&gt;&lt;ul&gt;
&lt;li&gt;数据分析
&lt;ul&gt;
&lt;li&gt;数据类型
&lt;ul&gt;
&lt;li&gt;数值 Numerical
&lt;ul&gt;
&lt;li&gt;离散 discrete&lt;/li&gt;
&lt;li&gt;连续 continuous&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分类 Categorical
&lt;ul&gt;
&lt;li&gt;无法相互度量的数据,例如颜色&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;序数 Ordinal
&lt;ul&gt;
&lt;li&gt;类似分类数据,但可以相互度量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;常用特殊值
&lt;ul&gt;
&lt;li&gt;均值 mean&lt;/li&gt;
&lt;li&gt;中值 median&lt;/li&gt;
&lt;li&gt;众数 mode&lt;/li&gt;
&lt;li&gt;标准差 std&lt;/li&gt;
&lt;li&gt;方差 var = std * std&lt;/li&gt;
&lt;li&gt;百分位数 percentile
&lt;ul&gt;
&lt;li&gt;返回一个数 x, 这个 x &amp;gt;= 数组中百分之 percentile 的数&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;待办&#34;&gt;待办&lt;/h2&gt;
&lt;h3 id=&#34;GAN&#34;&gt;GAN&lt;/h3&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Rsmdm0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;搜集大量 x 与 y 类型数据, GAN 模型可以自动学习 x 与 y 之间的关系&lt;/p&gt;
&lt;h3 id=&#34;异常检测-anomaly-detection&#34;&gt;异常检测-anomaly-detection&lt;/h3&gt;
&lt;p&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/blog/Rsmvdm.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;Glow&#34;&gt;Glow&lt;/h3&gt;
&lt;p&gt;Glow -&amp;gt; Flow-based generative model&lt;/p&gt;
&lt;p&gt;生成网络属于 DNN,是一种常用的&lt;a href=&#34;#%E5%8C%BA%E5%88%86%E6%9C%89-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0&#34;&gt;无监督学习模型&lt;/a&gt;&lt;/p&gt;
&lt;blockquote class=&#34;pullquote mindmap mindmap-md&#34;&gt;&lt;ul&gt;
&lt;li&gt;深度神经网络 DNN -&amp;gt; 生成网络
&lt;ul&gt;
&lt;li&gt;生成对抗网络 GANs (Generative Adversarial Networks)&lt;/li&gt;
&lt;li&gt;变分自编码器 VAE (Variational Auto-Encoder)&lt;/li&gt;
&lt;li&gt;Pixel RNN/CNN&lt;/li&gt;
&lt;li&gt;流模型 Glow (Generative Flow)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a&gt;&lt;img src= &#34;https://pan.weidows.tech/d/local/img/loading.svg&#34; data-lazy-src=&#34;https://pan.weidows.tech/d/local/img/divider.png&#34; alt=&#34;分割线&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;借物表&#34;&gt;借物表&lt;/h2&gt;
&lt;style&gt;.bbplayer{width: 100%; max-width: 850px; margin: auto}&lt;/style&gt;&lt;div class=&#34;bbplayer&#34;&gt;&lt;iframe class=&#34;bbplayer&#34; id=&#34;mmedia-SdqIqMdqlPnqocnW&#34; src=&#34;https://player.bilibili.com/player.html?bvid=BV1J94y1f7u5&amp;page=1&amp;high_quality=1&amp;danmaku=true&amp;autoplay=0&#34; allowfullscreen=&#34;allowfullscreen&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;0&#34; framespacing=&#34;0&#34; sandbox=&#34;allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups&#34;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script&gt; document.getElementById(&#34;mmedia-SdqIqMdqlPnqocnW&#34;).style.height=document.getElementById(&#34;mmedia-SdqIqMdqlPnqocnW&#34;).scrollWidth*0.76+&#34;px&#34;;
    window.onresize = function(){
      document.getElementById(&#34;mmedia-SdqIqMdqlPnqocnW&#34;).style.height=document.getElementById(&#34;mmedia-SdqIqMdqlPnqocnW&#34;).scrollWidth*0.76+&#34;px&#34;;
    }; &lt;/script&gt;
&lt;style&gt;.bbplayer{width: 100%; max-width: 850px; margin: auto}&lt;/style&gt;&lt;div class=&#34;bbplayer&#34;&gt;&lt;iframe class=&#34;bbplayer&#34; id=&#34;mmedia-RqHuTitokxKxuRuI&#34; src=&#34;https://player.bilibili.com/player.html?bvid=BV16L411w7oQ&amp;page=1&amp;high_quality=1&amp;danmaku=true&amp;autoplay=0&#34; allowfullscreen=&#34;allowfullscreen&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;0&#34; framespacing=&#34;0&#34; sandbox=&#34;allow-top-navigation allow-same-origin allow-forms allow-scripts allow-popups&#34;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script&gt; document.getElementById(&#34;mmedia-RqHuTitokxKxuRuI&#34;).style.height=document.getElementById(&#34;mmedia-RqHuTitokxKxuRuI&#34;).scrollWidth*0.76+&#34;px&#34;;
    window.onresize = function(){
      document.getElementById(&#34;mmedia-RqHuTitokxKxuRuI&#34;).style.height=document.getElementById(&#34;mmedia-RqHuTitokxKxuRuI&#34;).scrollWidth*0.76+&#34;px&#34;;
    }; &lt;/script&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-1&#39; href=&#39;#cite_ref-1&#39;&gt;[1]&lt;/a&gt;: &lt;a href=&#34;https://zhuanlan.zhihu.com/p/86794447&#34;&gt;一文看懂人工智能、机器学习、深度学习与神经网络之间的区别与关系&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&#39;cite_note-2&#39; href=&#39;#cite_ref-2&#39;&gt;[2]&lt;/a&gt;: &lt;a href=&#34;https://nndl.github.io/&#34;&gt;神经网络与深度学习&lt;/a&gt;&lt;/p&gt;
&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kity@2.0.4/dist/kity.min.js&#34;&gt;&lt;/script&gt;&lt;script type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js&#34;&gt;&lt;/script&gt;&lt;script defer=&#34;true&#34; type=&#34;text&amp;#x2F;javascript&#34; src=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js&#34;&gt;&lt;/script&gt;&lt;link rel=&#34;stylesheet&#34; type=&#34;text&amp;#x2F;css&#34; href=&#34;https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css&#34;&gt;</content>
        <category term="doing" />
        <category term="人工智能" />
        <category term="深度学习" />
        <category term="机器学习" />
        <updated>2022-03-18T16:13:49.000Z</updated>
    </entry>
</feed>
